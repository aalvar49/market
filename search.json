[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning for Propensity Modeling",
    "section": "",
    "text": "E-Commerce is important since it allows a business to reach customers across a larger footprint than a group of physical (brick-and-mortar) stores. Visitors to an e-commerce store can make a purchase at an time, in any location and in their choice of currency. The ability to attract such a diverse customer base is the main value of e-commerce to a business. While website traffic is a highly-tracked metric by e-commerce businesses, their hard work and efforts to attract visitors to their site should not go to waste. It is customers that every e-commerce site owner needs to sustain their business."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Machine Learning for Propensity Modeling",
    "section": "",
    "text": "E-Commerce is important since it allows a business to reach customers across a larger footprint than a group of physical (brick-and-mortar) stores. Visitors to an e-commerce store can make a purchase at an time, in any location and in their choice of currency. The ability to attract such a diverse customer base is the main value of e-commerce to a business. While website traffic is a highly-tracked metric by e-commerce businesses, their hard work and efforts to attract visitors to their site should not go to waste. It is customers that every e-commerce site owner needs to sustain their business."
  },
  {
    "objectID": "index.html#problem-with-visitors-to-an-e-commerce-store",
    "href": "index.html#problem-with-visitors-to-an-e-commerce-store",
    "title": "Machine Learning for Propensity Modeling",
    "section": "Problem with Visitors to an E-Commerce Store",
    "text": "Problem with Visitors to an E-Commerce Store\nThe majority of visitors to an e-commerce site leave without performing a transaction (making a purchase) on their first visit. In the case of the the Google merchandise store’s site, the fraction of such visitors leaving is greater than 95%. Industry research shows that the majority of purchases by a visitor to such a site don’t occur on the visitor’s first visit. If they do purchase, then more often than not they will return later and make a purchase."
  },
  {
    "objectID": "index.html#why-market-to-return-users",
    "href": "index.html#why-market-to-return-users",
    "title": "Machine Learning for Propensity Modeling",
    "section": "Why Market to Return Users?",
    "text": "Why Market to Return Users?\nBeing able to identify such high-value visitors ahead of time can be of tremendous help to a marketing team to develop campaigns to grow the number of first-time visitors who make a purchase (converters) or a return purchase (repeat customers).\nThe marketing team can design and deploy a campaign after visitors’ first visit to improve their chances of making a purchase on a future visit."
  },
  {
    "objectID": "index.html#why-machine-learning",
    "href": "index.html#why-machine-learning",
    "title": "Machine Learning for Propensity Modeling",
    "section": "Why Machine Learning?",
    "text": "Why Machine Learning?\nThrough the use of machine learning (ML), we can scale this approach to capture all first-time visitors to the store and also improve their likelihood (or propensity) to make a future purchase while they search on a competitor’s site for the same or a similar product. Doing so is one way to help grow the base of converters and repeat customers."
  },
  {
    "objectID": "index.html#who-is-the-business-client",
    "href": "index.html#who-is-the-business-client",
    "title": "Machine Learning for Propensity Modeling",
    "section": "Who is the Business Client?",
    "text": "Who is the Business Client?\nThis project would be directly useful to Robertson Marketing, who is responsible for management of the Google merchandise store."
  },
  {
    "objectID": "index.html#what-is-this-project-about",
    "href": "index.html#what-is-this-project-about",
    "title": "Machine Learning for Propensity Modeling",
    "section": "What is This Project About?",
    "text": "What is This Project About?\nIn this project, ML predictions are used to select a marketing audience with a low, medium and high propensity to make a purchase on a return visit. Within each group, we also develop and briefly profile test (or treatment) and control cohorts in order to help facilitate deployment of a marketing campaign."
  },
  {
    "objectID": "references/Scope.html",
    "href": "references/Scope.html",
    "title": "Project Scope",
    "section": "",
    "text": "The Google Merchandise store is an e-commerce store that sells Google-branded products. Less than 5% of visitors make a purchase from the Google merchandise store on the Google Marketplace. So, a large number of visitors are not making a purchase. They are either just visiting the store once (their first and only visit) and leaving, or visiting multiple times and but not making a purchase on any of those visits. It goes without saying that customers, and not visitors alone, ensure the sustainability of an e-commerce business.\nConsiderable effort has been made by the web design team to build the store’s website to attract site traffic and make a good impression on first-time visitors to the store. This effort should not go to waste. However, approximately 90% of purchases do not happen during an initial visit to an e-commerce website. Furthermore, repeat customers spend 33% more with a brand than new customers do. Only approximately 20% of existing customers account for approximately 80% of future profits. Getting visitors to return to a site is important, but is possibly of equal or greater importance to an e-commerce business to have these visitors make a purchase on a return visit. This underscores the importance of getting visitors to make a purchase on a subsequent visit to the store.\nBut, it is not just sufficient to ensure return visits occur. This is of no use to a business since they can’t grow customer revenue by relying visitors to return and make purchaes on their own volition. The visitor should be motivated between visits to return and make a purchase on one or more future visits, rather than just returning and browsing through the store as they did during a previous visit. Between August 1, 2016 and August 1, 2017, a little less than 2% of visitors made a purchase on a return visit to the Google merchandise store. One of the main reasons for visitors browsing an e-commerce store, rather than making a purchase, is because they are comparson-shopping across multiple such websites looking for the lowest price for the same or a very similar product.\nIn summary, it will help the Google Merchandise store grow their customer base and increase revenue if some of these first-time visitors who have\n\nnot made a purchase during their first visit\nmade a purchase during their first visit\n\nto the store will make a purchase during a subsequent visit. In other words, it is desirable that first-time visitors to the store become customers or repeat customers.\n\n\n\nIf the business can find ways to reach out to (interact with) visitors to the store after their first visit, and provide promotions, shipping offers, etc., then this could be one way to motivate these visitors to make a purchase on a return visit to the store. If the Google merchandise store management company can reach out to these first-time visitors based on the characteristics of their first visit to the store and get them to make a purchase on a return visit then this can not only grow the business’ customer base but also reduce the loss of customer revenue to a competitor.\nAlphabet is the parent company of Google, but Robertson Marketing is the company that manages the Google Merchandise store. The management company (Robertson Marketing) is impacted by the problem of low conversions or repeat customers among the pool of first-time visitors to the merchandise store and they would be interested in ways to turn such first-time visitors into one of the following\n\nfuture customers (converting visitors into customers, or conversions)\nrepeat-customers (customer retention)\n\n\n\n\nThe business (store management company, Robertson Marketing) has tasked its marketing team with growing\n\nnew customers (conversion)\nrepeat customers (getting customers to become repeat customers)\n\nfrom the pool of first-time visitors to the store.\nFor obvious reasons, not all first-time visitors to the merchandise store are alike and reaching out to visitors is a costly process. With this mind, the marketing team would like to design an appropriate marketing campaign to help achive the business’ objectives. With a strong preference to spend marketing funds (budget) wisely, the marketing team wants to interact with such first-time visitors through focused and relevant recommendations, reminders and other types of marketing promotions after their first visit to the store.\nA logical approach to developing targeted promotions to grow customers or repeat customers is to offer a promotion based on a visitor’s likelihood of making a purchase during a future visit to the merchandise store. Knowing this likelihood is useful in knowing which visitors the marketing team should be focused on and, subsequently, how much funding can be allocated to communicating with those visitors. Accordingly, the business can determine the type of promotion that should be offered. For example, a minimal discount could be offered to visitors with a high likelihood of making a future purchase. Similarly, more loyalty points, coupon giveaways or free shipping could be offered to visitors who are deemed less likely to make a future purchase from the store. These promotions can be offered after a visitor’s first visit to the store with the aim of persuading them to make a purchase during a future visit.\n\n\n\nWithout knowing visitors’ likelihood of making a purchase on a return visit, it is not possible to segment visitors into audience groups (eg. visitors with a high, medium or low likelihood of making a purchase on a return visit) after their first visit. If these groups and cohorts were known, the marketing team could test how they respond to marketing strategies. Naive random guesses at visitor likelihood groupings are costly and unlikely to get buy-in for funding requests from business management. Furthermore, a test and control cohort is needed within each group in order to quantitatively determine how each group responds to the chosen marketing campaign (i.e. these cohorts are needed to evaluate the performance of the campaign).\nWe will assume that the marketing team has not yet designed any approaches to address this problem. With this in mind, both the size of the audience groups and the size of these cohorts are currently completely unknown."
  },
  {
    "objectID": "references/Scope.html#understanding-the-problem",
    "href": "references/Scope.html#understanding-the-problem",
    "title": "Project Scope",
    "section": "",
    "text": "The Google Merchandise store is an e-commerce store that sells Google-branded products. Less than 5% of visitors make a purchase from the Google merchandise store on the Google Marketplace. So, a large number of visitors are not making a purchase. They are either just visiting the store once (their first and only visit) and leaving, or visiting multiple times and but not making a purchase on any of those visits. It goes without saying that customers, and not visitors alone, ensure the sustainability of an e-commerce business.\nConsiderable effort has been made by the web design team to build the store’s website to attract site traffic and make a good impression on first-time visitors to the store. This effort should not go to waste. However, approximately 90% of purchases do not happen during an initial visit to an e-commerce website. Furthermore, repeat customers spend 33% more with a brand than new customers do. Only approximately 20% of existing customers account for approximately 80% of future profits. Getting visitors to return to a site is important, but is possibly of equal or greater importance to an e-commerce business to have these visitors make a purchase on a return visit. This underscores the importance of getting visitors to make a purchase on a subsequent visit to the store.\nBut, it is not just sufficient to ensure return visits occur. This is of no use to a business since they can’t grow customer revenue by relying visitors to return and make purchaes on their own volition. The visitor should be motivated between visits to return and make a purchase on one or more future visits, rather than just returning and browsing through the store as they did during a previous visit. Between August 1, 2016 and August 1, 2017, a little less than 2% of visitors made a purchase on a return visit to the Google merchandise store. One of the main reasons for visitors browsing an e-commerce store, rather than making a purchase, is because they are comparson-shopping across multiple such websites looking for the lowest price for the same or a very similar product.\nIn summary, it will help the Google Merchandise store grow their customer base and increase revenue if some of these first-time visitors who have\n\nnot made a purchase during their first visit\nmade a purchase during their first visit\n\nto the store will make a purchase during a subsequent visit. In other words, it is desirable that first-time visitors to the store become customers or repeat customers.\n\n\n\nIf the business can find ways to reach out to (interact with) visitors to the store after their first visit, and provide promotions, shipping offers, etc., then this could be one way to motivate these visitors to make a purchase on a return visit to the store. If the Google merchandise store management company can reach out to these first-time visitors based on the characteristics of their first visit to the store and get them to make a purchase on a return visit then this can not only grow the business’ customer base but also reduce the loss of customer revenue to a competitor.\nAlphabet is the parent company of Google, but Robertson Marketing is the company that manages the Google Merchandise store. The management company (Robertson Marketing) is impacted by the problem of low conversions or repeat customers among the pool of first-time visitors to the merchandise store and they would be interested in ways to turn such first-time visitors into one of the following\n\nfuture customers (converting visitors into customers, or conversions)\nrepeat-customers (customer retention)\n\n\n\n\nThe business (store management company, Robertson Marketing) has tasked its marketing team with growing\n\nnew customers (conversion)\nrepeat customers (getting customers to become repeat customers)\n\nfrom the pool of first-time visitors to the store.\nFor obvious reasons, not all first-time visitors to the merchandise store are alike and reaching out to visitors is a costly process. With this mind, the marketing team would like to design an appropriate marketing campaign to help achive the business’ objectives. With a strong preference to spend marketing funds (budget) wisely, the marketing team wants to interact with such first-time visitors through focused and relevant recommendations, reminders and other types of marketing promotions after their first visit to the store.\nA logical approach to developing targeted promotions to grow customers or repeat customers is to offer a promotion based on a visitor’s likelihood of making a purchase during a future visit to the merchandise store. Knowing this likelihood is useful in knowing which visitors the marketing team should be focused on and, subsequently, how much funding can be allocated to communicating with those visitors. Accordingly, the business can determine the type of promotion that should be offered. For example, a minimal discount could be offered to visitors with a high likelihood of making a future purchase. Similarly, more loyalty points, coupon giveaways or free shipping could be offered to visitors who are deemed less likely to make a future purchase from the store. These promotions can be offered after a visitor’s first visit to the store with the aim of persuading them to make a purchase during a future visit.\n\n\n\nWithout knowing visitors’ likelihood of making a purchase on a return visit, it is not possible to segment visitors into audience groups (eg. visitors with a high, medium or low likelihood of making a purchase on a return visit) after their first visit. If these groups and cohorts were known, the marketing team could test how they respond to marketing strategies. Naive random guesses at visitor likelihood groupings are costly and unlikely to get buy-in for funding requests from business management. Furthermore, a test and control cohort is needed within each group in order to quantitatively determine how each group responds to the chosen marketing campaign (i.e. these cohorts are needed to evaluate the performance of the campaign).\nWe will assume that the marketing team has not yet designed any approaches to address this problem. With this in mind, both the size of the audience groups and the size of these cohorts are currently completely unknown."
  },
  {
    "objectID": "references/Scope.html#project-client-and-definition-of-objective",
    "href": "references/Scope.html#project-client-and-definition-of-objective",
    "title": "Project Scope",
    "section": "Project Client and Definition of Objective",
    "text": "Project Client and Definition of Objective\n\nBusiness Client\nThe client for this project is a marketing team responsible for managing marketing campaigns related to the Google merchandise store.\n\n\nProject Goal\nThis project exists to help the marketing team (client) interact with first-time visitors to the merchandise store, with the hopes of increasing the likelihood that these visitors will make a purchase (convert) or repeat-purchase during a future visit to the store. If this can be done, then it will help the team address the business’ objectives of growing new and repeat customers as mentioned above.\nThe objective of this project is to increase the number of first-time visitors to the merchandise store who are converted into new or repeat customers."
  },
  {
    "objectID": "references/Scope.html#actions-that-need-to-be-taken",
    "href": "references/Scope.html#actions-that-need-to-be-taken",
    "title": "Project Scope",
    "section": "Actions that Need to be Taken",
    "text": "Actions that Need to be Taken\nThis project will facilitate develpoment of a proactive and targeted marketing strategy (eg. promotions) to grow new and repeat customers."
  },
  {
    "objectID": "references/Scope.html#analysis",
    "href": "references/Scope.html#analysis",
    "title": "Project Scope",
    "section": "Analysis",
    "text": "Analysis\n\nType of Analysis\nWe need to answer the important question: Which visitors should we prioritize through proactive marketing promotions. In orther words, we want to identify the visitors with a low, medium and high likelihood of making a purchase during a future (or return) visit to the store.\nSince we want to intervene before a visitor’s next visit to the store, we would predict the likelihood of every first-time visitor making a purchase during a subsequent visit. These predictions will used to create audience groups based on the likelihood of making a future purchase and prioritize and focus the marketing strategy per group.\nThe analysis to be performed here is a prediction task. We need to predict the likelihood (or propensity) of a purchase during a future visit.\n\n\nFormat of Data\nThe analysis will be performed using machine learning (ML). A ML model will be trained using attributes (features) of the visitors’ first visit and it will predict visitors’ propensity to make a purchase on a return visit to the store. The best-performing trained ML model will be the one that can make this prediction with the highest accuracy or some other evaluation metric (this will be discussed later in the Evaluation Metric sub-section below). This application of ML is called propensity modeling. The outcome to be predicted is binary (there are only two possible outcomes)\n\nthe visitor will make a purchase on a return visit\nthe visitor will not make a purchase on a return visit\n\nIn a ML context, this is a supervised learning problem. Attributes about the first visit made by visitors to the store site are retrieved from Google Analytics (GA) tracking data accumulated for visitors to the merchandise store. GA tracking code has been embeded in the store’s website in order to anonymously track visitor interactions on the site. These attributes, or characteristics, of visitors’ first visit are the independent variables or features in ML.\nFor the same visitors, the outcome (or label in ML) of return visits (whether a purchase on a return visit was made or not) is retrieved to determine if a purchase on a future visit was made by this visitor. This label is a forward-looking label since it references events from the future. By comparison, the features are from the past (historical data) since they reference attributes of the visitor’s first visit to the store. Both features and label refer to the same visitor.\n\n\nAnalysis Workflow Overview\nWith such a dataset of Google Analytics tracking data available for all visitors to the store between August 1, 2016 and August 1, 2017, a ML model will be trained to predict whether first-time visitors will make a purchase during a future (return) visit. The trained model then predicts probabilities (which are interpreted as likelihoods or propensities) for new visitors to make a purchase on a return (or future) visit to the store. These new visitors were not part of the model’s training data. The predicted probabilities are then used to generate marketing audience groups (low, medium and high propensity) and test (or treatment) and control cohorts within each group as described above.\nIn summary the steps of such a workflow are\n\ntrain ML model using historical data for first visit of visitors\n\nthis is the training data\n\nuse trained model to predict probabilities for first visit of visitors that are not part of the training data\n\nthis is the unseen data\n\nuse predicted probabilities to assign audience cohorts (test or control) to all visitors in the unseen data\nbuild a brief profile of the visitors in the test cohort in unseen data\n\nwhen building a marketing strategy, we are not allowed to look at the control cohort and so the profile will be required for the test cohort only\n\nprovide audience test cohorts and their associated profile summaries to the marketing team\n\n\n\nTimeframes for Study\n\nIn order to avoid data leakage (or lookahead bias), the data splits are created in chronological order\n\ntraining data\n\nSeptember 1, 2016 to December 31, 2016\n\nvalidation data\n\nJanuary 1 - 31, 2017\n\ntest data\n\nFebruary 1 - 28, 2017\n\nunseen data\n\nMarch 1 - 31, 2017\n\n\nWe will assume that\n\nthe current date is March 1, 2017\nML model development can be performed between March 1 - 31, 2017\n\nThe marketing team is interested in growing new and repeat customers from visitors who made their first visit to the store during March 1 - 31, 2017 (unseen data). With this in mind, they want to\n\nbuild their campaign around these visitors\nlaunch their campaign on April 10, 2017\n\nThere are two constraints facing the client (marketing team)\n\nthe first visit data covering this period (unseen data) is only available on March 31, 2017 and this is close to the proposed campaign start date of April 10, 2017\ndesigning a typical marketing campaign takes 1 - 12 weeks\ncampaign launch windows occur every month\n\ncampaigns can be launched on April 10, 2017, May 10, 2017, June 10, 2017, etc.\n\n\nWith this in mind, the marketing team wants to start designing their campaign today (March 1, 2017). They do not want to wait until March 31, 2017 to receive recommended audience cohorts from the data science team and begin their campaign design. So, instead of waiting until March 31, 2017, the marketing team will start their campaign design using the audience cohorts recommended by the data science team using the test data split, which covers February 1 - 28, 2017.\nOn March 31, 2017, the marketing team will receive the audience cohorts from the data science team for the visits who made their first visit to the store during March 1 - 31, 2017. Between April 1, 2017 and April 9, 2017, the marketing team will start making adjustments to the campaign strategy by using the audience cohorts recommended by the data science team using the unseen data period (covering March 1 - 31, 2017). This will allow the marketing team to meet the proposed campaign start date of April 10, 2017.\nIf the datascience team is unable to generate a sufficiently accurate ML model to meet the April 10, 2017 campaign launch date then they will need to improve their analysis in order to try to meet the next available launch date (May 10, 2017).\n\n\n\nNotes\n\nRegarding ML labels (y)\n\nas mentioned earlier, these are forward-looking labels\n\nthe ML features (X) are attributes of a visitor’s first visit to the store\nthe ML labels (y) are the outcome (whether a purchase occurred or not) of that same visitor’s future visits to the store\n\na purchase is allowed to occur during any future visit to the store, not just the next visit\n\n\nin the period covering train, validation and test data splits, if a visitor has\n\nmade at least one purchase of a product during their return visit, then the label is set to True (or 1)\nnot made at least one purchase of a product during their return visit, then the label is set to False (or 0)\n\n\nThe data science team’s recommended audience cohorts (test and control) of visitors will be accepted by the marketing team if the ML model’s performance during evaluation (using the test data split) is better than that of a random model."
  },
  {
    "objectID": "references/Scope.html#how-do-actions-follow-from-the-analysis",
    "href": "references/Scope.html#how-do-actions-follow-from-the-analysis",
    "title": "Project Scope",
    "section": "How do Actions Follow From the Analysis",
    "text": "How do Actions Follow From the Analysis\nBased on visitors’ predicted likelihood of making a purchase on a future visit, marketing audience test and control groups (cohorts) will be created. Each group will contain a visitor ID as well as all the attributes of the visitor’s first visit that were used to predict the likelihood of a purchase during a return visit to the store.\nThese groups can be used by the marketing team to\n\ndesign appropriate strategies that can be implemented during activation\nestimate campaign costs"
  },
  {
    "objectID": "references/Scope.html#validation",
    "href": "references/Scope.html#validation",
    "title": "Project Scope",
    "section": "Validation",
    "text": "Validation\n\nDuring Development\nDevelopment covers September 1, 2016 - February 28, 2017.\nSince the current date is assumed to be March 1, 2017 and the training, validation and test data splits end no later than February 28, 2017, ML model predictions during validation (using validation split) and evaluation (using test split) can be scored before March 31, 2017.\nScoring is performed using evalaution metrics discussed in the ML Evaluation Metric sub-section below.\n\n\nDuring Production\nProduction covers March 1 - 31, 2017.\nThe model’s predictions will be scored against the outcome (whether the visitor makes a purchase on their return/future visit to the store) at the end of the marketing campaign.\n\n\nDifferences between Development and Production\n\nDuring production, the predictions are used to inform a marketing audience cohorts (test and control). By definition, the marketing strategy will be applied to the test cohort. It will not be applied to the control group. With this in mind, during the production period (March 1 - 31, 2017), we can only evaluate the predictions of the trained ML model that are associated with first-time visitors to the store during this period if those visitors are placed in the control cohort.\nAs mentioned earlier, the marketing team will only accept the data science team’s recommended audiente cohorts if the ML model outperforms a random model. At the same time, the data science team should also be checking for drift between attributes (features) of the first visit using the test split (development) and using the unseen data (production). If drift in features is observed outside a pre-defined threshold, then the data science team will need to repeat\n\nML model training using more training data (earlier start date than September 1, 2016)\nevaluation using the test split\nevaluation using the unseen data\n\nuntil drift is no longer observed. Feature drift checking will need to be done on April 1, 2017, before marketing audience visitor cohorts are given to the marketing team.\n\n\n\nWorkflow in Production\n\nThe trained model will make predictions of probability (propensity or likelihood) for all first-time visitors to the store during March 1 - 31, 2017. Predictions are used to identify marketing audience test (or treatment) and control cohorts.\nA marketing strategy is applied to all first-time visitors in the test group\nLength of marketing promotion campaign is to be determined by marketing team\nAt the end of the marketing campaign\n\nwe will know which visitors who were predicted to make a purchase on a return visit did actually make a purchase\nwe can evaluate the predictions made by the trained ML model on first visits that occurred during March 1 - 31, 2017\nwe can calculate a suitable KPI for this project\n\nKPI = number of purchases made by visitors in the test cohort - number of purchases made by visitors in the control cohort\n\nif this KPI is larger than zero, then we have successfully grown our customer base, which was the objective of the task that the business has given to the marketing team\n\nadditional KPIs can also be considered\n\n\n\nWe mentioned that scoring predictions of first visits that occurred during the unseen data period (production) of March 1 - 31, 2017 cannot be performed until the end of the marketing campaign. This was also mentioned in the during production sub-section above. It is worth emphasizing that until the end of the marketing campaign, we are unable to evalute the ML model’s predictions of data during the unseen data period (production). For this reason, it is improtant to check for drift in ML features between the unseen data (March 1 - 31, 2017) and test data (February 1 - 28, 2017) before the predictions are made and the audience cohorts are generated.\nGenerally, marketing campaigns run for approximately three months but this depends on numerous factors including\n\nmessage\ncall to action (CTA)\nfunds available (marketing budget)\nexpectations (desired uplift, etc.)\n\nThe duration, design and structure of the campaign will be determined by the marketing team starting on March 1, 2017 (today) and it will be finalized between April 1 - 9, 2019. On April 9, 2017, if it is determined that it is not feasible to design a campaign based on the audience cohorts recommended by the data science team (eg. cohorts are too large, etc.) then\n\nthe next available campaign launch window (May 10, 2017) will have to be targeted\nthe new unseen data (production) period will cover April 1 - 30, 2017\nthe datascience team will have to improve ML model performance between April 10 - 30, 2017\n\n\n\nML Evaluation Metric\nFalse negatives (tweets that should have been responded to but were predicted to not need a response) and false positives (tweets that did not need review by a team member but were predicted as requiring a review) are the most important types of errors. So the candidate metrics to be used to assess ML model performance are\n\nF1-score (if false negatives and false positives are equally important)\nF2-score (if false negatives are more important)\nF0.5-score (if false positives are more important)\n\nFor the current predicton task, there are two possible outcomes indicate whether a visitor did or did not make a purchase on a return visit to the store and these are\n\nactual\n\nis the true outcome\nthis is known after a visitor’s first visit to the store\nthis indicates that action that the marketing team should have taken\n\npredicted\n\nis the predicted outcome\nthis is predicted after the visitor’s first visit to the store\nthis indicates that action that the marketing team was predicted to have taken\n\n\nThe four possible ML prediction scenarios are listed below for the prediction of the outcome [whether a first-time visitor will, or will not, make a purchase on a return (future) visit to the merchandise store]\n\nTP: actual = makes purchase on return visit, predicted = makes purchase on return visit\n\npredicted marketing strategy matches what should be the actual marketing strategy\n\nTN: actual = does not make purchase on return visit, predicted = does not make purchase on return visit\n\npredicted marketing strategy matches what should be the actual marketing strategy\n\nFN: actual = makes purchase on return visit, predicted = does not make purchase on return visit\n\npredicted marketing strategy\n\npredicted to offer minimal promotion\n\nactual marketing strategy\n\nactually should have offered a stronger promotion\n\neg. more loyalty points, more frequent free/shipping, etc.\n\n\nthese errors in prediction lead to missed opportunities to correctly target first-time visitors since the predicted promotion offered is an underestimate of the true promotion that the team should have offered to these visitors\nthese errors lead to underspending on promotions to first-time visitors who are likely to benefit from them\n\nFP: actual = does not make purchase on return visit, predicted = makes purchase on return visit\n\npredicted marketing strategy\n\npredicted to offer a stronger promotion\n\nactual marketing strategy\n\nactually should have offered minimal promotion\n\nthese errors lead to overspending on promotions to first-time visitors who are not likely to benefit from them\nthis is the most expensive type of prediction error\nthis scenario must be avoided\n\n\nSince FP (false positives) are more costly than FN (false negatives), the scoring metric chosen to evaluate predictions made using the ML model is F0.5-score."
  },
  {
    "objectID": "references/Scope.html#data",
    "href": "references/Scope.html#data",
    "title": "Project Scope",
    "section": "Data",
    "text": "Data\nAn important factor that is driving propensity modeling in marketing is the need to do more with first-party customer data. This is data that comes directly from the customer and not from third-party sources. For marketing use-cases, effective propensity models use customer attributes from online and offline first-party data sources, including site analytics (online) and CRM (offline) data.\nHere, we have access to online data only Google Analytics tracking data (see the dataset and its documentation). This will be used to build a ML model to predict visitors’ propensity to make a purchase during a future visit to the store.\nVisit data for the merchandise store is available for the period of August 1, 2016 to August 1, 2017. This data provides information such as\n\nvisitor ID\nvisit date\nvist datetime\nactions performed during visit\n\nadd to cart\nremove from cart\nmake purchase\nview product details\netc.\n\ntotal time spent viewing pages during each visit\netc."
  },
  {
    "objectID": "references/Scope.html#analysis-notebooks",
    "href": "references/Scope.html#analysis-notebooks",
    "title": "Project Scope",
    "section": "Analysis Notebooks",
    "text": "Analysis Notebooks\n\nGet data and EDA Part 1\n\nconnect to raw visit data generated by Google Analytics tracking embedded in the merchandise store’s site\n\ndata is stored as Google BigQuery public dataset\nuse Python client to connect to dataset\nget overview of the columns in the raw visit data\n\nunderstand underlying patterns and stats about the visit-level data\nEDA part 1/2\n01_get_data.ipynb\n\nEDA Part 2\n\nEDA part 2/2\n02_eda.ipynb\n\nTransform data\n\n03_transform.ipynb\nextract the first visit per visitor (features, or X) and align with whether they made a purchase on a return (future) visit to the store (labels, or y)\n\nBaseline model development\n\ndevelop a baseline model to predict probability of purchase during future visit\n\nthis will be fast to train and will demonstrate the end-to-end project workflow, but will likely be over-simplified and so will underperform relative to a ML-based approach\n\n04_development.ipynb\n\nML model development\n\nrepeat baseline model development, but use a ML model instead\n05_dev_v2.ipynb"
  },
  {
    "objectID": "references/Scope.html#limitations",
    "href": "references/Scope.html#limitations",
    "title": "Project Scope",
    "section": "Limitations",
    "text": "Limitations\n\nBusiness Use Case\nThe analysis implemented here is only possible if Google Analytics tracking is embedded into an e-commerce website. Guides for embedding GA tracking code are documented below\n\nchartio blog post\nGoogle Support documentation\n\nFor the current use-case, this was already done for the Google Merchandise store’s website and so valuable tracking data could be collected and used. However, if such a solution is to be adopted for other digital marketplaces, then the Google Analytics tracking code must be embedded into those websites.\n\n\nData\n\nThe analytics dataset used in this project is based on a version of Google Analytics (GA360) that is deprecated as of July 1 2023 or 2024.\n\n\n\nOthers\nFor other limitations, please see the Limitations section in each notebook."
  },
  {
    "objectID": "references/Scope.html#assumptions",
    "href": "references/Scope.html#assumptions",
    "title": "Project Scope",
    "section": "Assumptions",
    "text": "Assumptions\n\nBusiness Use Case\n\nFor visitors who made a purchase on a return visit, we will include those who could have bought on their first as well. These are repeat customers, who we have assumed are one of the two types of visitors that we want to grow. For this reason, we will include their visits in the data.\nThe marketing team has does not have a preliminary idea as to the size of the audience groups (low, medium, high likelihood or propensity to make a purchase on a return visit) or cohorts and the strategy they will deploy as part of a campaign. As such, they have not yet designed any approaches to address this problem.\nDeployment-related assumptions (see point 4. in Timeframes for Study)\n\nwe have assumed that the current date is March 1, 2017\nwe have assumed that a trained ML model will make predictions for all first-time visitors to the store between March 1 - 31, 2017\n\n\nFor other assumptions, please see the Assumptions section in each notebook."
  },
  {
    "objectID": "notebooks/01-get-data/notebooks/01_get_data.html",
    "href": "notebooks/01-get-data/notebooks/01_get_data.html",
    "title": "Get Data",
    "section": "",
    "text": "Import Python modules\nCode\nimport os\nfrom datetime import date, datetime\nfrom glob import glob\n\nimport pandas as pd\nfrom google.oauth2 import service_account"
  },
  {
    "objectID": "notebooks/01-get-data/notebooks/01_get_data.html#about",
    "href": "notebooks/01-get-data/notebooks/01_get_data.html#about",
    "title": "Get Data",
    "section": "About",
    "text": "About\n\nObjective\nTo start analysis for this project, we will retrieve visitor session data from a small sample of the Google Merchandise Store on the Google Marketplace between the summer of August 1, 2016 and August 1, 2017.\n\n\nData\nThe dataset is provided by Google BigQuery (Google’s data warehouse) and is available here. It consists of a single table of visitor session data. The documentation for this dataset shows the column names and description."
  },
  {
    "objectID": "notebooks/01-get-data/notebooks/01_get_data.html#user-inputs",
    "href": "notebooks/01-get-data/notebooks/01_get_data.html#user-inputs",
    "title": "Get Data",
    "section": "User Inputs",
    "text": "User Inputs\nGet relative path to project root directory\n\nPROJ_ROOT_DIR = os.path.join(os.pardir)\n\nRetrieve credentials for bigquery client\n\n# Google Cloud PROJECT ID\ngcp_project_id = os.environ[\"GCP_PROJECT_ID\"]\n\nGet filepath to Google Cloud Service Account JSON key\n\nraw_data_dir = os.path.join(PROJ_ROOT_DIR, \"data\", \"raw\")\ngcp_creds_fpath = glob(os.path.join(raw_data_dir, \"*.json\"))[0]\n\nAuthenticate bigquery client and get dictionary with credentials\n\ngcp_credentials = service_account.Credentials.from_service_account_file(gcp_creds_fpath)\ngcp_auth_dict = dict(gcp_project_id=gcp_project_id, gcp_creds=gcp_credentials)\n\nCreate a mapping between action type integer and label, in order to get meaningful names from the action_type column\n\nmapper = {\n    1: \"Click through of product lists\",\n    2: \"Product detail views\",\n    3: \"Add product(s) to cart\",\n    4: \"Remove product(s) from cart\",\n    5: \"Check out\",\n    6: \"Completed purchase\",\n    7: \"Refund of purchase\",\n    8: \"Checkout options\",\n    0: \"Unknown\",\n}\n\nDefine a Python helper function to execute a SQL query using Google BigQuery\n\n\nCode\ndef run_sql_query(\n    query: str,\n    gcp_project_id: str,\n    gcp_creds: os.PathLike,\n    show_dtypes: bool = False,\n    show_info: bool = False,\n    show_df: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Run query on BigQuery and return results as pandas.DataFrame.\"\"\"\n    start_time = datetime.now()\n    start_time_str = start_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n    print(f\"Query execution start time = {start_time_str}...\", end=\"\")\n    df = pd.read_gbq(\n        query,\n        project_id=gcp_project_id,\n        credentials=gcp_creds,\n        dialect=\"standard\",\n        # configuration is optional, since default for query caching is True\n        configuration={\"query\": {\"useQueryCache\": True}},\n        # use_bqstorage_api=True,\n    )\n    end_time = datetime.now()\n    end_time_str = end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n    duration = end_time - start_time\n    duration = duration.seconds + (duration.microseconds / 1_000_000)\n    print(f\"done at {end_time_str} ({duration:.3f} seconds).\")\n    print(f\"Query returned {len(df):,} rows\")\n    if show_df:\n        with pd.option_context(\"display.max_columns\", None):\n            display(df)\n    if show_dtypes:\n        display(df.dtypes.rename(\"dtype\").to_frame().transpose())\n    if show_info:\n        df.info()\n    return df"
  },
  {
    "objectID": "notebooks/01-get-data/notebooks/01_get_data.html#get-data",
    "href": "notebooks/01-get-data/notebooks/01_get_data.html#get-data",
    "title": "Get Data",
    "section": "Get Data",
    "text": "Get Data\nShow the column properties (schema) of the sessions by users on the Google Marketplace\n\n\nCode\nquery = \"\"\"\n        SELECT table_name,\n               column_name,\n               data_type,\n               is_nullable,\n               ordinal_position\n        FROM `data-to-insights`.ecommerce.INFORMATION_SCHEMA.COLUMNS\n        WHERE table_name = 'web_analytics'\n        \"\"\"\n_ = run_sql_query(query, **gcp_auth_dict, show_df=True)\n\n\nQuery execution start time = 2023-04-10 05:17:23...done at 2023-04-10 05:17:24 (1.398 seconds).\nQuery returned 15 rows\n\n\n\n\n\n\n\n\n\ntable_name\ncolumn_name\ndata_type\nis_nullable\nordinal_position\n\n\n\n\n0\nweb_analytics\nvisitorId\nINT64\nYES\n1\n\n\n1\nweb_analytics\nvisitNumber\nINT64\nYES\n2\n\n\n2\nweb_analytics\nvisitId\nINT64\nYES\n3\n\n\n3\nweb_analytics\nvisitStartTime\nINT64\nYES\n4\n\n\n4\nweb_analytics\ndate\nSTRING\nYES\n5\n\n\n5\nweb_analytics\ntotals\nSTRUCT&lt;visits INT64, hits INT64, pageviews INT...\nYES\n6\n\n\n6\nweb_analytics\ntrafficSource\nSTRUCT&lt;referralPath STRING, campaign STRING, s...\nYES\n7\n\n\n7\nweb_analytics\ndevice\nSTRUCT&lt;browser STRING, browserVersion STRING, ...\nYES\n8\n\n\n8\nweb_analytics\ngeoNetwork\nSTRUCT&lt;continent STRING, subContinent STRING, ...\nYES\n9\n\n\n9\nweb_analytics\ncustomDimensions\nARRAY&lt;STRUCT&lt;index INT64, value STRING&gt;&gt;\nNO\n10\n\n\n10\nweb_analytics\nhits\nARRAY&lt;STRUCT&lt;hitNumber INT64, time INT64, hour...\nNO\n11\n\n\n11\nweb_analytics\nfullVisitorId\nSTRING\nYES\n12\n\n\n12\nweb_analytics\nuserId\nSTRING\nYES\n13\n\n\n13\nweb_analytics\nchannelGrouping\nSTRING\nYES\n14\n\n\n14\nweb_analytics\nsocialEngagementType\nSTRING\nYES\n15\n\n\n\n\n\n\n\nNotes\n\nThere are eight flattened columns and six nested columns in the web_analytics table.\nThe flattened columns are briefly explained below\n\ngeoNetwork provides information about the geography of the users who accessed the store website\ncustomDimensions are user-configured combinations of values of specific metrics to be tracked\n\nthese won’t be used for the current project\n\ndevice provides information about the user’s electronic device that was used to access the store website\ntotals provides aggregated stats per visit\ntrafficSource contains metadata about the traffic source that resulted in a user’s visit\nhits tracks execution of Google analytics tracking code embedded in the store’s website (this happends when a user performs an interaction with the store webpage)\n\n\nObservations\n\nWhile features for machine learning can be extracted from all the nested and flattened columns, the usefulness of these features is based on our understanding of the data. Only the features that can be\n\nwell understood\nextracted without data leakage/lookahead bias\n\nshould be extracted for use in ML. The following nested features should be intuitive and so will likely be easier to understand in the context of e-commerce transactions that the other nested columns\n\ngeoNetwork\ndevice\ntotals\n\n\nA simple SELECT is used to show a subset of the columns for the first 15 visits between November 1, 2016 and November 2, 2016\n\nquery = \"\"\"\n        SELECT fullvisitorid,\n               -- get date of transaction\n               date,\n               -- convert date to datetime in year-month-date format\n               PARSE_DATE('%Y%m%d', DATE) AS datetime_ymd,\n               -- visit start time and number\n               DATETIME(\n                   TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)),\n                   \"America/New_York\"\n               ) AS visitStartTime,\n               visitNumber,\n               -- source of the traffic from which the session was initiated\n               trafficSource.source,\n               -- medium of the traffic from which the session was initiated\n               trafficSource.medium,\n               -- referring channel connected to session\n               channelGrouping,\n               -- user's type of device\n               device.deviceCategory AS device_category,\n               -- user's operating system\n               device.operatingSystem AS os,\n               -- referring page for visits that ended in a transaction\n               CAST(h.eCommerceAction.action_type AS INT64) AS action_type,\n               -- transactions\n               totals.transactions,\n               -- return visits to the merchandise store\n               totals.newVisits AS newVisits\n        FROM `data-to-insights.ecommerce.web_analytics`,\n        UNNEST(hits) AS h\n        WHERE date BETWEEN '20161101' AND '20161102'\n        LIMIT 15\n        \"\"\"\ndf = run_sql_query(query, **gcp_auth_dict, show_df=False)\ndf[\"action_type\"] = df[\"action_type\"].map(mapper).astype(pd.StringDtype())\ndisplay(df)\ndf.info()\n\nQuery execution start time = 2023-04-10 05:17:24...done at 2023-04-10 05:17:26 (1.149 seconds).\nQuery returned 15 rows\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 15 entries, 0 to 14\nData columns (total 13 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   fullvisitorid    15 non-null     object        \n 1   date             15 non-null     object        \n 2   datetime_ymd     15 non-null     dbdate        \n 3   visitStartTime   15 non-null     datetime64[ns]\n 4   visitNumber      15 non-null     Int64         \n 5   source           15 non-null     object        \n 6   medium           15 non-null     object        \n 7   channelGrouping  15 non-null     object        \n 8   device_category  15 non-null     object        \n 9   os               15 non-null     object        \n 10  action_type      15 non-null     string        \n 11  transactions     0 non-null      Int64         \n 12  newVisits        7 non-null      Int64         \ndtypes: Int64(3), datetime64[ns](1), dbdate(1), object(7), string(1)\nmemory usage: 1.7+ KB\n\n\n\n\n\n\n\n\n\nfullvisitorid\ndate\ndatetime_ymd\nvisitStartTime\nvisitNumber\nsource\nmedium\nchannelGrouping\ndevice_category\nos\naction_type\ntransactions\nnewVisits\n\n\n\n\n0\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n1\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n2\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n3\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n4\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n5\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n6\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n7\n151591047911499240\n20161101\n2016-11-01\n2016-11-01 16:40:03\n10\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n8\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n9\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n10\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n11\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n12\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n13\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n14\n9346510850147042542\n20161102\n2016-11-02\n2016-11-02 13:37:44\n1\ngoogle\norganic\nOrganic Search\ndesktop\nWindows\nUnknown\n&lt;NA&gt;\n1\n\n\n\n\n\n\n\nNotes\n\nFor the datetime_ymd column, dbdate is the expected BigQuery SQL datatype.\nThe columns shown here are a subset of all the columns available in the table.\nUNNEST has to be used to flatten arrays (nested columns, such as hits) (explode them into separate rows), which is similar to pandas.DataFrame.explode().\nBigQuery uses query output caching, so subsequent runs of the same query SQL will return results in a shorter period of time than the previous run. See limitations here."
  },
  {
    "objectID": "notebooks/01-get-data/notebooks/01_get_data.html#next-step",
    "href": "notebooks/01-get-data/notebooks/01_get_data.html#next-step",
    "title": "Get Data",
    "section": "Next Step",
    "text": "Next Step\nThe next step in the analysis workflow will involve exploring the visits data."
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html",
    "title": "Data Preparation",
    "section": "",
    "text": "Import Python modules\nCode\nimport os\nfrom datetime import datetime\nfrom glob import glob\nfrom typing import Dict, List\n\nimport pandas as pd\nimport pytz\nfrom google.oauth2 import service_account"
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#about",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#about",
    "title": "Data Preparation",
    "section": "About",
    "text": "About\nThis step of the analysis will prepare data for use in exploratory and quantitative data analysis.\n\nDiscussion of Study Period for This Project\nWe will need to discuss the data that can be used to prepare data without suffering from lookahead bias/data leakage.\nData splits are created in a later step. ML model development will be performed using a training data split, validation (feature selection, hyperparameter tuning, etc.) is performed using the validation data split and, finally, the best ML model is evaluated using the test data split.\nSo, the validation and test data splits should be treated as unseen data. In order to avoid lookahead bias/data leakage during data preparation, this means that data preparation steps should be determined using the training data and simply applied to the validation and test data splits.\n\n\nData Selection for Data Preparation\nWith the above in mind, data preparation will cover the training data."
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#user-inputs",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#user-inputs",
    "title": "Data Preparation",
    "section": "User Inputs",
    "text": "User Inputs\nGet relative path to project root directory\n\nPROJ_ROOT_DIR = os.path.join(os.pardir)\n\nDefine the following\n\ntrain data start date\ntrain data end date\ntest data end date\n\n\ntrain_start_date = \"20160901\"\ntrain_end_date = \"20161231\"\ntest_end_date = \"20170228\"\n\nRetrieve credentials for bigquery client\n\n# Google Cloud PROJECT ID\ngcp_project_id = os.environ[\"GCP_PROJECT_ID\"]\n\nGet filepath to Google Cloud Service Account JSON key\n\nraw_data_dir = os.path.join(PROJ_ROOT_DIR, \"data\", \"raw\")\ngcp_creds_fpath = glob(os.path.join(raw_data_dir, \"*.json\"))[0]\n\nAuthenticate bigquery client and get dictionary with credentials\n\ngcp_credentials = service_account.Credentials.from_service_account_file(gcp_creds_fpath)\ngcp_auth_dict = dict(gcp_project_id=gcp_project_id, gcp_creds=gcp_credentials)\n\nCreate a mapping between action type integer and label, in order to get meaningful names from the action_type column\n\nmapper = {\n    1: \"Click through of product lists\",\n    2: \"Product detail views\",\n    3: \"Add product(s) to cart\",\n    4: \"Remove product(s) from cart\",\n    5: \"Check out\",\n    6: \"Completed purchase\",\n    7: \"Refund of purchase\",\n    8: \"Checkout options\",\n    0: \"Unknown\",\n}\n\nDefine a Python helper function to execute a SQL query using Google BigQuery\n\n\nCode\ndef run_sql_query(\n    query: str,\n    gcp_project_id: str,\n    gcp_creds: os.PathLike,\n    show_dtypes: bool = False,\n    show_info: bool = False,\n    show_df: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Run query on BigQuery and return results as pandas.DataFrame.\"\"\"\n    start_time = datetime.now(pytz.timezone(\"US/Eastern\"))\n    start_time_str = start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n    print(f\"Query execution start time = {start_time_str[:-3]}...\", end=\"\")\n    df = pd.read_gbq(\n        query,\n        project_id=gcp_project_id,\n        credentials=gcp_creds,\n        dialect=\"standard\",\n        # configuration is optional, since default for query caching is True\n        configuration={\"query\": {\"useQueryCache\": True}},\n        # use_bqstorage_api=True,\n    )\n    end_time = datetime.now(pytz.timezone(\"US/Eastern\"))\n    end_time_str = end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n    duration = end_time - start_time\n    duration = duration.seconds + (duration.microseconds / 1_000_000)\n    print(f\"done at {end_time_str[:-3]} ({duration:.3f} seconds).\")\n    print(f\"Query returned {len(df):,} rows\")\n    if show_df:\n        with pd.option_context(\"display.max_columns\", None):\n            display(df)\n    if show_dtypes:\n        display(df.dtypes.rename(\"dtype\").to_frame().transpose())\n    if show_info:\n        df.info()\n    return df"
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#data-preparation",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#data-preparation",
    "title": "Data Preparation",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nVisitors Who Made a Purchase\nQuestion 1. Get visitors with a purchase on a future visit to the Marketplace.\nTo get these visitors, a similar approach to that from the get-data step will be used. In that step, two criteria were used to identify a purchase on a future visit, namely total.transactions &gt; 0 and totals.newVisits IS NULL. Those will be used here as well.\nA query with these filters is executed below\n\nquery = f\"\"\"\n        SELECT fullvisitorid,\n               IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, True, False) AS made_purchase_on_future_visit,\n               IF(\n                   SUM(CASE WHEN totals.transactions &gt; 0 AND totals.newVisits IS NULL THEN 1 ELSE 0 END) &gt; 0, True, False\n               ) AS made_purchase_on_future_visit_v2\n        FROM `data-to-insights.ecommerce.web_analytics`\n        WHERE date BETWEEN '{train_start_date}' AND '{test_end_date}'\n        AND geoNetwork.country = 'United States'\n        GROUP BY fullvisitorid\n        \"\"\"\ndf = run_sql_query(query, **gcp_auth_dict, show_df=False)\ndisplay(\n    # breakdown of returning purchasers using COUNTIF()\n    df[\"made_purchase_on_future_visit\"]\n    .value_counts()\n    .rename(\"num_return_purchasers_using_countif\")\n    .to_frame()\n    .merge(\n        # breakdown of returning purchasers using CASE WHEN()\n        df[\"made_purchase_on_future_visit_v2\"]\n        .value_counts()\n        .rename(\"num_return_purchasers_using_if_sum_casewhen\")\n        .to_frame(),\n        left_index=True,\n        right_index=True,\n    )\n    .merge(\n        (\n            100\n            * df[\"made_purchase_on_future_visit\"]\n            .value_counts(normalize=True)\n            .rename(\"frac_made_purchase_on_future_visit\")\n        ).to_frame(),\n        left_index=True,\n        right_index=True,\n    )\n    .reset_index()\n    .rename(columns={\"index\": \"made_return_purchase\"})\n)\n\nQuery execution start time = 2023-04-12 11:40:28.222...done at 2023-04-12 11:40:33.195 (4.973 seconds).\nQuery returned 137,727 rows\n\n\n\n\n\n\n\n\n\nmade_purchase_on_future_visit\nnum_return_purchasers_using_countif\nnum_return_purchasers_using_if_sum_casewhen\nfrac_made_purchase_on_future_visit\n\n\n\n\n0\nFalse\n131734\n131734\n95.648638\n\n\n1\nTrue\n5993\n5993\n4.351362\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nCOUNTIF() is a BigQuery SQL function (1) but it gives the same output as a standard SQL-based approach using IF(SUM(CASE WHEN...)). For the rest of this step, COUNTIF() will be used\nOver the selected months, the class imbalance is close to 96% to 4% (or 96:4)\n\nthis comes from the made_purchase_on_future_visit column\nthese are the class labels for ML experiments\n\n\n\n\n\n\nFirst Visit Attributes\nQuestion 2. Extract attributes from the first visit by visitors that made a purchase on a future visit.\nThe following are the attributes extracted from the first visit (for the above visitors only) and the high-level categories that they belong to\n\ngeospatial and temporal\n\ncountry\ndatetime attributes (day of month, hour of day, etc.)\n\nmetadata of each visit and visitor\n\nthese are id (or equivalent) columns\n\ntraffic sources and channels\n\ntraffic sources\n\nthese are search engines, social media networks, and other sources that result in visitors reaching the merchandise store’s website (link)\n\nchannels\n\nthese are groups of traffic sources (link)\n\n\nvisitor activity on site\n\nhits\nbounces\npage views\ntime spent on site\nnumber of add-to-cart actions performed\n\nvisitor’s device used to access site\n\nbrowser\ndevice category\noperating system\n\nlabel for machine learning\n\nmade_purchase_on_future_visit\n\nsame as in the above query\nindicates whether a visitor makes a purchase during their next visit\n\n\nProduct\n\nproducts viewed\nproducts clicked\n\nPromotion\n\npromotions viewed (impressions)\npromotions clicked\n\n\n\nquery = f\"\"\"\n        WITH\n        -- Step 1. get visitors with a purchase on a future visit\n        next_visit_purchasers AS (\n             SELECT fullvisitorid,\n                    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, True, False) AS made_purchase_on_future_visit\n             FROM `data-to-insights.ecommerce.web_analytics`\n             WHERE date BETWEEN '{train_start_date}' AND '{test_end_date}'\n             AND geoNetwork.country = 'United States'\n             GROUP BY fullvisitorid\n        ),\n        -- Steps 2. and 3. get attributes of the first visit\n        first_visit_attributes AS (\n            SELECT -- =========== GEOSPATIAL AND TEMPORAL ATTRIBUTES OF VISIT ===========\n                   geoNetwork.country,\n                   EXTRACT(QUARTER FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS quarter,\n                   EXTRACT(MONTH FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS month,\n                   EXTRACT(DAY FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS day_of_month,\n                   EXTRACT(DAYOFWEEK FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS day_of_week,\n                   EXTRACT(HOUR FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS hour,\n                   EXTRACT(MINUTE FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS minute,\n                   EXTRACT(SECOND FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS second,\n                   -- =========== VISIT AND VISITOR METADATA ===========\n                   fullvisitorid,\n                   visitId,\n                   visitNumber,\n                   DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern') AS visitStartTime,\n                   -- =========== SOURCE OF SITE TRAFFIC ===========\n                   -- source of the traffic from which the visit was initiated\n                   trafficSource.source,\n                   -- medium of the traffic from which the visit was initiated\n                   trafficSource.medium,\n                   -- referring channel connected to visit\n                   channelGrouping,\n                   -- =========== VISITOR ACTIVITY ===========\n                   -- total number of hits\n                   (CASE WHEN totals.hits &gt; 0 THEN totals.hits ELSE 0 END) AS hits,\n                   -- number of bounces\n                   (CASE WHEN totals.bounces &gt; 0 THEN totals.bounces ELSE 0 END) AS bounces,\n                   -- action performed during first visit\n                   CAST(h.eCommerceAction.action_type AS INT64) AS action_type,\n                   -- page views\n                   IFNULL(totals.pageviews, 0) AS pageviews,\n                   -- total revenue\n                   totals.totalTransactionRevenue / 1000000 AS transact_revenue,\n                   -- time on the website\n                   IFNULL(totals.timeOnSite, 0) AS time_on_site,\n                   -- whether add-to-cart was performed during visit\n                   (CASE WHEN CAST(h.eCommerceAction.action_type AS INT64) = 3 THEN 1 ELSE 0 END) AS added_to_cart,\n                   (CASE WHEN CAST(h.eCommerceAction.action_type AS INT64) = 2 THEN 1 ELSE 0 END) AS product_details_viewed,\n                   -- =========== VISITOR DEVICES ===========\n                   -- user's browser\n                   device.browser,\n                   -- user's operating system\n                   device.operatingSystem AS os,\n                   -- user's type of device\n                   device.deviceCategory,\n                   -- =========== PROMOTION ===========\n                   h.promotion,\n                   h.promotionActionInfo AS pa_info,\n                   -- =========== PRODUCT ===========\n                   h.product,\n                   -- =========== ML LABEL (DEPENDENT VARIABLE) ===========\n                   made_purchase_on_future_visit\n            FROM `data-to-insights.ecommerce.web_analytics`,\n            UNNEST(hits) AS h\n            INNER JOIN next_visit_purchasers USING (fullvisitorid)\n            WHERE date BETWEEN '{train_start_date}' AND '{train_end_date}'\n            AND geoNetwork.country = 'United States'\n            AND totals.newVisits = 1\n        ),\n        -- Step 4. get aggregated features (attributes) per visit\n        visit_attributes AS (\n            SELECT fullvisitorid,\n                   visitId,\n                   visitNumber,\n                   visitStartTime,\n                   country,\n                   quarter,\n                   month,\n                   day_of_month,\n                   day_of_week,\n                   hour,\n                   minute,\n                   second,\n                   source,\n                   medium,\n                   channelGrouping,\n                   hits,\n                   bounces,\n                   -- get the last action performed during the first visit\n                   -- (this indicates where the visitor left off at the end of their visit)\n                   MAX(action_type) AS last_action,\n                   -- get number of products whose details were viewed\n                   SUM(product_details_viewed) AS product_detail_views,\n                   -- get number of promotions displayed and clicked during the first visit\n                   COUNT(CASE WHEN pa_info IS NOT NULL THEN pa_info.promoIsView ELSE NULL END) AS promos_displayed,\n                   COUNT(CASE WHEN pa_info IS NOT NULL THEN pa_info.promoIsClick ELSE NULL END) AS promos_clicked,\n                   -- get number of products displayed and clicked during the first visit\n                   COUNT(CASE WHEN pu.isImpression IS NULL THEN NULL ELSE 1 END) AS product_views,\n                   COUNT(CASE WHEN pu.isClick IS NULL THEN NULL ELSE 1 END) AS product_clicks,\n                   pageviews,\n                   transact_revenue,\n                   time_on_site,\n                   browser,\n                   os,\n                   deviceCategory,\n                   SUM(added_to_cart) AS added_to_cart,\n                   made_purchase_on_future_visit,\n            FROM first_visit_attributes\n            LEFT JOIN UNNEST(promotion) as p\n            LEFT JOIN UNNEST(product) as pu\n            GROUP BY fullvisitorid,\n                     visitId,\n                     visitNumber,\n                     visitStartTime,\n                     country,\n                     quarter,\n                     month,\n                     day_of_month,\n                     day_of_week,\n                     hour,\n                     minute,\n                     second,\n                     source,\n                     medium,\n                     channelGrouping,\n                     hits,\n                     bounces,\n                     pageviews,\n                     transact_revenue,\n                     time_on_site,\n                     browser,\n                     os,\n                     deviceCategory,\n                     made_purchase_on_future_visit\n        )\n        SELECT *\n        FROM visit_attributes\n        \"\"\"\ndf = run_sql_query(query, **gcp_auth_dict, show_df=False)\nwith pd.option_context(\"display.max_columns\", None):\n    display(df.head())\n    display(df.tail())\n\nQuery execution start time = 2023-04-12 11:40:33.218...done at 2023-04-12 11:40:50.480 (17.262 seconds).\nQuery returned 92,859 rows\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n0\n483329569933708956\n1477437687\n1\n2016-10-25 19:21:27\nUnited States\n4\n10\n25\n3\n19\n21\n27\ngoogle\norganic\nOrganic Search\n6\n0\n0\n0\n0\n0\n0\n0\n6\nNaN\n602\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n1\n9534112552538425546\n1476671570\n1\n2016-10-16 22:32:50\nUnited States\n4\n10\n16\n1\n22\n32\n50\nyoutube.com\nreferral\nSocial\n6\n0\n0\n0\n54\n0\n0\n0\n1\nNaN\n270\nOpera\nWindows\ndesktop\n0\nFalse\n\n\n2\n4648924122067625674\n1475958245\n1\n2016-10-08 16:24:05\nUnited States\n4\n10\n8\n7\n16\n24\n5\nyoutube.com\nreferral\nSocial\n5\n0\n0\n0\n36\n0\n4\n0\n2\nNaN\n198\nOpera\nWindows\ndesktop\n0\nFalse\n\n\n3\n2743152869399749836\n1481229164\n1\n2016-12-08 15:32:44\nUnited States\n4\n12\n8\n5\n15\n32\n44\ngoogle\norganic\nOrganic Search\n5\n0\n0\n0\n18\n0\n0\n0\n5\nNaN\n1004\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n4\n1565213706199847638\n1475172212\n1\n2016-09-29 14:03:32\nUnited States\n3\n9\n29\n5\n14\n3\n32\ngoogle\norganic\nOrganic Search\n5\n0\n0\n0\n18\n0\n15\n0\n5\nNaN\n107\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n92854\n116047731488418420\n1481947293\n1\n2016-12-16 23:01:33\nUnited States\n4\n12\n16\n6\n23\n1\n33\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n40\n0\n4\nNaN\n41\nInternet Explorer\nWindows\ndesktop\n0\nFalse\n\n\n92855\n4456968726181345855\n1475469647\n1\n2016-10-03 00:40:47\nUnited States\n4\n10\n3\n2\n0\n40\n47\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n48\n0\n4\nNaN\n116\nSafari\nMacintosh\ndesktop\n0\nFalse\n\n\n92856\n3959327314706060020\n1482846670\n1\n2016-12-27 08:51:10\nUnited States\n4\n12\n27\n3\n8\n51\n10\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n43\n0\n4\nNaN\n77\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n92857\n3020400276554321201\n1478988254\n1\n2016-11-12 17:04:14\nUnited States\n4\n11\n12\n7\n17\n4\n14\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n48\n0\n4\nNaN\n61\nInternet Explorer\nWindows\ndesktop\n0\nFalse\n\n\n92858\n7677161554293089105\n1481515229\n1\n2016-12-11 23:00:29\nUnited States\n4\n12\n11\n1\n23\n0\n29\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n44\n0\n4\nNaN\n31\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nBelow is a brief overview of the CTEs used here\n\nnext_visit_purchasers\n\ngets visitors who made a purchase on a return visit to the merchandise store on the Google Marketplace\n\nfirst_visit_attributes\n\ngets attributes of first visit\nthe statement INNER JOIN next_visit_purchasers USING (fullvisitorid) is used to only select the visitors that made a purchase on a return visit to the store (these fullvisitorids are stored in the next_visit_purchasers CTE)\n\nvisit_attributes\n\naggregates values from nested columns to get views and clicks for promotions and products\n\n\nThe BigQuery SQL function UNNEST was used to flatten nested columns.\nThe start and end dates of the ML training, validation and test data splits were defined. The training dates have been used to filter the first_visit_attributes CTE in order since EDA in this step will only be performed using the training data in order to avoid data leakage (or lookahead bias).\nThe SQL required to extract most of these columns was fairly straightforward and was determined from (a) the documentation for the dataset and (b) examining the first few rows of the dataset in these columns. For brevity, we won’t discuss these columns in further detail. These column categories are listed below\n\ngeospatial and temporal\nmetadata of each visit and visitor\ntraffic sources and channels\nvisitor activity on merchandise store website\nvisitor’s device\nlabel for machine learning (discussed in Data Preparation Question 2. above)\n\nThese columns were extracted based on intuition about the attributes of each visit that will help to predict the probability of a visitor making a purchase on a future (return) visit to the merchandise store.\n\n\n\n\n\nFraction of Visitors with Add-to-Cart on First Visit\nQuestion 3. What fraction of visitors added one or more items to their shopping cart during their first visit?\n\nfor c in [\"added_to_cart\"]:\n    display(\n        (100 * df[c].value_counts(dropna=False, normalize=True))\n        .rename(\"number\")\n        .reset_index()\n        .rename(columns={\"index\": \"added_to_cart\"})\n    )\n\n\n\n\n\n\n\n\nadded_to_cart\nnumber\n\n\n\n\n0\n0\n89.336521\n\n\n1\n1\n6.335412\n\n\n2\n2\n2.073035\n\n\n3\n3\n0.915366\n\n\n4\n4\n0.479221\n\n\n5\n5\n0.273533\n\n\n6\n6\n0.176612\n\n\n7\n7\n0.102306\n\n\n8\n8\n0.078614\n\n\n9\n9\n0.041999\n\n\n10\n10\n0.034461\n\n\n11\n12\n0.033384\n\n\n12\n11\n0.029076\n\n\n13\n14\n0.014\n\n\n14\n13\n0.012923\n\n\n15\n15\n0.010769\n\n\n16\n17\n0.009692\n\n\n17\n16\n0.006461\n\n\n18\n19\n0.004308\n\n\n19\n20\n0.004308\n\n\n20\n18\n0.004308\n\n\n21\n21\n0.003231\n\n\n22\n25\n0.003231\n\n\n23\n22\n0.002154\n\n\n24\n40\n0.002154\n\n\n25\n34\n0.002154\n\n\n26\n27\n0.001077\n\n\n27\n32\n0.001077\n\n\n28\n24\n0.001077\n\n\n29\n36\n0.001077\n\n\n30\n113\n0.001077\n\n\n31\n45\n0.001077\n\n\n32\n39\n0.001077\n\n\n33\n30\n0.001077\n\n\n34\n28\n0.001077\n\n\n35\n26\n0.001077\n\n\n36\n&lt;NA&gt;\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nDuring the months covered by the training data, nearly 90% of visitors did not add an item to their shopping cart during their first visit to the merchandise store (added_to_cart = 0). Only 10% of such visitors added an item to their shopping cart during this time.\n\n\n\n\n\nReasons For and Handling of Duplicates\nQuestion 4. Comment on duplicates present in the data prepared above. What are some possible reasons for the presence of duplicates in the above prepared data? How should these be handled?\nBelow we show that there are duplicates within the fullvisitorid column\n\n\nCode\nprint(\n    f\"Number of rows = {len(df):,}\\nNumber of unique visitor IDs = \"\n    f\"{df['fullvisitorid'].nunique():,}\\n\"\n    f\"Largest visitNumber = {df['visitNumber'].max()}\"\n)\n\n\nNumber of rows = 92,859\nNumber of unique visitor IDs = 92,551\nLargest visitNumber = 1\n\n\nThese duplicates are retrieved below, showing that multiple visitIds are present for the same visitorid\n\ndf_num_dups = (\n    df.groupby([\"fullvisitorid\"])\n    .agg({\"visitId\": \"count\", \"visitNumber\": \"max\"})\n    .reset_index()\n    .rename(columns={\"visitId\": \"num_visitIds\"})\n    .query(\"num_visitIds &gt; 1\")\n)\ndisplay(df_num_dups.head())\ndisplay(df_num_dups.tail())\n\n\n\n\n\n\n\n\nfullvisitorid\nnum_visitIds\nvisitNumber\n\n\n\n\n124\n0014997413479849928\n2\n1\n\n\n1186\n012569301201854368\n2\n1\n\n\n1400\n0153393931967124172\n2\n1\n\n\n1831\n0196238382136996118\n2\n1\n\n\n2163\n0233922069260074966\n2\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfullvisitorid\nnum_visitIds\nvisitNumber\n\n\n\n\n91561\n9897914422695841426\n2\n1\n\n\n91653\n9906208132011345120\n2\n1\n\n\n91749\n9915457192772678365\n2\n1\n\n\n92054\n9949751653823311987\n2\n1\n\n\n92079\n9952616174324085427\n2\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nDuplicates can occur by\n\nfullvisitorid\nvisitId\n\nso, we should explore both cases separately.\n\n\n\nDuplicated visitIds are shown below\n\ndup_visit_ids = df[df.duplicated(subset=[\"visitId\"], keep=False)]\nnum_dups = len(df[df.duplicated(subset=[\"visitId\"], keep=\"first\")])\nprint(\n    f\"Found {num_dups:,} duplicated visitIds out of \"\n    f\"{len(df):,} ({100*num_dups/len(df):.3f}%)\"\n)\nwith pd.option_context(\"display.max_columns\", None):\n    display(dup_visit_ids.sort_values(by=[\"visitId\"]).head(25))\n\nFound 742 duplicated visitIds out of 92,859 (0.799%)\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n4977\n7673928089571501866\n1472751431\n1\n2016-09-01 13:37:11\nUnited States\n3\n9\n1\n5\n13\n37\n11\ngoogle\norganic\nOrganic Search\n27\n0\n2\n6\n0\n0\n293\n8\n19\nNaN\n845\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n47310\n6028120763017470092\n1472751431\n1\n2016-09-01 13:37:11\nUnited States\n3\n9\n1\n5\n13\n37\n11\ndfa\ncpm\nDisplay\n7\n0\n0\n0\n9\n0\n147\n0\n7\nNaN\n153\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n26457\n0622219713224273207\n1472752926\n1\n2016-09-01 14:02:06\nUnited States\n3\n9\n1\n5\n14\n2\n6\nmall.googleplex.com\nreferral\nReferral\n7\n0\n0\n0\n9\n0\n167\n0\n7\nNaN\n178\nChrome\nLinux\ndesktop\n0\nFalse\n\n\n66595\n4654710059786315542\n1472752926\n1\n2016-09-01 14:02:06\nUnited States\n3\n9\n1\n5\n14\n2\n6\nyoutube.com\nreferral\nSocial\n3\n0\n0\n0\n18\n0\n0\n0\n3\nNaN\n50\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n64155\n8679833862264857329\n1472771118\n1\n2016-09-01 19:05:18\nUnited States\n3\n9\n1\n5\n19\n5\n18\ngoogle\norganic\nOrganic Search\n1\n1\n0\n0\n0\n0\n0\n0\n1\nNaN\n0\nSafari\nMacintosh\ndesktop\n0\nFalse\n\n\n21248\n0983194581450463928\n1472771118\n1\n2016-09-01 19:05:18\nUnited States\n3\n9\n1\n5\n19\n5\n18\nreddit.com\nreferral\nSocial\n2\n0\n0\n0\n9\n0\n34\n0\n2\nNaN\n15\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n62164\n5501176514964856126\n1472799309\n1\n2016-09-02 02:55:09\nUnited States\n3\n9\n2\n6\n2\n55\n9\ngoogle\norganic\nOrganic Search\n12\n0\n2\n4\n0\n0\n108\n4\n8\nNaN\n288\nChrome\nChrome OS\ndesktop\n0\nFalse\n\n\n72189\n5501176514964856126\n1472799309\n1\n2016-09-02 03:00:01\nUnited States\n3\n9\n2\n6\n3\n0\n1\ngoogle\norganic\nOrganic Search\n5\n0\n0\n0\n0\n0\n143\n0\n5\nNaN\n75\nChrome\nChrome OS\ndesktop\n0\nFalse\n\n\n86303\n3718403740052363161\n1472826491\n1\n2016-09-02 10:28:11\nUnited States\n3\n9\n2\n6\n10\n28\n11\ngoogle\norganic\nOrganic Search\n27\n0\n2\n9\n36\n2\n70\n9\n16\nNaN\n196\nSafari\niOS\ntablet\n0\nFalse\n\n\n1993\n0841953213802800334\n1472826491\n1\n2016-09-02 10:28:11\nUnited States\n3\n9\n2\n6\n10\n28\n11\n(direct)\n(none)\nDirect\n83\n0\n3\n15\n45\n0\n361\n20\n59\nNaN\n873\nChrome\nMacintosh\ndesktop\n4\nFalse\n\n\n29447\n3379865943266894087\n1472827968\n1\n2016-09-02 10:52:48\nUnited States\n3\n9\n2\n6\n10\n52\n48\n(direct)\n(none)\nDirect\n1\n1\n0\n0\n0\n0\n0\n0\n1\nNaN\n0\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n41280\n8072421534192464916\n1472827968\n1\n2016-09-02 10:52:48\nUnited States\n3\n9\n2\n6\n10\n52\n48\nyoutube.com\nreferral\nSocial\n1\n1\n0\n0\n0\n0\n0\n0\n1\nNaN\n0\nEdge\nWindows\ndesktop\n0\nFalse\n\n\n13883\n7256457379544446924\n1472830743\n1\n2016-09-02 11:39:03\nUnited States\n3\n9\n2\n6\n11\n39\n3\n(direct)\n(none)\nDirect\n4\n0\n0\n0\n9\n1\n17\n0\n3\nNaN\n31\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n20568\n1755792970575692332\n1472830743\n1\n2016-09-02 11:39:03\nUnited States\n3\n9\n2\n6\n11\n39\n3\n(direct)\n(none)\nDirect\n3\n0\n0\n0\n9\n1\n34\n0\n2\nNaN\n23\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n90216\n0632675186889921612\n1472837248\n1\n2016-09-02 13:27:28\nUnited States\n3\n9\n2\n6\n13\n27\n28\ngoogle\norganic\nOrganic Search\n3\n0\n0\n0\n9\n1\n26\n0\n2\nNaN\n8\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n5682\n3083609601584075244\n1472837248\n1\n2016-09-02 13:27:28\nUnited States\n3\n9\n2\n6\n13\n27\n28\ndfa\ncpm\nDisplay\n1\n1\n0\n0\n0\n0\n0\n0\n1\nNaN\n0\nSafari\niOS\nmobile\n0\nFalse\n\n\n85346\n921700488150606409\n1472840651\n1\n2016-09-02 14:24:11\nUnited States\n3\n9\n2\n6\n14\n24\n11\nanalytics.google.com\nreferral\nReferral\n12\n0\n3\n1\n9\n1\n62\n1\n9\nNaN\n71\nChrome\nWindows\ndesktop\n1\nFalse\n\n\n12700\n0519598949480129245\n1472840651\n1\n2016-09-02 14:24:11\nUnited States\n3\n9\n2\n6\n14\n24\n11\ngoogle\norganic\nOrganic Search\n9\n0\n0\n0\n18\n0\n108\n0\n9\nNaN\n1906\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n91711\n7005010567253535201\n1472845470\n1\n2016-09-02 15:44:30\nUnited States\n3\n9\n2\n6\n15\n44\n30\ngoogle\norganic\nOrganic Search\n1\n1\n0\n0\n0\n0\n10\n0\n1\nNaN\n0\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n30129\n837289177119980105\n1472845470\n1\n2016-09-02 15:44:30\nUnited States\n3\n9\n2\n6\n15\n44\n30\n(direct)\n(none)\nDirect\n1\n1\n0\n0\n9\n0\n0\n0\n1\nNaN\n0\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n48767\n0634421561835257232\n1472930237\n1\n2016-09-03 15:17:17\nUnited States\n3\n9\n3\n7\n15\n17\n17\nyoutube.com\nreferral\nSocial\n4\n0\n2\n1\n9\n0\n31\n1\n3\nNaN\n119\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n77061\n8889451242449489132\n1472930237\n1\n2016-09-03 15:17:17\nUnited States\n3\n9\n3\n7\n15\n17\n17\ngoogle\norganic\nOrganic Search\n1\n1\n0\n0\n9\n0\n0\n0\n1\nNaN\n0\nSafari\niOS\nmobile\n0\nFalse\n\n\n38847\n1935680082667534577\n1472972244\n1\n2016-09-04 03:00:42\nUnited States\n3\n9\n4\n1\n3\n0\n42\ngoogle\norganic\nOrganic Search\n12\n0\n2\n3\n0\n0\n115\n3\n9\nNaN\n203\nChrome\niOS\nmobile\n0\nFalse\n\n\n23907\n1935680082667534577\n1472972244\n1\n2016-09-04 02:57:24\nUnited States\n3\n9\n4\n1\n2\n57\n24\ngoogle\norganic\nOrganic Search\n6\n0\n0\n0\n9\n0\n106\n0\n6\nNaN\n144\nChrome\niOS\nmobile\n0\nFalse\n\n\n87832\n1007310562563797720\n1473058799\n1\n2016-09-05 02:59:59\nUnited States\n3\n9\n5\n2\n2\n59\n59\n(direct)\n(none)\nDirect\n1\n1\n0\n0\n9\n0\n0\n0\n1\nNaN\n0\nSafari (in-app)\niOS\nmobile\n0\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nFor the same visitId, different traffic sources (source, medium, channelGrouping) bring the same or different visitors (fullvisitorid) to the website at the same datetime (visitStartTime). Google Analytics assigns the same visitId to such visitors. There are two types of nested duplicates here\n\nthe same visitor accessing the merchandise store from\n\nmultiple devices at the same time\n\nthis cross-device tracking appears to be allowed by Google Analytics\n\nthe same device and same browser (using separate browser windows after clearing cookies) at the same time\n\nthis is also allowed by Google Analytics\n\n\ndifferent visitors are accessing the merchandise store from multiple devices at the same time\n\nthis is not a duplicated occurrence\nmost likely this corresponds to two distinct visitors who happened to navigate to the site at the same time\n\n\nThere are a negligible number of such duplicates in the dataset.\n\n\n\nDuplicated fullvisitorIds are shown below\n\ndup_visitor_ids = df[df.duplicated(subset=[\"fullvisitorid\"], keep=False)]\nnum_dups = len(df[df.duplicated(subset=[\"fullvisitorid\"], keep=\"first\")])\nprint(\n    f\"Found {num_dups:,} duplicated fullvisitorid out of \"\n    f\"{len(df):,} ({100*num_dups/len(df):.3f}%)\"\n)\nwith pd.option_context(\"display.max_columns\", None):\n    display(dup_visitor_ids.sort_values(by=[\"fullvisitorid\"]).head(25))\n\nFound 308 duplicated fullvisitorid out of 92,859 (0.332%)\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n50703\n0014997413479849928\n1477513747\n1\n2016-10-26 16:29:07\nUnited States\n4\n10\n26\n4\n16\n29\n7\n(direct)\n(none)\nDirect\n14\n0\n2\n1\n18\n0\n38\n4\n10\nNaN\n77\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n62579\n0014997413479849928\n1474324872\n1\n2016-09-19 18:41:12\nUnited States\n3\n9\n19\n2\n18\n41\n12\nmall.googleplex.com\nreferral\nReferral\n17\n0\n2\n3\n9\n0\n168\n5\n12\nNaN\n349\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n9213\n012569301201854368\n1477339547\n1\n2016-10-24 16:05:52\nUnited States\n4\n10\n24\n2\n16\n5\n52\n(direct)\n(none)\nDirect\n2\n0\n0\n0\n9\n0\n10\n0\n2\nNaN\n12\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n87971\n012569301201854368\n1477496472\n1\n2016-10-26 11:41:12\nUnited States\n4\n10\n26\n4\n11\n41\n12\nanalytics.google.com\nreferral\nReferral\n1\n1\n0\n0\n9\n0\n0\n0\n1\nNaN\n0\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n62216\n0153393931967124172\n1481528488\n1\n2016-12-12 03:00:03\nUnited States\n4\n12\n12\n2\n3\n0\n3\ngoogle\norganic\nOrganic Search\n13\n0\n2\n1\n9\n0\n92\n2\n11\nNaN\n614\nSafari\nMacintosh\ndesktop\n0\nFalse\n\n\n23567\n0153393931967124172\n1481528488\n1\n2016-12-12 02:41:28\nUnited States\n4\n12\n12\n2\n2\n41\n28\ngoogle\norganic\nOrganic Search\n5\n0\n0\n0\n9\n0\n15\n0\n5\nNaN\n1105\nSafari\nMacintosh\ndesktop\n0\nFalse\n\n\n27183\n0196238382136996118\n1482220536\n1\n2016-12-20 02:55:36\nUnited States\n4\n12\n20\n3\n2\n55\n36\n(direct)\n(none)\nDirect\n11\n0\n5\n1\n0\n0\n7\n1\n9\nNaN\n99\nChrome\nMacintosh\ndesktop\n1\nFalse\n\n\n92841\n0196238382136996118\n1482220536\n1\n2016-12-20 03:00:19\nUnited States\n4\n12\n20\n3\n3\n0\n19\n(direct)\n(none)\nDirect\n4\n0\n6\n0\n0\n0\n0\n0\n4\n165.0\n61\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n79440\n0233922069260074966\n1477516633\n1\n2016-10-26 17:17:13\nUnited States\n4\n10\n26\n4\n17\n17\n13\nmall.googleplex.com\nreferral\nReferral\n3\n0\n0\n0\n9\n0\n14\n0\n3\nNaN\n46\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n14258\n0233922069260074966\n1474926165\n1\n2016-09-26 17:42:45\nUnited States\n3\n9\n26\n2\n17\n42\n45\n(direct)\n(none)\nDirect\n5\n0\n0\n0\n0\n0\n18\n0\n5\nNaN\n869\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n6588\n023880134273808115\n1473836398\n1\n2016-09-14 02:59:58\nUnited States\n3\n9\n14\n4\n2\n59\n58\nmall.googleplex.com\nreferral\nReferral\n1\n1\n0\n0\n9\n0\n0\n0\n1\nNaN\n0\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n21411\n023880134273808115\n1473836398\n1\n2016-09-14 03:01:08\nUnited States\n3\n9\n14\n4\n3\n1\n8\nmall.googleplex.com\nreferral\nReferral\n3\n0\n0\n0\n0\n1\n68\n0\n2\nNaN\n9\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n6591\n0253256708649119169\n1477495482\n1\n2016-10-26 11:24:42\nUnited States\n4\n10\n26\n4\n11\n24\n42\nmall.googleplex.com\nreferral\nReferral\n1\n1\n0\n0\n9\n0\n0\n0\n1\nNaN\n0\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n13220\n0253256708649119169\n1475866302\n1\n2016-10-07 14:51:42\nUnited States\n4\n10\n7\n6\n14\n51\n42\ngoogle\norganic\nOrganic Search\n17\n0\n4\n2\n9\n0\n60\n2\n12\nNaN\n185\nChrome\nMacintosh\ndesktop\n2\nFalse\n\n\n26243\n0273626426804732878\n1477523531\n1\n2016-10-26 19:12:11\nUnited States\n4\n10\n26\n4\n19\n12\n11\nmall.googleplex.com\nreferral\nReferral\n6\n0\n0\n0\n9\n0\n32\n0\n6\nNaN\n71\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n4464\n0273626426804732878\n1475625049\n1\n2016-10-04 19:50:49\nUnited States\n4\n10\n4\n3\n19\n50\n49\nmall.googleplex.com\nreferral\nReferral\n17\n0\n0\n0\n27\n1\n101\n0\n16\nNaN\n279\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n28585\n0495389417785084319\n1476424324\n1\n2016-10-14 01:52:04\nUnited States\n4\n10\n14\n6\n1\n52\n4\ngoogle\norganic\nOrganic Search\n45\n0\n3\n2\n54\n4\n108\n3\n34\nNaN\n2644\nChrome\nAndroid\nmobile\n4\nFalse\n\n\n68258\n0495389417785084319\n1477460221\n1\n2016-10-26 01:37:01\nUnited States\n4\n10\n26\n4\n1\n37\n1\n(direct)\n(none)\nDirect\n1\n1\n0\n0\n0\n0\n12\n0\n1\nNaN\n0\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n44670\n0510616407042133197\n1477499309\n1\n2016-10-26 12:28:29\nUnited States\n4\n10\n26\n4\n12\n28\n29\nsites.google.com\nreferral\nReferral\n3\n0\n0\n0\n9\n0\n15\n0\n3\nNaN\n20\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n28323\n0510616407042133197\n1473965199\n1\n2016-09-15 14:46:39\nUnited States\n3\n9\n15\n5\n14\n46\n39\nmall.googleplex.com\nreferral\nReferral\n28\n0\n3\n3\n36\n0\n36\n3\n23\nNaN\n1183\nChrome\nMacintosh\ndesktop\n2\nFalse\n\n\n73353\n0567348342496807208\n1480060521\n1\n2016-11-25 03:08:08\nUnited States\n4\n11\n25\n6\n3\n8\n8\ngoogle\norganic\nOrganic Search\n9\n0\n2\n3\n0\n0\n21\n3\n6\nNaN\n103\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n81083\n0567348342496807208\n1480060521\n1\n2016-11-25 02:55:21\nUnited States\n4\n11\n25\n6\n2\n55\n21\ngoogle\norganic\nOrganic Search\n2\n0\n0\n0\n0\n0\n24\n0\n2\nNaN\n66\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n8962\n0611144195339874223\n1477810729\n1\n2016-10-30 03:00:13\nUnited States\n4\n10\n30\n1\n3\n0\n13\nmall.googleplex.com\nreferral\nReferral\n3\n0\n0\n0\n18\n0\n10\n0\n3\nNaN\n65\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n71666\n0611144195339874223\n1477810729\n1\n2016-10-30 02:58:49\nUnited States\n4\n10\n30\n1\n2\n58\n49\nmall.googleplex.com\nreferral\nReferral\n3\n0\n0\n0\n18\n0\n10\n0\n3\nNaN\n33\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n10194\n0707913578847667979\n1480233588\n1\n2016-11-27 02:59:48\nUnited States\n4\n11\n27\n1\n2\n59\n48\n(direct)\n(none)\nDirect\n1\n1\n0\n0\n0\n0\n12\n0\n1\nNaN\n0\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nFor the same fullvisitorid, different traffic sources (source, medium, channelGrouping) bring the same visitor (fullvisitorid) to the website at the different datetimes (visitStartTimes) from the same device (browser, os, deviceCategory). There are two types of nested duplicates here\n\nthe same visit by the same visitor with a &lt;30 minute period of inactivity between duplicates\n\n(by default) Google Analytics allows up to 30 minutes of inactivity before starting a new visit, so it is not clear why such a short period of inactivity should start a new instance of the same visit instead of just accumulating stats into the same instance\n\na different visit by the same visitor with a &gt;30 minute period of inactivity between duplicates\n\nit is also not clear why these duplicates are present in the data\n\n\nSince\n\nthe use-case for this project requires attributes of only the first visit (per visitor) to be used to predict the probability of a purchase during a future visit by the same visitor\nit is not clear why this type of duplicated record is present in the prepared data\n\nwe will want to drop this type of duplicate from the training, validation and test splits of the prepared data (we’re assuming that the same type of problem can occur throughout the dataset and not just in the training data).\nThere are a negligible number of such duplicates in the dataset.\n\n\n\nWith this in mind, columns with duplicates in the fullvisitorid column are dropped. This will be done using Python\n\ndf = df.drop_duplicates(subset=[\"fullvisitorid\"], keep=\"first\")\n\n\n\nNested Promotion Column\nQuestion 5. Show and comment on unique values in the nested promotion column.\nThe number of promotions and products displayed (impressions) and clicked are shown below\n\nfor c in [\n    \"promos_displayed\",\n    \"promos_clicked\",\n    \"product_views\",\n    \"product_clicks\",\n    \"product_detail_views\",\n]:\n    df_num_visitor_counts = (\n        df[c]\n        .value_counts(dropna=False)\n        .rename(\"num_visitors\")\n        .reset_index()\n        .rename(columns={\"index\": f\"num_{c}\"})\n    )\n    assert (\n        type(df_num_visitor_counts.query(\"num_visitors == 0\")[c].squeeze()).__name__\n        == \"NAType\"\n    )\n    display(df_num_visitor_counts.query(\"num_visitors &gt; 0\"))\n\n\n\n\n\n\n\n\npromos_displayed\nnum_visitors\n\n\n\n\n0\n9\n42832\n\n\n1\n0\n28668\n\n\n2\n18\n12933\n\n\n3\n27\n4082\n\n\n4\n36\n1728\n\n\n5\n45\n875\n\n\n6\n54\n427\n\n\n7\n13\n251\n\n\n8\n63\n241\n\n\n9\n72\n143\n\n\n10\n81\n74\n\n\n11\n90\n58\n\n\n12\n26\n54\n\n\n13\n99\n30\n\n\n14\n117\n28\n\n\n15\n108\n22\n\n\n16\n39\n17\n\n\n17\n135\n14\n\n\n18\n126\n13\n\n\n19\n153\n9\n\n\n20\n198\n7\n\n\n21\n65\n6\n\n\n22\n52\n5\n\n\n23\n144\n4\n\n\n24\n180\n3\n\n\n25\n171\n3\n\n\n26\n162\n2\n\n\n27\n252\n2\n\n\n28\n315\n1\n\n\n29\n49\n1\n\n\n30\n216\n1\n\n\n31\n765\n1\n\n\n32\n189\n1\n\n\n33\n50\n1\n\n\n34\n12\n1\n\n\n35\n432\n1\n\n\n36\n342\n1\n\n\n37\n522\n1\n\n\n38\n130\n1\n\n\n39\n711\n1\n\n\n40\n279\n1\n\n\n41\n207\n1\n\n\n42\n297\n1\n\n\n43\n234\n1\n\n\n44\n143\n1\n\n\n45\n31\n1\n\n\n46\n22\n1\n\n\n47\n225\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npromos_clicked\nnum_visitors\n\n\n\n\n0\n0\n78330\n\n\n1\n1\n10805\n\n\n2\n2\n2017\n\n\n3\n3\n751\n\n\n4\n4\n316\n\n\n5\n5\n146\n\n\n6\n6\n75\n\n\n7\n7\n47\n\n\n8\n8\n20\n\n\n9\n9\n13\n\n\n10\n10\n8\n\n\n11\n11\n6\n\n\n12\n14\n3\n\n\n13\n17\n2\n\n\n14\n34\n2\n\n\n15\n16\n2\n\n\n16\n12\n2\n\n\n17\n15\n1\n\n\n18\n23\n1\n\n\n19\n13\n1\n\n\n20\n19\n1\n\n\n21\n30\n1\n\n\n22\n21\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nproduct_views\nnum_visitors\n\n\n\n\n0\n0\n26846\n\n\n1\n12\n14268\n\n\n2\n24\n4664\n\n\n3\n36\n2339\n\n\n4\n7\n2273\n\n\n...\n...\n...\n\n\n601\n627\n1\n\n\n602\n706\n1\n\n\n603\n645\n1\n\n\n604\n998\n1\n\n\n605\n1487\n1\n\n\n\n\n606 rows × 2 columns\n\n\n\n\n\n\n\n\n\n\nproduct_clicks\nnum_visitors\n\n\n\n\n0\n0\n68182\n\n\n1\n1\n8674\n\n\n2\n2\n5454\n\n\n3\n3\n3057\n\n\n4\n4\n2035\n\n\n...\n...\n...\n\n\n62\n125\n1\n\n\n63\n52\n1\n\n\n64\n71\n1\n\n\n65\n42\n1\n\n\n66\n138\n1\n\n\n\n\n67 rows × 2 columns\n\n\n\n\n\n\n\n\n\n\nproduct_detail_views\nnum_visitors\n\n\n\n\n0\n0\n68227\n\n\n1\n1\n10544\n\n\n2\n2\n5193\n\n\n3\n3\n2926\n\n\n4\n4\n1735\n\n\n...\n...\n...\n\n\n56\n71\n1\n\n\n57\n96\n1\n\n\n58\n138\n1\n\n\n59\n69\n1\n\n\n60\n82\n1\n\n\n\n\n61 rows × 2 columns\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nProduct views are the number of times a product was seen while in a list of other products (eg. on a product listing page or in a product category page).\nProduct clicks are the number of times a product was clicked on after being viewed.\nProduct detail views are the number of times a visitor has visited a product’s page (not just viewed its details as part of a product listing).\n\na visitor might have viewed product details page for products that are\n\npart of a product listing\nnot part of a product listing\n\n\nSimilar logic applies to promotions (eg. banners) views and clicks.\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nProducts and promotions on the merchandise store’s website on the Google Marketplace are not being\n\nviewed (as part of a listing or in detail)\nclicked\n\noften.\n\n\n\nPromotion-related columns are flattened and shown (see promotionActionInfo) for a single visit\n\nquery = f\"\"\"\n        WITH visit_promotion_attrs AS (\n            SELECT fullvisitorid,\n                   visitId,\n                   visitNumber,\n                   DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern') AS visitStartTime,\n                   CAST(h.ecommerceaction.action_type AS INT64) AS action_type,\n                   h.promotion,\n                   h.promotionActionInfo AS pa_info,\n                   trafficSource.source,\n                   trafficSource.medium,\n                   channelGrouping,\n                   device.browser,\n                   device.operatingSystem,\n                   device.deviceCategory\n            FROM `data-to-insights.ecommerce.web_analytics`,\n            UNNEST(hits) AS h\n            WHERE visitId = 1476880065  -- 1476880065, 1478579523, 1474972357, 1478844153\n            AND geoNetwork.country = 'United States'\n        )\n        SELECT * EXCEPT(promotion, promoId, pa_info, visitStartTime),\n               pa_info,\n               CASE WHEN pa_info IS NOT NULL THEN pa_info.promoIsView ELSE NULL END AS view_promo,\n               CASE WHEN pa_info IS NOT NULL THEN pa_info.promoIsClick ELSE NULL END AS click_promo\n        FROM visit_promotion_attrs\n        LEFT JOIN UNNEST(promotion) as p\n        \"\"\"\ndf_raw = run_sql_query(query, **gcp_auth_dict, show_df=False)\ndf_raw[\"action_type\"] = df_raw[\"action_type\"].map(mapper)\nwith pd.option_context(\"display.max_colwidth\", None, \"display.max_rows\", None):\n    display(df_raw.head(10))\n\nQuery execution start time = 2023-04-12 11:40:50.810...done at 2023-04-12 11:40:52.167 (1.357 seconds).\nQuery returned 42 rows\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\naction_type\nsource\nmedium\nchannelGrouping\nbrowser\noperatingSystem\ndeviceCategory\npromoName\npromoCreative\npromoPosition\npa_info\nview_promo\nclick_promo\n\n\n\n\n0\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n1\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n2\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n3\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n4\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nApparel\nhome_main_link_apparel.jpg\nRow 1\n{'promoIsView': True, 'promoIsClick': None}\nTrue\n&lt;NA&gt;\n\n\n5\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nBackpacks\nhome_bags_google_2.jpg\nRow 2 Combo\n{'promoIsView': True, 'promoIsClick': None}\nTrue\n&lt;NA&gt;\n\n\n6\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nMens T-Shirts\nmens-tshirts.jpg\nRow 3-1\n{'promoIsView': True, 'promoIsClick': None}\nTrue\n&lt;NA&gt;\n\n\n7\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nWomens T-Shirts\nwomens-tshirts.jpg\nRow 3-2\n{'promoIsView': True, 'promoIsClick': None}\nTrue\n&lt;NA&gt;\n\n\n8\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nOffice\ngreen_row_link_to_office.jpg\nRow 5 Color Combo\n{'promoIsView': True, 'promoIsClick': None}\nTrue\n&lt;NA&gt;\n\n\n9\n3072592563711482446\n1476880065\n1\nUnknown\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\nDrinkware\nred_row_hydrate.jpg\nRow 4 Color Combo\n{'promoIsView': True, 'promoIsClick': None}\nTrue\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\npromotionActionInfo contains information about visitor views and clicks.\nThe CASE WHEN was constructed for both view_promo and click_promo columns based on the nested promotionActionInfo (mapped to pa_info) column.\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nWhen view_promo = True, a visitor has viewed a promotion. If it is not viewed, then it is NULL.\nWhen a visitor clicks a promotion after viewing it\n\nclick_promo = True\nview_promo is NULL\n\nthis prevents double-counting a promotion that is both viewed and clicked\n\n\n\n\n\n\n\nNested Product Column\nQuestion 6. Show and comment on unique values in the nested product column.\nProduct-related columns are flattened and shown for a single visit\n\nquery = f\"\"\"\n        WITH visit_product_attrs AS (\n            SELECT fullvisitorid,\n               visitId,\n               visitNumber,\n               DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern') AS visitStartTime,\n               CAST(h.ecommerceaction.action_type AS INT64) AS action_type,\n               h.product,\n               (CASE WHEN ARRAY_LENGTH(h.product) = 0 THEN 0 ELSE ARRAY_LENGTH(h.product) END) AS product_count,\n               (CASE WHEN CAST(h.eCommerceAction.action_type AS INT64) = 2 THEN 1 ELSE 0 END) AS product_details_viewed,\n               trafficSource.source,\n               trafficSource.medium,\n               channelGrouping,\n               device.browser,\n               device.operatingSystem,\n               device.deviceCategory\n            FROM `data-to-insights.ecommerce.web_analytics`,\n            UNNEST(hits) AS h\n            WHERE visitId = 1478579523  -- 1478579523, 1474972357\n            AND geoNetwork.country = 'United States'\n        )\n        SELECT *,\n               p.isImpression AS viewed_product,\n               p.isClick AS clicked_product\n        FROM visit_product_attrs\n        LEFT JOIN UNNEST(product) as p\n        \"\"\"\ndf_raw = run_sql_query(query, **gcp_auth_dict, show_df=False)\ndf_raw[\"action_type\"] = df_raw[\"action_type\"].map(mapper)\nwith pd.option_context(\"display.max_columns\", None):\n    display(df_raw.head())\n    display(df_raw.tail())\n\nQuery execution start time = 2023-04-12 11:40:52.204...done at 2023-04-12 11:40:53.807 (1.603 seconds).\nQuery returned 266 rows\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\naction_type\nproduct\nproduct_count\nproduct_details_viewed\nsource\nmedium\nchannelGrouping\nbrowser\noperatingSystem\ndeviceCategory\nproductSKU\nv2ProductName\nv2ProductCategory\nproductVariant\nproductBrand\nproductRevenue\nlocalProductRevenue\nproductPrice\nlocalProductPrice\nproductQuantity\nproductRefundAmount\nlocalProductRefundAmount\nisImpression\nisClick\ncustomDimensions\ncustomMetrics\nproductListName\nproductListPosition\nviewed_product\nclicked_product\n\n\n\n\n0\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[]\n0\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nNone\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n[]\n[]\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n1\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[]\n0\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nNone\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n[]\n[]\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n2\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[]\n0\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nNone\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n[]\n[]\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n3\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[]\n0\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nNone\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n[]\n[]\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n4\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[]\n0\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nNone\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n[]\n[]\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\naction_type\nproduct\nproduct_count\nproduct_details_viewed\nsource\nmedium\nchannelGrouping\nbrowser\noperatingSystem\ndeviceCategory\nproductSKU\nv2ProductName\nv2ProductCategory\nproductVariant\nproductBrand\nproductRevenue\nlocalProductRevenue\nproductPrice\nlocalProductPrice\nproductQuantity\nproductRefundAmount\nlocalProductRefundAmount\nisImpression\nisClick\ncustomDimensions\ncustomMetrics\nproductListName\nproductListPosition\nviewed_product\nclicked_product\n\n\n\n\n261\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[{'productSKU': 'GGOEGAAX0318', 'v2ProductName...\n12\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nGGOEGAAX0686\nYouTube Youth Short Sleeve Tee Red\nHome/Shop by Brand/YouTube/\n(not set)\n(not set)\n&lt;NA&gt;\n&lt;NA&gt;\n18990000\n18990000\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\nTrue\n&lt;NA&gt;\n[]\n[]\nCategory\n9\nTrue\n&lt;NA&gt;\n\n\n262\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[{'productSKU': 'GGOEGAAX0318', 'v2ProductName...\n12\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nGGOEYHPA003510\nYouTube Trucker Hat\nHome/Shop by Brand/YouTube/\n(not set)\n(not set)\n&lt;NA&gt;\n&lt;NA&gt;\n21990000\n21990000\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\nTrue\n&lt;NA&gt;\n[]\n[]\nCategory\n10\nTrue\n&lt;NA&gt;\n\n\n263\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[{'productSKU': 'GGOEGAAX0318', 'v2ProductName...\n12\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nGGOEGAAX0330\nYouTube Men's Skater Tee Charcoal\nHome/Shop by Brand/YouTube/\n(not set)\n(not set)\n&lt;NA&gt;\n&lt;NA&gt;\n19990000\n19990000\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\nTrue\n&lt;NA&gt;\n[]\n[]\nCategory\n11\nTrue\n&lt;NA&gt;\n\n\n264\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[{'productSKU': 'GGOEGAAX0318', 'v2ProductName...\n12\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nGGOEYDHJ056099\n22 oz YouTube Bottle Infuser\nHome/Shop by Brand/YouTube/\n(not set)\n(not set)\n&lt;NA&gt;\n&lt;NA&gt;\n4990000\n4990000\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\nTrue\n&lt;NA&gt;\n[]\n[]\nCategory\n12\nTrue\n&lt;NA&gt;\n\n\n265\n7270403007208566857\n1478579523\n1\n2016-11-07 23:32:03\nUnknown\n[]\n0\n0\nsiliconvalley.about.com\nreferral\nReferral\nChrome\nChrome OS\ndesktop\nNone\nNone\nNone\nNone\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n[]\n[]\nNone\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe product column is a nested column with a multi-element array. Each element (dictionary) of the array corresponds to a different product in a listing or category of products. With the BigQuery UNNEST() function, this column is exploded into the following standalone columns\n\nproductSKU\nv2ProductName\nv2ProductCategory\nproductVariant\nproductBrand\nproductRevenue\nlocalProductRevenue\nproductPrice\nlocalProductPrice\nproductQuantity\nproductRefundAmount\nlocalProductRefundAmount\nisImpression\nisClick\ncustomDimensions\ncustomMetrics\nproductListName\nproductListPosition\nviewed_product\nclicked_product\n\nviewed_product is True for every product in the product listing that was viewed.\n\n\n\nIf a product is viewed in a listing (product_count &gt; 0) during a visit, then there are only two possible values for clicked_product and viewed_product, as shown below\n\nfor c in [\"viewed_product\", \"clicked_product\"]:\n    # show unique values\n    display(\n        df_raw.query(\"product_count &gt; 0\")[c].value_counts(dropna=False).reset_index()\n    )\n\n    # verify that False is not a unique value\n    assert df_raw.query(\"product_count &gt; 0\").query(f\"{c} == False\").empty\n\n\n\n\n\n\n\n\nviewed_product\ncount\n\n\n\n\n0\nTrue\n189\n\n\n1\n&lt;NA&gt;\n41\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclicked_product\ncount\n\n\n\n\n0\n&lt;NA&gt;\n213\n\n\n1\nTrue\n17\n\n\n\n\n\n\n\nIf a product is not viewed in a listing, then the only value in these same two columns is NULL since they come from a nested column product which contains an empty array [] if a product is such a scenario.\nThis is shown below\n\nfor c in [\"viewed_product\", \"clicked_product\"]:\n    display(\n        df_raw.query(\"product_count == 0\")[c].value_counts(dropna=False).reset_index()\n    )\n\n\n\n\n\n\n\n\nviewed_product\ncount\n\n\n\n\n0\n&lt;NA&gt;\n36\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclicked_product\ncount\n\n\n\n\n0\n&lt;NA&gt;\n36\n\n\n\n\n\n\n\nFor every product in the product listing that was viewed and clicked\n\nclicked_product is True\nviewed_product is NULL\n\nwhich prevents double-counting products that are both viewed and clicked (similar to for promotions), as shown below\n\n\nCode\ndisplay(df_raw.query(\"clicked_product == True\")[[\"viewed_product\", \"clicked_product\"]])\n\n\n\n\n\n\n\n\n\nviewed_product\nclicked_product\n\n\n\n\n20\n&lt;NA&gt;\nTrue\n\n\n23\n&lt;NA&gt;\nTrue\n\n\n42\n&lt;NA&gt;\nTrue\n\n\n44\n&lt;NA&gt;\nTrue\n\n\n75\n&lt;NA&gt;\nTrue\n\n\n140\n&lt;NA&gt;\nTrue\n\n\n149\n&lt;NA&gt;\nTrue\n\n\n152\n&lt;NA&gt;\nTrue\n\n\n155\n&lt;NA&gt;\nTrue\n\n\n158\n&lt;NA&gt;\nTrue\n\n\n161\n&lt;NA&gt;\nTrue\n\n\n173\n&lt;NA&gt;\nTrue\n\n\n176\n&lt;NA&gt;\nTrue\n\n\n187\n&lt;NA&gt;\nTrue\n\n\n190\n&lt;NA&gt;\nTrue\n\n\n223\n&lt;NA&gt;\nTrue\n\n\n224\n&lt;NA&gt;\nTrue\n\n\n\n\n\n\n\nProduct detail views and clicking of products that were viewed in a product or product category listing can also be retrieved from the action_type column, which tracks each action performed by a visitor during a visit. Its unique values are shown below\n\n\nCode\ndf_raw[\"action_type\"].value_counts(dropna=False).reset_index()\n\n\n\n\n\n\n\n\n\naction_type\ncount\n\n\n\n\n0\nUnknown\n225\n\n\n1\nProduct detail views\n22\n\n\n2\nClick through of product lists\n17\n\n\n3\nAdd product(s) to cart\n2\n\n\n\n\n\n\n\nBelow, we verify that the products that were clicked can be equivalently determined using separated nested columns\n\nclicked_product (extracted from nested column product)\n\nclicked_product == True\n\naction_type (extracted from nested column hits)\n\naction_type == 'Click through of product lists'\n\n\n\nvisit_prodict_view_click_cols = [\n    \"fullvisitorid\",\n    \"visitStartTime\",\n    \"action_type\",\n    \"product_details_viewed\",\n    \"isImpression\",\n    \"isClick\",\n    \"viewed_product\",\n    \"clicked_product\",\n]\nassert df_raw.query(\"clicked_product == True\")[visit_prodict_view_click_cols].equals(\n    df_raw.query(\"action_type == 'Click through of product lists'\")[\n        visit_prodict_view_click_cols\n    ]\n)\n\nWhen a product is viewed in a listing (viewed_product), during a visit, the product count for those visits is greater than zero\n\nassert df_raw.query(\"viewed_product == True\")[\"product_count\"].min() &gt; 0\ndisplay(df_raw.query(\"viewed_product == True\")[\"product_count\"].describe().to_frame())\n\n\n\n\n\n\n\n\nproduct_count\n\n\n\n\ncount\n189.0\n\n\nmean\n9.719577\n\n\nstd\n3.355004\n\n\nmin\n2.0\n\n\n25%\n6.0\n\n\n50%\n12.0\n\n\n75%\n12.0\n\n\nmax\n12.0\n\n\n\n\n\n\n\nFor informational purposes, the raw dataset without unnesting the products and promotions columns is shown below for a small number of visits\n\nvisit_ids_dict = {\n    1478844153: \"papayawhip\",\n    1476880065: \"mistyrose\",\n    1478579523: \"lavender\",\n    1474972357: \"lightcyan\",\n}\nvisit_ids_str = \"(\" + \", \".join([str(v) for v in list(visit_ids_dict)]) + \")\"\n\nAttributes for these visits are retrieved below without unnesting product and promotion\n\nquery = f\"\"\"\n        WITH visit_promotion_attrs AS (\n            SELECT fullvisitorid,\n                   visitId,\n                   visitNumber,\n                   DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern') AS visitStartTime,\n                   CAST(h.ecommerceaction.action_type AS INT64) AS action_type,\n                   (CASE WHEN CAST(h.eCommerceAction.action_type AS INT64) = 2 THEN 1 ELSE 0 END) AS product_details_viewed,\n                   trafficSource.source,\n                   trafficSource.medium,\n                   channelGrouping,\n                   device.browser,\n                   device.operatingSystem,\n                   device.deviceCategory,\n                   -- visit\n                   totals.timeOnSite,\n                   totals.timeOnScreen,\n                   totals.visits,\n                   totals.totalTransactionRevenue / 1000000 AS transact_revenue,\n                   -- nested columns\n                   h.product,\n                   h.promotion,\n                   -- experimental columns that were not used\n                   h.isInteraction,\n                   trafficSource.campaign,\n                   trafficSource.isTrueDirect,\n            FROM `data-to-insights.ecommerce.web_analytics`,\n            UNNEST(hits) AS h\n            WHERE visitId IN {visit_ids_str}\n        )\n        SELECT * EXCEPT(visitStartTime)\n        FROM visit_promotion_attrs\n        \"\"\"\ndf_raw = run_sql_query(query, **gcp_auth_dict, show_df=False)\ndf_raw[\"action_type\"] = df_raw[\"action_type\"].map(mapper)\n\nQuery execution start time = 2023-04-12 11:40:54.002...done at 2023-04-12 11:40:55.510 (1.508 seconds).\nQuery returned 143 rows\n\n\nThese attributes can be shown per visitId using\nfor visit_id in list(visit_ids_dict):\n    with pd.option_context(\"display.max_columns\", None, \"display.max_rows\", None):\n        display(df_raw.query(f\"visitId == {visit_id}\"))\n\n\nChange Data Types in Prepared Data\n\ndtypes_dict = {\n    \"fullvisitorid\": pd.StringDtype(),\n    \"visitId\": pd.StringDtype(),\n    \"visitNumber\": pd.Int8Dtype(),\n    \"country\": pd.StringDtype(),\n    \"quarter\": pd.Int8Dtype(),\n    \"month\": pd.Int8Dtype(),\n    \"day_of_month\": pd.Int8Dtype(),\n    \"day_of_week\": pd.Int8Dtype(),\n    \"hour\": pd.Int8Dtype(),\n    \"minute\": pd.Int8Dtype(),\n    \"second\": pd.Int8Dtype(),\n    \"source\": pd.StringDtype(),\n    \"medium\": pd.StringDtype(),\n    \"channelGrouping\": pd.StringDtype(),\n    \"hits\": pd.Int16Dtype(),\n    \"bounces\": pd.Int16Dtype(),\n    \"last_action\": pd.Int8Dtype(),\n    \"product_detail_views\": pd.Int16Dtype(),\n    \"promos_displayed\": pd.Int16Dtype(),\n    \"promos_clicked\": pd.Int16Dtype(),\n    \"product_views\": pd.Int16Dtype(),\n    \"product_clicks\": pd.Int16Dtype(),\n    \"pageviews\": pd.Int16Dtype(),\n    \"transact_revenue\": pd.Float32Dtype(),\n    \"time_on_site\": pd.Int16Dtype(),\n    \"browser\": pd.StringDtype(),\n    \"os\": pd.StringDtype(),\n    \"added_to_cart\": pd.Int16Dtype(),\n    \"deviceCategory\": pd.StringDtype(),\n}\n\n\ndf = df.astype(dtypes_dict)\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 92551 entries, 0 to 92858\nData columns (total 31 columns):\n #   Column                         Non-Null Count  Dtype         \n---  ------                         --------------  -----         \n 0   fullvisitorid                  92551 non-null  string        \n 1   visitId                        92551 non-null  string        \n 2   visitNumber                    92551 non-null  Int8          \n 3   visitStartTime                 92551 non-null  datetime64[ns]\n 4   country                        92551 non-null  string        \n 5   quarter                        92551 non-null  Int8          \n 6   month                          92551 non-null  Int8          \n 7   day_of_month                   92551 non-null  Int8          \n 8   day_of_week                    92551 non-null  Int8          \n 9   hour                           92551 non-null  Int8          \n 10  minute                         92551 non-null  Int8          \n 11  second                         92551 non-null  Int8          \n 12  source                         92551 non-null  string        \n 13  medium                         92551 non-null  string        \n 14  channelGrouping                92551 non-null  string        \n 15  hits                           92551 non-null  Int16         \n 16  bounces                        92551 non-null  Int16         \n 17  last_action                    92551 non-null  Int8          \n 18  product_detail_views           92551 non-null  Int16         \n 19  promos_displayed               92551 non-null  Int16         \n 20  promos_clicked                 92551 non-null  Int16         \n 21  product_views                  92551 non-null  Int16         \n 22  product_clicks                 92551 non-null  Int16         \n 23  pageviews                      92551 non-null  Int16         \n 24  transact_revenue               3091 non-null   Float32       \n 25  time_on_site                   92551 non-null  Int16         \n 26  browser                        92551 non-null  string        \n 27  os                             92551 non-null  string        \n 28  deviceCategory                 92551 non-null  string        \n 29  added_to_cart                  92551 non-null  Int16         \n 30  made_purchase_on_future_visit  92551 non-null  boolean       \ndtypes: Float32(1), Int16(10), Int8(9), boolean(1), datetime64[ns](1), string(9)\nmemory usage: 12.6 MB\n\n\n\n\nSeparate Columns by Type\nThe first three rows of the prepared data are shown below\n\n\nCode\nwith pd.option_context(\n    \"display.max_colwidth\", None, \"display.max_rows\", None, \"display.max_columns\", None\n):\n    display(df.head(3))\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n0\n483329569933708956\n1477437687\n1\n2016-10-25 19:21:27\nUnited States\n4\n10\n25\n3\n19\n21\n27\ngoogle\norganic\nOrganic Search\n6\n0\n0\n0\n0\n0\n0\n0\n6\n&lt;NA&gt;\n602\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n1\n9534112552538425546\n1476671570\n1\n2016-10-16 22:32:50\nUnited States\n4\n10\n16\n1\n22\n32\n50\nyoutube.com\nreferral\nSocial\n6\n0\n0\n0\n54\n0\n0\n0\n1\n&lt;NA&gt;\n270\nOpera\nWindows\ndesktop\n0\nFalse\n\n\n2\n4648924122067625674\n1475958245\n1\n2016-10-08 16:24:05\nUnited States\n4\n10\n8\n7\n16\n24\n5\nyoutube.com\nreferral\nSocial\n5\n0\n0\n0\n36\n0\n4\n0\n2\n&lt;NA&gt;\n198\nOpera\nWindows\ndesktop\n0\nFalse\n\n\n\n\n\n\n\nCreate lists of columns based on their type. Three such lists are shown below\n\ndatetime\ncategorical\nnumerical\n\n\ndatetime_columns = [\n    \"quarter\",\n    \"month\",\n    \"day_of_month\",\n    \"day_of_week\",\n    \"hour\",\n]\ncategorical_columns = [\n    \"bounces\",\n    \"last_action\",\n    \"source\",\n    \"medium\",\n    \"channelGrouping\",\n    \"browser\",\n    \"os\",\n    \"deviceCategory\",\n]\nnumerical_columns = [\n    \"hits\",\n    \"product_detail_views\",\n    \"promos_displayed\",\n    \"promos_clicked\",\n    \"product_views\",\n    \"product_clicks\",\n    \"pageviews\",\n    \"time_on_site\",\n    \"added_to_cart\",\n]\n\n\n\nHandling Categorical Columns\nHigh-cardinality categorical features are a problem for machine learning models as they create a large number of dummy variables (after dummy encoding), or a sparse matrix (1, 2) that slows ML model training. So, it is frequently necessary to reduce this cardinality before training a ML model.\nTwo of the well-known apprroaches to reduce dimensionality of such features are (1, 2)\n\nfrequency endoding\n\nonly keep the N most common values for each feature and replace all the other (infrequently occurring) values with a placeholder value such as other\nthis will be the approach used for the current project\n\nclass label or target encoding\n\ngroup categorical features by the class labels (the dependent variable, or y)\n\n\nReducing the cardinality of such features is performed during the data transformation step of a ML workflow. Here, we will demonstrate this before exploratory data analysis (this step) and then apply it during data transformation (next step).\nShow the number of unique values in all categorical columns\n\ndf_nunique = pd.DataFrame.from_records(\n    [{\"column\": c, \"num_unique_values\": df[c].nunique()} for c in categorical_columns]\n)\ndf_nunique\n\n\n\n\n\n\n\n\ncolumn\nnum_unique_values\n\n\n\n\n0\nbounces\n2\n\n\n1\nlast_action\n7\n\n\n2\nsource\n116\n\n\n3\nmedium\n7\n\n\n4\nchannelGrouping\n8\n\n\n5\nbrowser\n26\n\n\n6\nos\n15\n\n\n7\ndeviceCategory\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nHigh-cardinality categorical columns are present in the training data.\nThe following categorical columns are high-cardinality columns with the largest number of unique values\n\nsource (source of visitor traffic reaching the merchandise store’s website)\nbrowser\nos (visitor’s operating system used to access merchandise store’s website)\n\nand will likely need to be binned or grouped\nInfrequently occurring values in the following medium-cardinality columns related the source of website visitor traffic will also be grouped\n\nchannelGrouping\nmedium\n\nlast_action will be left unchanged\n\nit is likely that the last action performed by a visitor during their first visit to the merchandise store will have some influence on their probability (propensity) to make a purchase during a future visit\n\n\n\n\nThe category distributions (frequencies) after grouping are shown below for all categorical columns (including those that were grouped)\n\ndfs_cats_groups = []\nfor c in categorical_columns:\n    # get fraction of unique values\n    df_frequencies = (\n        df[c]\n        .value_counts()\n        .rename(\"number_of_visitors\")\n        .to_frame()\n        .merge(\n            (\n                df[c].value_counts(normalize=True).rename(\"fraction_of_visitors\") * 100\n            ).to_frame(),\n            left_index=True,\n            right_index=True,\n        )\n    )\n\n    # map unique values for last_action and bounces to get meaningful names\n    if c == \"last_action\":\n        df_frequencies.index = df_frequencies.index.map(mapper)\n    if c == \"bounces\":\n        df_frequencies.index = df_frequencies.index.map({0: False, 1: True})\n\n    # get running total of fraction (cumulative sum)\n    df_frequencies = (\n        df_frequencies.sort_values(by=[\"fraction_of_visitors\"])\n        .assign(\n            cumulative_fraction_of_visitors=lambda df: df[\n                \"fraction_of_visitors\"\n            ].cumsum(),\n            column_name=c,\n        )\n        .sort_values(by=[\"fraction_of_visitors\"], ascending=False)\n    )\n\n    # rename columns\n    df_frequencies = df_frequencies.reset_index().rename(columns={c: \"column_value\"})\n    dfs_cats_groups.append(df_frequencies)\ndf_frequencies_raw = pd.concat(dfs_cats_groups, ignore_index=True)\ncol = df_frequencies_raw.pop(\"column_name\")\ndf_frequencies_raw.insert(0, col.name, col)\nwith pd.option_context(\"display.max_rows\", None):\n    display(df_frequencies_raw)\n\n\n\n\n\n\n\n\ncolumn_name\ncolumn_value\nnumber_of_visitors\nfraction_of_visitors\ncumulative_fraction_of_visitors\n\n\n\n\n0\nbounces\nFalse\n65500\n70.771791\n100.0\n\n\n1\nbounces\nTrue\n27051\n29.228209\n29.228209\n\n\n2\nlast_action\nUnknown\n67519\n72.953291\n100.0\n\n\n3\nlast_action\nProduct detail views\n14720\n15.904744\n27.046709\n\n\n4\nlast_action\nAdd product(s) to cart\n4663\n5.038303\n11.141965\n\n\n5\nlast_action\nCompleted purchase\n3094\n3.343022\n6.103662\n\n\n6\nlast_action\nCheck out\n1632\n1.763352\n2.76064\n\n\n7\nlast_action\nRemove product(s) from cart\n882\n0.952988\n0.997288\n\n\n8\nlast_action\nClick through of product lists\n41\n0.0443\n0.0443\n\n\n9\nsource\ngoogle\n43478\n46.977342\n100.0\n\n\n10\nsource\n(direct)\n21539\n23.272574\n53.022658\n\n\n11\nsource\nmall.googleplex.com\n11776\n12.723796\n29.750084\n\n\n12\nsource\nyoutube.com\n8021\n8.666573\n17.026288\n\n\n13\nsource\nsites.google.com\n1098\n1.186373\n8.359715\n\n\n14\nsource\nmoma.corp.google.com\n1040\n1.123705\n7.173342\n\n\n15\nsource\nPartners\n899\n0.971356\n6.049637\n\n\n16\nsource\ndfa\n842\n0.909769\n5.078281\n\n\n17\nsource\nsiliconvalley.about.com\n593\n0.640728\n4.168512\n\n\n18\nsource\nanalytics.google.com\n485\n0.524035\n3.527785\n\n\n19\nsource\ngoogle.com\n413\n0.44624\n3.003749\n\n\n20\nsource\nbaidu\n314\n0.339272\n2.557509\n\n\n21\nsource\nm.facebook.com\n190\n0.205292\n2.218236\n\n\n22\nsource\nyahoo\n178\n0.192326\n2.012944\n\n\n23\nsource\nbing\n161\n0.173958\n1.820618\n\n\n24\nsource\nreddit.com\n131\n0.141544\n1.64666\n\n\n25\nsource\nl.facebook.com\n127\n0.137222\n1.505116\n\n\n26\nsource\ngroups.google.com\n120\n0.129658\n1.367894\n\n\n27\nsource\nfacebook.com\n112\n0.121014\n1.238236\n\n\n28\nsource\nmail.google.com\n110\n0.118853\n1.117222\n\n\n29\nsource\ngoogleux.perksplus.com\n95\n0.102646\n0.998368\n\n\n30\nsource\nquora.com\n86\n0.092922\n0.895722\n\n\n31\nsource\nblog.golang.org\n82\n0.0886\n0.802801\n\n\n32\nsource\nt.co\n80\n0.086439\n0.714201\n\n\n33\nsource\ndealspotr.com\n74\n0.079956\n0.627762\n\n\n34\nsource\nask\n48\n0.051863\n0.547806\n\n\n35\nsource\ndocs.google.com\n39\n0.042139\n0.495943\n\n\n36\nsource\nconnect.googleforwork.com\n33\n0.035656\n0.453804\n\n\n37\nsource\nplus.google.com\n21\n0.02269\n0.418148\n\n\n38\nsource\noutlook.live.com\n20\n0.02161\n0.395458\n\n\n39\nsource\ntpc.googlesyndication.com\n19\n0.020529\n0.373848\n\n\n40\nsource\nm.reddit.com\n18\n0.019449\n0.353319\n\n\n41\nsource\nphandroid.com\n17\n0.018368\n0.33387\n\n\n42\nsource\nsearch.xfinity.com\n17\n0.018368\n0.315502\n\n\n43\nsource\nlearn.colorado.edu\n13\n0.014046\n0.297133\n\n\n44\nsource\ngoogleads.g.doubleclick.net\n12\n0.012966\n0.283087\n\n\n45\nsource\nm.baidu.com\n12\n0.012966\n0.270121\n\n\n46\nsource\nproductforums.google.com\n11\n0.011885\n0.257156\n\n\n47\nsource\nlunametrics.com\n11\n0.011885\n0.24527\n\n\n48\nsource\narstechnica.com\n10\n0.010805\n0.211775\n\n\n49\nsource\npinterest.com\n10\n0.010805\n0.22258\n\n\n50\nsource\nduckduckgo.com\n10\n0.010805\n0.233385\n\n\n51\nsource\nsearch.tb.ask.com\n9\n0.009724\n0.20097\n\n\n52\nsource\nus.search.yahoo.com\n9\n0.009724\n0.191246\n\n\n53\nsource\nplus.sandbox.google.com\n8\n0.008644\n0.181522\n\n\n54\nsource\nuweoconnect.extn.washington.edu\n7\n0.007563\n0.172878\n\n\n55\nsource\ncourse.fso.fullsail.edu\n6\n0.006483\n0.165314\n\n\n56\nsource\nmg.mail.yahoo.com\n6\n0.006483\n0.158831\n\n\n57\nsource\ntrainup.withgoogle.com\n6\n0.006483\n0.152348\n\n\n58\nsource\nluyaochen.mtv.corp.google.com:8080\n6\n0.006483\n0.145866\n\n\n59\nsource\nplus.url.google.com\n5\n0.005402\n0.139383\n\n\n60\nsource\nwap.sogou.com\n5\n0.005402\n0.13398\n\n\n61\nsource\ngophergala.com\n5\n0.005402\n0.128578\n\n\n62\nsource\ncsfirst.withgoogle.com\n4\n0.004322\n0.118853\n\n\n63\nsource\nm.sogou.com\n4\n0.004322\n0.11021\n\n\n64\nsource\naol\n4\n0.004322\n0.123175\n\n\n65\nsource\namazon.com\n4\n0.004322\n0.114531\n\n\n66\nsource\ndrawnames.com\n4\n0.004322\n0.105888\n\n\n67\nsource\ngithub.com\n4\n0.004322\n0.097244\n\n\n68\nsource\ndynamite.sandbox.google.com\n4\n0.004322\n0.092922\n\n\n69\nsource\nkeep.google.com\n4\n0.004322\n0.0886\n\n\n70\nsource\nhangouts.google.com\n4\n0.004322\n0.084278\n\n\n71\nsource\nfeedly.com\n4\n0.004322\n0.079956\n\n\n72\nsource\nsearch.earthlink.net\n4\n0.004322\n0.101566\n\n\n73\nsource\ns0.2mdn.net\n3\n0.003241\n0.056185\n\n\n74\nsource\nqiita.com\n3\n0.003241\n0.062668\n\n\n75\nsource\nweb.mail.comcast.net\n3\n0.003241\n0.059427\n\n\n76\nsource\nmessenger.com\n3\n0.003241\n0.06591\n\n\n77\nsource\noptimize.google.com\n3\n0.003241\n0.069151\n\n\n78\nsource\nus-mg5.mail.yahoo.com\n3\n0.003241\n0.072393\n\n\n79\nsource\nics-devel-west.qa.adz.google.com\n3\n0.003241\n0.075634\n\n\n80\nsource\nm.mg.mail.yahoo.com\n2\n0.002161\n0.052944\n\n\n81\nsource\n(not set)\n2\n0.002161\n0.050783\n\n\n82\nsource\nso.com\n2\n0.002161\n0.048622\n\n\n83\nsource\nawics.corp.google.com\n2\n0.002161\n0.046461\n\n\n84\nsource\nadwords.google.com\n1\n0.00108\n0.017288\n\n\n85\nsource\ninbox.google.com\n1\n0.00108\n0.015127\n\n\n86\nsource\nus.reddit.com\n1\n0.00108\n0.016207\n\n\n87\nsource\nblackboard.neu.edu\n1\n0.00108\n0.002161\n\n\n88\nsource\nkik.com\n1\n0.00108\n0.018368\n\n\n89\nsource\n0.shared.bow.cat2.ads-bow.qk.borg.google.com:9830\n1\n0.00108\n0.019449\n\n\n90\nsource\nonline-metrics.com\n1\n0.00108\n0.020529\n\n\n91\nsource\n0.shared.bow.cat2.ads-bow.lf.borg.google.com:9860\n1\n0.00108\n0.012966\n\n\n92\nsource\n0.shared.bow.cat2.ads-bow.yw.borg.google.com:9885\n1\n0.00108\n0.014046\n\n\n93\nsource\nwheretoget.it\n1\n0.00108\n0.003241\n\n\n94\nsource\ngetpocket.com\n1\n0.00108\n0.011885\n\n\n95\nsource\n0.shared.bow.cat2.ads-bow.qk.borg.google.com:9848\n1\n0.00108\n0.010805\n\n\n96\nsource\ng3doc.corp.google.com\n1\n0.00108\n0.009724\n\n\n97\nsource\nmail.aol.com\n1\n0.00108\n0.008644\n\n\n98\nsource\nwanelo.com\n1\n0.00108\n0.007563\n\n\n99\nsource\nmail.verizon.com\n1\n0.00108\n0.006483\n\n\n100\nsource\nm.sp.sm.cn\n1\n0.00108\n0.005402\n\n\n101\nsource\ngoto.google.com\n1\n0.00108\n0.004322\n\n\n102\nsource\npinpoint.corp.google.com\n1\n0.00108\n0.02269\n\n\n103\nsource\n9to5google.com\n1\n0.00108\n0.02161\n\n\n104\nsource\nbaidu.com\n1\n0.00108\n0.032415\n\n\n105\nsource\nadwords-displayads.googleusercontent.com\n1\n0.00108\n0.023771\n\n\n106\nsource\nxbidprodmirror.corp.google.com\n1\n0.00108\n0.024851\n\n\n107\nsource\nmyactivity.google.com\n1\n0.00108\n0.0443\n\n\n108\nsource\nprod.facebook.com\n1\n0.00108\n0.043219\n\n\n109\nsource\nlogin.corp.google.com\n1\n0.00108\n0.042139\n\n\n110\nsource\nsearchlock.com\n1\n0.00108\n0.041058\n\n\n111\nsource\nnewclasses.nyu.edu\n1\n0.00108\n0.039978\n\n\n112\nsource\ndailydot.com\n1\n0.00108\n0.038897\n\n\n113\nsource\nbusinessinsider.com\n1\n0.00108\n0.037817\n\n\n114\nsource\nlm.facebook.com\n1\n0.00108\n0.036737\n\n\n115\nsource\ncl-cards.googleplex.com\n1\n0.00108\n0.035656\n\n\n116\nsource\nspaces.google.com\n1\n0.00108\n0.034576\n\n\n117\nsource\nevernote.com\n1\n0.00108\n0.033495\n\n\n118\nsource\n0.shared.bow.cat2.ads-bow.yw.borg.google.com:9813\n1\n0.00108\n0.031334\n\n\n119\nsource\ndigg.com\n1\n0.00108\n0.030254\n\n\n120\nsource\ngoogle.co.jp\n1\n0.00108\n0.029173\n\n\n121\nsource\n0.shared.bow.cat2.ads-bow.yw.borg.google.com:9849\n1\n0.00108\n0.028093\n\n\n122\nsource\nseroundtable.com\n1\n0.00108\n0.027012\n\n\n123\nsource\ncases.corp.google.com\n1\n0.00108\n0.025932\n\n\n124\nsource\n0.shared.bow.cat2.ads-bow.yw.borg.google.com:9850\n1\n0.00108\n0.00108\n\n\n125\nmedium\norganic\n38580\n41.685125\n100.0\n\n\n126\nmedium\nreferral\n25084\n27.102895\n58.314875\n\n\n127\nmedium\n(none)\n21539\n23.272574\n31.21198\n\n\n128\nmedium\ncpc\n5605\n6.05612\n7.939406\n\n\n129\nmedium\naffiliate\n899\n0.971356\n1.883286\n\n\n130\nmedium\ncpm\n842\n0.909769\n0.91193\n\n\n131\nmedium\n(not set)\n2\n0.002161\n0.002161\n\n\n132\nchannelGrouping\nOrganic Search\n38580\n41.685125\n100.0\n\n\n133\nchannelGrouping\nDirect\n21539\n23.272574\n58.314875\n\n\n134\nchannelGrouping\nReferral\n16158\n17.458482\n35.042301\n\n\n135\nchannelGrouping\nSocial\n8926\n9.644412\n17.583819\n\n\n136\nchannelGrouping\nPaid Search\n5605\n6.05612\n7.939406\n\n\n137\nchannelGrouping\nAffiliates\n899\n0.971356\n1.883286\n\n\n138\nchannelGrouping\nDisplay\n842\n0.909769\n0.91193\n\n\n139\nchannelGrouping\n(Other)\n2\n0.002161\n0.002161\n\n\n140\nbrowser\nChrome\n69001\n74.55457\n100.0\n\n\n141\nbrowser\nSafari\n15294\n16.524943\n25.44543\n\n\n142\nbrowser\nFirefox\n2594\n2.802779\n8.920487\n\n\n143\nbrowser\nInternet Explorer\n2214\n2.392195\n6.117708\n\n\n144\nbrowser\nOpera\n1119\n1.209063\n3.725514\n\n\n145\nbrowser\nEdge\n989\n1.0686\n2.51645\n\n\n146\nbrowser\nSafari (in-app)\n799\n0.863308\n1.44785\n\n\n147\nbrowser\nAndroid Webview\n166\n0.179361\n0.584543\n\n\n148\nbrowser\nYaBrowser\n107\n0.115612\n0.405182\n\n\n149\nbrowser\nAmazon Silk\n93\n0.100485\n0.28957\n\n\n150\nbrowser\nMozilla Compatible Agent\n31\n0.033495\n0.189085\n\n\n151\nbrowser\nUC Browser\n28\n0.030254\n0.15559\n\n\n152\nbrowser\nOpera Mini\n19\n0.020529\n0.125336\n\n\n153\nbrowser\nAndroid Browser\n16\n0.017288\n0.104807\n\n\n154\nbrowser\nIron\n15\n0.016207\n0.087519\n\n\n155\nbrowser\nCoc Coc\n13\n0.014046\n0.071312\n\n\n156\nbrowser\nNintendo Browser\n13\n0.014046\n0.057266\n\n\n157\nbrowser\nBlackBerry\n10\n0.010805\n0.043219\n\n\n158\nbrowser\nMaxthon\n10\n0.010805\n0.032415\n\n\n159\nbrowser\nMRCHROME\n7\n0.007563\n0.02161\n\n\n160\nbrowser\nNichrome\n5\n0.005402\n0.014046\n\n\n161\nbrowser\nApple-iPhone7C2\n3\n0.003241\n0.008644\n\n\n162\nbrowser\nMozilla\n2\n0.002161\n0.005402\n\n\n163\nbrowser\nNokiaE52-1\n1\n0.00108\n0.002161\n\n\n164\nbrowser\nSeaMonkey\n1\n0.00108\n0.003241\n\n\n165\nbrowser\nno-ua\n1\n0.00108\n0.00108\n\n\n166\nos\nMacintosh\n30610\n33.073657\n100.0\n\n\n167\nos\nWindows\n25588\n27.647459\n66.926343\n\n\n168\nos\niOS\n13500\n14.586552\n39.278884\n\n\n169\nos\nAndroid\n11486\n12.410455\n24.692332\n\n\n170\nos\nLinux\n6500\n7.023155\n12.281877\n\n\n171\nos\nChrome OS\n4741\n5.122581\n5.258722\n\n\n172\nos\n(not set)\n53\n0.057266\n0.136141\n\n\n173\nos\nWindows Phone\n39\n0.042139\n0.078875\n\n\n174\nos\nNintendo Wii\n11\n0.011885\n0.036737\n\n\n175\nos\nBlackBerry\n10\n0.010805\n0.024851\n\n\n176\nos\nXbox\n9\n0.009724\n0.014046\n\n\n177\nos\nNokia\n1\n0.00108\n0.00108\n\n\n178\nos\nSamsung\n1\n0.00108\n0.002161\n\n\n179\nos\nFreeBSD\n1\n0.00108\n0.003241\n\n\n180\nos\nSunOS\n1\n0.00108\n0.004322\n\n\n181\ndeviceCategory\ndesktop\n67355\n72.776091\n100.0\n\n\n182\ndeviceCategory\nmobile\n21790\n23.543776\n27.223909\n\n\n183\ndeviceCategory\ntablet\n3406\n3.680133\n3.680133\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nWe’ll create frequency groupings as follows\n\nsource and browser\n\nall categories which occur with a frequency of less than 5% will be grouped into a single value other\n\nos, channelGrouping and medium\n\nall categories which occur with a frequency of less than 10% will be grouped into a single value other\n\n\nThese thresholds were determined by examining the output of df_frequencies_raw, which shows the freqencies of all categories for all categorical columns.\n\n\n\nBelow are lists of categorical columns to be grouped based on this threshold (5% or 10%)\n\ncols_to_group_5_pct = [\"source\", \"browser\"]\ncols_to_group_10_pct = [\"os\", \"channelGrouping\", \"medium\"]\n\nWe’ll get names for the columns after grouping, by adding a _grouped suffix\n\ngrouped_cols_5_pct = [f\"{c}_grouped\" for c in cols_to_group_5_pct]\ngrouped_cols_10_pct = [f\"{c}_grouped\" for c in cols_to_group_10_pct]\n\nNext, create lists of categorical columns that will and will not be grouped and then combine them into a single list\n\ncategorical_columns_mapped = (\n    # columns that will not be grouped\n    list(\n        set(categorical_columns) - set(cols_to_group_5_pct) - set(cols_to_group_10_pct)\n    )\n    # columns that will be grouped\n    + grouped_cols_5_pct\n    + grouped_cols_10_pct\n)\n\nCreate a duplicate of the columns that will be grouped and add a _grouped suffix to their column name\n\nfor c in cols_to_group_5_pct + cols_to_group_10_pct:\n    df[f\"{c}_grouped\"] = df[c]\n\nFinally, perform the grouping using\n\npandas.value_counts(normalize=True) &lt; 0.05 (5% threshold)\npandas.value_counts(normalize=True) &lt; 0.10 (10% threshold)\n\nwhere all infrequently occurring values that satisfy these filters will have their values replaced by other\n\ndf[grouped_cols_5_pct] = df[grouped_cols_5_pct].apply(\n    lambda x: x.mask(x.map(x.value_counts(normalize=True)) &lt; 0.05, \"other\"), axis=0\n)\ndf[grouped_cols_10_pct] = df[grouped_cols_10_pct].apply(\n    lambda x: x.mask(x.map(x.value_counts(normalize=True)) &lt; 0.10, \"other\"), axis=0\n)\n\nThe cardinality of the columns before and after grouping is shown below\n\ndf_nunique.merge(\n    pd.DataFrame.from_records(\n        [\n            {\n                \"column\": c.replace(\"_grouped\", \"\"),\n                \"column_grouped\": c,\n                \"num_unique_values_after_grouping\": df[c].nunique(),\n            }\n            for c in categorical_columns_mapped\n        ]\n    ).assign(column_grouped=lambda df: df[\"column_grouped\"] != df[\"column\"]),\n    on=[\"column\"],\n    how=\"left\",\n)\n\n\n\n\n\n\n\n\ncolumn\nnum_unique_values\ncolumn_grouped\nnum_unique_values_after_grouping\n\n\n\n\n0\nbounces\n2\nFalse\n2\n\n\n1\nlast_action\n7\nFalse\n7\n\n\n2\nsource\n116\nTrue\n5\n\n\n3\nmedium\n7\nTrue\n4\n\n\n4\nchannelGrouping\n8\nTrue\n4\n\n\n5\nbrowser\n26\nTrue\n3\n\n\n6\nos\n15\nTrue\n5\n\n\n7\ndeviceCategory\n3\nFalse\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe cardinality has been significantly reduced for the columns where the infrequently occurring values were grouped (column_grouped == True).\nThe cardinality is unchanged for the columns where the infrequently occurring values were not grouped (column_grouped == False).\n\n\n\nThe category distributions (frequencies) after grouping are shown below for all categorical columns (including those that were grouped)\n\ndfs_cats_groups = []\nfor c in categorical_columns_mapped:\n    # get fraction of unique values\n    df_frequencies = (\n        df[c]\n        .value_counts()\n        .rename(\"number_of_visitors\")\n        .to_frame()\n        .merge(\n            (\n                df[c].value_counts(normalize=True).rename(\"fraction_of_visitors\") * 100\n            ).to_frame(),\n            left_index=True,\n            right_index=True,\n        )\n    )\n\n    # map unique values for last_action and bounces to get meaningful names\n    if c == \"last_action\":\n        df_frequencies.index = df_frequencies.index.map(mapper)\n    if c == \"bounces\":\n        df_frequencies.index = df_frequencies.index.map({0: False, 1: True})\n\n    # get running total of fraction (cumulative sum)\n    df_frequencies = (\n        df_frequencies.sort_values(by=[\"fraction_of_visitors\"])\n        .assign(\n            cumulative_fraction_of_visitors=lambda df: df[\n                \"fraction_of_visitors\"\n            ].cumsum(),\n            column_name=c,\n        )\n        .sort_values(by=[\"fraction_of_visitors\"], ascending=False)\n    )\n\n    # rename columns\n    df_frequencies = df_frequencies.reset_index().rename(columns={c: \"column_value\"})\n    dfs_cats_groups.append(df_frequencies)\ndf_frequencies_grouped = pd.concat(dfs_cats_groups, ignore_index=True)\ncol = df_frequencies_grouped.pop(\"column_name\")\ndf_frequencies_grouped.insert(0, col.name, col)\nwith pd.option_context(\"display.max_rows\", None):\n    display(df_frequencies_grouped)\n\n\n\n\n\n\n\n\ncolumn_name\ncolumn_value\nnumber_of_visitors\nfraction_of_visitors\ncumulative_fraction_of_visitors\n\n\n\n\n0\nlast_action\nUnknown\n67519\n72.953291\n100.0\n\n\n1\nlast_action\nProduct detail views\n14720\n15.904744\n27.046709\n\n\n2\nlast_action\nAdd product(s) to cart\n4663\n5.038303\n11.141965\n\n\n3\nlast_action\nCompleted purchase\n3094\n3.343022\n6.103662\n\n\n4\nlast_action\nCheck out\n1632\n1.763352\n2.76064\n\n\n5\nlast_action\nRemove product(s) from cart\n882\n0.952988\n0.997288\n\n\n6\nlast_action\nClick through of product lists\n41\n0.0443\n0.0443\n\n\n7\nbounces\nFalse\n65500\n70.771791\n100.0\n\n\n8\nbounces\nTrue\n27051\n29.228209\n29.228209\n\n\n9\ndeviceCategory\ndesktop\n67355\n72.776091\n100.0\n\n\n10\ndeviceCategory\nmobile\n21790\n23.543776\n27.223909\n\n\n11\ndeviceCategory\ntablet\n3406\n3.680133\n3.680133\n\n\n12\nsource_grouped\ngoogle\n43478\n46.977342\n100.0\n\n\n13\nsource_grouped\n(direct)\n21539\n23.272574\n53.022658\n\n\n14\nsource_grouped\nmall.googleplex.com\n11776\n12.723796\n29.750084\n\n\n15\nsource_grouped\nyoutube.com\n8021\n8.666573\n17.026288\n\n\n16\nsource_grouped\nother\n7737\n8.359715\n8.359715\n\n\n17\nbrowser_grouped\nChrome\n69001\n74.55457\n100.0\n\n\n18\nbrowser_grouped\nSafari\n15294\n16.524943\n25.44543\n\n\n19\nbrowser_grouped\nother\n8256\n8.920487\n8.920487\n\n\n20\nos_grouped\nMacintosh\n30610\n33.073657\n100.0\n\n\n21\nos_grouped\nWindows\n25588\n27.647459\n66.926343\n\n\n22\nos_grouped\niOS\n13500\n14.586552\n39.278884\n\n\n23\nos_grouped\nAndroid\n11486\n12.410455\n24.692332\n\n\n24\nos_grouped\nother\n11367\n12.281877\n12.281877\n\n\n25\nchannelGrouping_grouped\nOrganic Search\n38580\n41.685125\n100.0\n\n\n26\nchannelGrouping_grouped\nDirect\n21539\n23.272574\n58.314875\n\n\n27\nchannelGrouping_grouped\nother\n16274\n17.583819\n35.042301\n\n\n28\nchannelGrouping_grouped\nReferral\n16158\n17.458482\n17.458482\n\n\n29\nmedium_grouped\norganic\n38580\n41.685125\n100.0\n\n\n30\nmedium_grouped\nreferral\n25084\n27.102895\n58.314875\n\n\n31\nmedium_grouped\n(none)\n21539\n23.272574\n31.21198\n\n\n32\nmedium_grouped\nother\n7348\n7.939406\n7.939406\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nThese distributions are shown here after frequency encoding (grouping) the high-cardinality columns in order to determine the thresholds (5% and 10%) for replacing infrequently occurring values in these columns. Earlier, the same was shown in the raw categorical columns. In that DataFrame, there were 184 unique categories across all categorical columns (length of df_frequencies_raw). After dummy encoding (where we will drop duplicate categories in each raw categorical column - 1), there would be 184 - &lt;number-of-categorical-columns&gt; = 184 - 8 = 176 features.\nAfter frequency grouping (where we will drop duplicate categories in each grouped categorical column), there are 33 unique categories. After dummy encoding, the number of dummy variables will be 33 - &lt;number-of-categorical-columns&gt; = 33 - 8 = 26 features. This frequency encoding approach has reduced the cardinality by (176 - 26) / 176 = 0.86 (or 86%).\n\n\n\nThe reduction in cardinality of the categorical feaures, after frequency grouping, is calculated below\n\nfrac_reduction_in_cats_cardinality = (\n    100\n    * (\n        (len(df_frequencies_raw) - len(categorical_columns))\n        - (len(df_frequencies_grouped) - len(categorical_columns))\n    )\n    / (len(df_frequencies_raw) - len(categorical_columns))\n)\nprint(\n    \"Frequency encoding (grouping) has reduced cardinality of categorical features by \"\n    f\"{frac_reduction_in_cats_cardinality:,.3f}%\"\n)\n\nFrequency encoding (grouping) has reduced cardinality of categorical features by 85.795%\n\n\nThe groupings above have been learnt from the training data. We now need to create a lookup table for columns that were grouped so that we can apply the same groupings to unseen data (validation and test data splits). This means when we encounter the same infrequently occurring values in the validation and test data splits, they will be replaced by other.\nThis lookup table is defined below\n\ndf_groupings = pd.DataFrame.from_dict(\n    {\n        c: df[c]\n        .value_counts(normalize=True)\n        .rename(\"fraction\")\n        .to_frame()\n        .query(f\"fraction &lt; {threshold}\")\n        .index.tolist()\n        for cols, threshold in zip(\n            [cols_to_group_5_pct, cols_to_group_10_pct], [0.05, 0.10]\n        )\n        for c in cols\n    },\n    orient=\"index\",\n).transpose()\ndisplay(df_groupings.head())\ndisplay(df_groupings.tail())\n\n\n\n\n\n\n\n\nsource\nbrowser\nos\nchannelGrouping\nmedium\n\n\n\n\n0\nsites.google.com\nFirefox\nLinux\nSocial\ncpc\n\n\n1\nmoma.corp.google.com\nInternet Explorer\nChrome OS\nPaid Search\naffiliate\n\n\n2\nPartners\nOpera\n(not set)\nAffiliates\ncpm\n\n\n3\ndfa\nEdge\nWindows Phone\nDisplay\n(not set)\n\n\n4\nsiliconvalley.about.com\nSafari (in-app)\nNintendo Wii\n(Other)\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\nbrowser\nos\nchannelGrouping\nmedium\n\n\n\n\n107\nseroundtable.com\nNone\nNone\nNone\nNone\n\n\n108\ncases.corp.google.com\nNone\nNone\nNone\nNone\n\n\n109\nspaces.google.com\nNone\nNone\nNone\nNone\n\n\n110\nsearchlock.com\nNone\nNone\nNone\nNone\n\n\n111\n0.shared.bow.cat2.ads-bow.yw.borg.google.com:9850\nNone\nNone\nNone\nNone\n\n\n\n\n\n\n\nWe’ll also create a lookup table of unique values in the categorical columns that were not grouped. When we encounter these values in the validation or test data splits, they will remain unchanged.\nThis lookup table is defined below\n\ndf_ungrouped = pd.DataFrame.from_dict(\n    {\n        c: df[c]\n        .value_counts(normalize=True)\n        .rename(\"fraction\")\n        .to_frame()\n        .query(f\"fraction &gt;= {threshold}\")\n        .index.tolist()\n        for cols, threshold in zip(\n            [cols_to_group_5_pct, cols_to_group_10_pct], [0.05, 0.10]\n        )\n        for c in cols\n    },\n    orient=\"index\",\n).transpose()\ndf_ungrouped\n\n\n\n\n\n\n\n\nsource\nbrowser\nos\nchannelGrouping\nmedium\n\n\n\n\n0\ngoogle\nChrome\nMacintosh\nOrganic Search\norganic\n\n\n1\n(direct)\nSafari\nWindows\nDirect\nreferral\n\n\n2\nmall.googleplex.com\nNone\niOS\nReferral\n(none)\n\n\n3\nyoutube.com\nNone\nAndroid\nNone\nNone\n\n\n\n\n\n\n\nFor a quick demonstration of using these two lookup tables, we’ll create a dummy validation data DataFrame below with two categorical features\n\n\nCode\ndf_val = pd.DataFrame.from_records(\n    [\n        {\"source\": \"Partners\", \"browser\": \"Internet Explorer\"},\n        {\"source\": \"dfa\", \"browser\": \"new-browser\"},\n        {\"source\": \"new-source-value\", \"browser\": \"Chrome\"},\n    ]\n)\ndf_val\n\n\n\n\n\n\n\n\n\nsource\nbrowser\n\n\n\n\n0\nPartners\nInternet Explorer\n\n\n1\ndfa\nnew-browser\n\n\n2\nnew-source-value\nChrome\n\n\n\n\n\n\n\nWe’ll now apply both the lookup tables defined above using the following approach\n\nfor all columns that were grouped, create columns with a suffix _grouped which contains the value other for infrequently occurring values\nfor all columns that were not grouped, create columns with a suffix _ungrouped which contains the same values with no changes\ncombine columns with the _ungrouped and _grouped suffixes into a single column column\n\nto do this, fill missing values in the _grouped column with those in the _ungrouped column\n\ndrop original columns and rename the combined columns appropriately\n\n\ncategorical_columns_validation_data = [\"source\", \"browser\"]\nfor c in categorical_columns_validation_data:\n    # 1. replace infrequent values in columns that were grouped (add suffix _grouped)\n    df_val[f\"{c}_grouped\"] = df_val[c].map(\n        {c_grouped: \"other\" for c_grouped in df_groupings[c].tolist()}\n    )\n    # 2. keep all values in columns that were not grouped (add suffix _ungrouped)\n    df_val[f\"{c}_ungrouped\"] = df_val[c].map(\n        {c_ungrouped: c_ungrouped for c_ungrouped in df_ungrouped[c].tolist()}\n    )\n    # 3. combine columns that were replaced (_grouped) and those that were not replaced (_ungrouped)\n    df_val[f\"{c}_grouped\"] = df_val[f\"{c}_grouped\"].fillna(df_val[f\"{c}_ungrouped\"])\n# 4. drop unwanted columns and rename\ndf_val = df_val.drop(\n    columns=[\"browser_ungrouped\", \"source_ungrouped\"]\n    + categorical_columns_validation_data\n).rename(columns={f\"{c}_grouped\": c for c in categorical_columns_validation_data})\ndf_val\n\n\n\n\n\n\n\n\nsource\nbrowser\n\n\n\n\n0\nother\nother\n\n\n1\nother\nNaN\n\n\n2\nNaN\nChrome\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nIn both features of the validation data, there are new categories that were not seen in the training data. After applying the two lookup tables above, these values are replaced by Nones. We can fill these missing values using\n\nnew (or keep it as None) to indicate this is a new category\n\nthe ML model has not seen this value in the appropriate feature during training, so the predictive power of such a feature in the unseen (validation) data will likely be reduced or minimal (the model won’t know its relationship to the label y)\n\nother to group this into the infrequently occurring categories that were identified from the training data\n\nthe disadvantage is that these new categories might have a different relationship to the label label (y) than the grouped (other) category\nin such a scenario\n\nthe ML model might not able to leverage the full predictive power of such new categories in the validation (unseen) data when it makes predictions since it was not trained to learn this relationship in the training data\nthe model will make predictions based on the relationship learnt between the grouped (other) category and the label (y)\n\n\n\n\n\n\nDuring data processing (after this EDA step), we will create the training, validation and test data splits for ML development and the same workflow will be used to handle categorical features during data processing."
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#key-findings",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#key-findings",
    "title": "Data Preparation",
    "section": "Key Findings",
    "text": "Key Findings\n\nNested Attributes of First-Time Visits\n\nPromotion nested column\n\nWhen view_promo = True, a visitor has viewed a promotion. If it is not viewed, then it is None\nWhen a visitor clicks a promotion after viewing it\n\nclick_promo = True\nview_promo is NULL\n\n\nProduct nested column\n\nif a product is viewed in a listing (product_count &gt; 0) during a visit, then there are only two possible values for clicked_product and viewed_product, namely True and None\na product is not viewed in a listing, then the only value in these same two columns is None\n\n\n\n\nRecommendations for Data Processing\n\nNegligible duplicates exist for\n\nvisitId\n\nthe reason for this duplication is known\nsuch duplicates are kept in the data\n\nfullvisitorid\n\nthe reason for this duplication is not known\nall but the first of such duplicates should be dropped\n\n\nThe cardinality across the combination of all categorical columns extracted from visitors’ first visit to the store can be significantly reduced by replacing infrequently occuring values by the category other\n\nsource and browser columns\n\nall categories which occur with a frequency of less than 5% should be grouped into a single value other\n\nos, channelGrouping and medium columns\n\nall categories which occur with a frequency of less than 10% should be grouped into a single value other"
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#summary-of-assumptions",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#summary-of-assumptions",
    "title": "Data Preparation",
    "section": "Summary of Assumptions",
    "text": "Summary of Assumptions\n\nNegligible duplicates in fullvisitorid are found and are not well understood and so they should be dropped in the training, validation and test data splits during data transformation."
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#summary-of-tasks-performed",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#summary-of-tasks-performed",
    "title": "Data Preparation",
    "section": "Summary of Tasks Performed",
    "text": "Summary of Tasks Performed\nThis step has performed the following\n\nextracted attributes from dataset to create a prepared dataset for use in EDA\n\nflattened nested columns for products and promotions\nextracted columns that should intuitively help predict probability of making a purchase on a return (future) visit\n\naddressed duplicated visits\nhandled high-cardinality categorical columns"
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#limitations",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#limitations",
    "title": "Data Preparation",
    "section": "Limitations",
    "text": "Limitations\nNone."
  },
  {
    "objectID": "notebooks/02-prepare/notebooks/02_prepare.html#next-step",
    "href": "notebooks/02-prepare/notebooks/02_prepare.html#next-step",
    "title": "Data Preparation",
    "section": "Next Step",
    "text": "Next Step\nThe next step will be to perform exploratory data analysis using data prepared using the findings from this data preparation step."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html",
    "href": "notebooks/03-eda/notebooks/03_eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Import Python modules\nCode\nimport os\nfrom calendar import day_name, month_name\nfrom datetime import datetime\nfrom glob import glob\nfrom typing import Dict, List, Tuple, Union\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pytz\nimport seaborn as sns\nfrom feature_engine.encoding import RareLabelEncoder\nfrom google.oauth2 import service_account\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import Pipeline"
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#about",
    "href": "notebooks/03-eda/notebooks/03_eda.html#about",
    "title": "Exploratory Data Analysis",
    "section": "About",
    "text": "About\nThis step of the analysis explores the visit data for the Google Merchandise store on the Google Marketplace, based on learnings from the data preparation step.\n\nObjectives\nThe goals of this step in the analysis are the following\n\nexplore the prepared data to look for any underlying patterns that can be captured through features that might help ML modeling\nobserve the class imbalance of the labels (y) to get a sense of any resampling techniques that could aid the performance of a ML model\n\n\n\nDiscussion of Study Period for This Project\nSame as for data preparation.\n\n\nData Selection for EDA\nWith the above in mind, EDA in this step will cover the training data.\n\n\nBusiness Questions for EDA\nWe will explore this dataset by answering the following (non-exhaustive) set of business-relevant questions\n\nFor high-level channel, and the more fine-graned traffic source and traffic medium, get the correlation between the numerical attributes of visits and total visit revenue. Across all of these groupings of sources of web traffic arriving at the merchandise store, comment on the strongest and weakest correlations to revenue.\nWhich channels were responsible for the most first-visitors with a purchase on their return visit? Show this comparison on a chart by channel.\nIs there any one web-browser that return purchasers used on their first visit?\nDo visitors who make a purchase on their return visit to the store have a preference for the type of device they are using (desktop, mobile, etc.)?\nWhich traffic sources were responsible for the most return purchasers on weekdays and weekends?\nShow the fraction of visitors who did make a purchase on their return visit to the merchandise store by month and day of the month.\nShow the fraction of visitors who made a purchase on their return visit to the merchandise store by month and day of the week.\nShow the breakdown of total revenue earned by visitors who are return purchasers and those that are not return purchasers."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#user-inputs",
    "href": "notebooks/03-eda/notebooks/03_eda.html#user-inputs",
    "title": "Exploratory Data Analysis",
    "section": "User Inputs",
    "text": "User Inputs\nGet relative path to project root directory\n\nPROJ_ROOT_DIR = os.path.join(os.pardir)\n\nDefine the following\n\ntrain data start date\ntrain data end date\ntest data end date\n\n\ntrain_start_date = \"20160901\"\ntrain_end_date = \"20161231\"\ntest_end_date = \"20170228\"\n\n# categorical column names\ncategorical_columns = [\n    \"bounces\",\n    \"last_action\",\n    \"source\",\n    \"medium\",\n    \"channelGrouping\",\n    \"browser\",\n    \"os\",\n    \"deviceCategory\",\n]\n\n# categorical columns to be grouped\ncols_to_group = {\n    \"5_pct\": [\"source\", \"browser\"],\n    \"10_pct\": [\"os\", \"channelGrouping\", \"medium\"],\n}\n\nRetrieve credentials for bigquery client\n\n# Google Cloud PROJECT ID\ngcp_project_id = os.environ[\"GCP_PROJECT_ID\"]\n\nGet filepath to Google Cloud Service Account JSON key\n\nraw_data_dir = os.path.join(PROJ_ROOT_DIR, \"data\", \"raw\")\ngcp_creds_fpath = glob(os.path.join(raw_data_dir, \"*.json\"))[0]\n\nAuthenticate bigquery client and get dictionary with credentials\n\ngcp_credentials = service_account.Credentials.from_service_account_file(gcp_creds_fpath)\ngcp_auth_dict = dict(gcp_project_id=gcp_project_id, gcp_creds=gcp_credentials)\n\nCreate a mapping between action type integer and label, in order to get meaningful names from the action_type column\n\nmapper = {\n    1: \"Click through of product lists\",\n    2: \"Product detail views\",\n    3: \"Add product(s) to cart\",\n    4: \"Remove product(s) from cart\",\n    5: \"Check out\",\n    6: \"Completed purchase\",\n    7: \"Refund of purchase\",\n    8: \"Checkout options\",\n    0: \"Unknown\",\n}\n\nDefine a dictionary to change datatypes of prepared data (this was originally developed in the data preparation step)\n\ndtypes_dict = {\n    \"fullvisitorid\": pd.StringDtype(),\n    \"visitId\": pd.StringDtype(),\n    \"visitNumber\": pd.Int8Dtype(),\n    \"country\": pd.StringDtype(),\n    \"quarter\": pd.Int8Dtype(),\n    \"month\": pd.Int8Dtype(),\n    \"day_of_month\": pd.Int8Dtype(),\n    \"day_of_week\": pd.Int8Dtype(),\n    \"hour\": pd.Int8Dtype(),\n    \"minute\": pd.Int8Dtype(),\n    \"second\": pd.Int8Dtype(),\n    \"source\": pd.CategoricalDtype(),  #\n    \"medium\": pd.CategoricalDtype(),  #\n    \"channelGrouping\": pd.CategoricalDtype(),  #\n    \"hits\": pd.Int16Dtype(),\n    \"bounces\": pd.CategoricalDtype(),  #\n    \"last_action\": pd.CategoricalDtype(),  #\n    \"product_detail_views\": pd.Int16Dtype(),\n    \"promos_displayed\": pd.Int16Dtype(),\n    \"promos_clicked\": pd.Int16Dtype(),\n    \"product_views\": pd.Int16Dtype(),\n    \"product_clicks\": pd.Int16Dtype(),\n    \"pageviews\": pd.Int16Dtype(),\n    \"transact_revenue\": pd.Float32Dtype(),\n    \"time_on_site\": pd.Int16Dtype(),\n    \"browser\": pd.CategoricalDtype(),  #\n    \"os\": pd.CategoricalDtype(),  #\n    \"added_to_cart\": pd.Int16Dtype(),\n    \"deviceCategory\": pd.CategoricalDtype(),  #\n}\n\nDefine a Python helper functions to perform the following\n\nexecute a SQL query using Google BigQuery\nset column datatypes of a pandas.DataFrame\ndrop duplicates based on a list of columns in a pandas.DataFrame\ncustomize the axes of a matplotlib plot\nplot a faceted bar chart using seaborn\nplot a heatmap using seaborn\n\n\ndef run_sql_query(\n    query: str,\n    gcp_project_id: str,\n    gcp_creds: os.PathLike,\n    show_dtypes: bool = False,\n    show_info: bool = False,\n    show_df: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Run query on BigQuery and return results as pandas.DataFrame.\"\"\"\n    start_time = datetime.now(pytz.timezone(\"US/Eastern\"))\n    start_time_str = start_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n    print(f\"Query execution start time = {start_time_str[:-3]}...\", end=\"\")\n    df = pd.read_gbq(\n        query,\n        project_id=gcp_project_id,\n        credentials=gcp_creds,\n        dialect=\"standard\",\n        # configuration is optional, since default for query caching is True\n        configuration={\"query\": {\"useQueryCache\": True}},\n        # use_bqstorage_api=True,\n    )\n    end_time = datetime.now(pytz.timezone(\"US/Eastern\"))\n    end_time_str = end_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n    duration = end_time - start_time\n    duration = duration.seconds + (duration.microseconds / 1_000_000)\n    print(f\"done at {end_time_str[:-3]} ({duration:.3f} seconds).\")\n    print(f\"Query returned {len(df):,} rows\")\n    if show_df:\n        with pd.option_context(\"display.max_columns\", None):\n            display(df)\n    if show_dtypes:\n        display(df.dtypes.rename(\"dtype\").to_frame().transpose())\n    if show_info:\n        df.info()\n    return df\n\n\ndef set_datatypes(df: pd.DataFrame, dtypes: Dict) -&gt; pd.DataFrame:\n    \"\"\"Set DataFrame datatypes using dictionary.\"\"\"\n    df = df.astype(dtypes)\n    return df\n\n\ndef drop_duplicates(df: pd.DataFrame, subset: List[str]) -&gt; pd.DataFrame:\n    \"\"\"Drop duplicates.\"\"\"\n    df = df.drop_duplicates(subset=subset, keep=\"first\")\n    return df\n\n\ndef customize_splines(ax: plt.axis, edgecolor: str = \"grey\") -&gt; plt.axis:\n    \"\"\"Customize matplotlib axis properties.\"\"\"\n    ax.spines[\"left\"].set_edgecolor(edgecolor)\n    ax.spines[\"left\"].set_linewidth(1.5)\n    ax.spines[\"bottom\"].set_edgecolor(edgecolor)\n    ax.spines[\"bottom\"].set_linewidth(1.5)\n    ax.spines[\"top\"].set_edgecolor(None)\n    ax.spines[\"right\"].set_edgecolor(None)\n    ax.tick_params(\n        top=False,\n        bottom=False,\n        left=False,\n        right=False,\n        labelleft=True,\n        labelbottom=True,\n    )\n    return ax\n\n\ndef plot_faceted_grouped_bar_chart(\n    data: pd.DataFrame,\n    xvar: str,\n    yvar: str,\n    zvar: str,\n    color_by_col: str,\n    colors: List[str],\n    xvar_type: str,\n    high_corr_categories: List[str],\n    bar_order: List[str],\n) -&gt; None:\n    \"\"\"Plot faceted grouped bar chart.\"\"\"\n    g = sns.FacetGrid(\n        data,\n        row=zvar,\n        hue=color_by_col,\n        palette=colors,\n        height=3,\n        sharey=False,\n        sharex=False,\n        aspect=3,\n    )\n    g.map(sns.barplot, xvar, yvar, order=bar_order)\n    g.fig.tight_layout(h_pad=-2)\n\n    # flatten axes into a 1-d array\n    axes = g.axes.flatten()\n\n    # iterate through the axes\n    for k, ax in enumerate(axes):\n        zvar_attr = ax.get_title().split(\" = \")[-1]\n        z_value_min = data.query(f\"{zvar} == '{zvar_attr}'\")[yvar].min()\n\n        ax.set_xlabel(None)\n        ax.set_ylabel(zvar_attr.title().replace(\"_\", \" \"), fontsize=12)\n        ax.xaxis.set_tick_params(labelsize=12)\n        ax.yaxis.set_tick_params(labelsize=12)\n        ax.tick_params(size=0)\n        ax = customize_splines(ax, None)\n        if z_value_min &lt; 0:\n            ax.axhline(0, ls=\"--\", c=\"black\")\n        ax.set_title(None)\n        ptitle = (\n            \"Highest correlation to revenue is for \"\n            f\"{', '.join(high_corr_categories)} {xvar_type}\"\n        )\n        if k == 0:\n            ax.set_title(ptitle, fontweight=\"bold\", loc=\"left\")\n        if k in range(len(bar_order)):\n            ax.set_xticklabels([])\n\n\ndef show_heatmap(\n    data: pd.DataFrame,\n    ytitle: str,\n    ptitle: str,\n    cbar_params: Union[Dict[str, float], bool] = False,\n    annot_kws: Union[Dict[str, int], bool] = False,\n    fig_size: Tuple[int] = (10, 12),\n) -&gt; None:\n    \"\"\".\"\"\"\n    fig, ax = plt.subplots(figsize=fig_size)\n    ax = sns.heatmap(\n        data,\n        cmap=\"YlOrRd\",\n        linewidth=0.5,\n        cbar=True if cbar_params else None,\n        cbar_kws=cbar_params if cbar_params else None,\n        annot=True if annot_kws else None,\n        annot_kws=annot_kws if annot_kws else None,\n        ax=ax,\n    )\n    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=12)\n    ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n    ax.set_xlabel(None)\n    ax.set_ylabel(ytitle, fontsize=12)\n    if cbar_params:\n        cbar = ax.collections[0].colorbar\n        cbar.ax.tick_params(size=0, labelsize=12)\n    ax.tick_params(size=0)\n    ax.set_title(\n        ptitle,\n        loc=\"left\",\n        fontsize=11,\n        fontweight=\"bold\",\n    )"
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#get-and-prepare-data",
    "href": "notebooks/03-eda/notebooks/03_eda.html#get-and-prepare-data",
    "title": "Exploratory Data Analysis",
    "section": "Get and Prepare Data",
    "text": "Get and Prepare Data\nData will be prepared for EDA based on our learnings from the data preparation step 1. SQL to get the following for visitors who made a return (future) visit to the merchandise store during the months to be included in the training data split - attributes of their first visit - these are candidate features (X) for use in ML development - one visitor is present per row - forward-looking label (y) that indicates if each visitor made a purchase on a return visit to the store - one visitor is present per row 2. drop duplicates by fullvisitorid 3. set column datatypes for all columns\nThese three steps are enclosed into a pandas.pipeline (link), which is defined below\n\nquery = f\"\"\"\n        WITH\n        -- Step 1. get visitors with a purchase on a future visit\n        next_visit_purchasers AS (\n             SELECT fullvisitorid,\n                    IF(COUNTIF(totals.transactions &gt; 0 AND totals.newVisits IS NULL) &gt; 0, True, False) AS made_purchase_on_future_visit\n             FROM `data-to-insights.ecommerce.web_analytics`\n             WHERE date BETWEEN '{train_start_date}' AND '{test_end_date}'\n             AND geoNetwork.country = 'United States'\n             GROUP BY fullvisitorid\n        ),\n        -- Steps 2. and 3. get attributes of the first visit\n        first_visit_attributes AS (\n            SELECT -- =========== GEOSPATIAL AND TEMPORAL ATTRIBUTES OF VISIT ===========\n                   geoNetwork.country,\n                   EXTRACT(QUARTER FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS quarter,\n                   EXTRACT(MONTH FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS month,\n                   EXTRACT(DAY FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS day_of_month,\n                   EXTRACT(DAYOFWEEK FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS day_of_week,\n                   EXTRACT(HOUR FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS hour,\n                   EXTRACT(MINUTE FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS minute,\n                   EXTRACT(SECOND FROM DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern')) AS second,\n                   -- =========== VISIT AND VISITOR METADATA ===========\n                   fullvisitorid,\n                   visitId,\n                   visitNumber,\n                   DATETIME(TIMESTAMP(TIMESTAMP_SECONDS(visitStartTime)), 'US/Eastern') AS visitStartTime,\n                   -- =========== SOURCE OF SITE TRAFFIC ===========\n                   -- source of the traffic from which the visit was initiated\n                   trafficSource.source,\n                   -- medium of the traffic from which the visit was initiated\n                   trafficSource.medium,\n                   -- referring channel connected to visit\n                   channelGrouping,\n                   -- =========== VISITOR ACTIVITY ===========\n                   -- total number of hits\n                   (CASE WHEN totals.hits &gt; 0 THEN totals.hits ELSE 0 END) AS hits,\n                   -- number of bounces\n                   (CASE WHEN totals.bounces &gt; 0 THEN totals.bounces ELSE 0 END) AS bounces,\n                   -- action performed during first visit\n                   CAST(h.eCommerceAction.action_type AS INT64) AS action_type,\n                   -- page views\n                   IFNULL(totals.pageviews, 0) AS pageviews,\n                   -- total revenue\n                   totals.totalTransactionRevenue / 1000000 AS transact_revenue,\n                   -- time on the website\n                   IFNULL(totals.timeOnSite, 0) AS time_on_site,\n                   -- whether add-to-cart was performed during visit\n                   (CASE WHEN CAST(h.eCommerceAction.action_type AS INT64) = 3 THEN 1 ELSE 0 END) AS added_to_cart,\n                   (CASE WHEN CAST(h.eCommerceAction.action_type AS INT64) = 2 THEN 1 ELSE 0 END) AS product_details_viewed,\n                   -- =========== VISITOR DEVICES ===========\n                   -- user's browser\n                   device.browser,\n                   -- user's operating system\n                   device.operatingSystem AS os,\n                   -- user's type of device\n                   device.deviceCategory,\n                   -- =========== PROMOTION ===========\n                   h.promotion,\n                   h.promotionActionInfo AS pa_info,\n                   -- =========== PRODUCT ===========\n                   h.product,\n                   -- =========== ML LABEL (DEPENDENT VARIABLE) ===========\n                   made_purchase_on_future_visit\n            FROM `data-to-insights.ecommerce.web_analytics`,\n            UNNEST(hits) AS h\n            INNER JOIN next_visit_purchasers USING (fullvisitorid)\n            WHERE date BETWEEN '{train_start_date}' AND '{train_end_date}'\n            AND geoNetwork.country = 'United States'\n            AND totals.newVisits = 1\n        ),\n        -- Step 4. get aggregated features (attributes) per visit\n        visit_attributes AS (\n            SELECT fullvisitorid,\n                   visitId,\n                   visitNumber,\n                   visitStartTime,\n                   country,\n                   quarter,\n                   month,\n                   day_of_month,\n                   day_of_week,\n                   hour,\n                   minute,\n                   second,\n                   source,\n                   medium,\n                   channelGrouping,\n                   hits,\n                   bounces,\n                   -- get the last action performed during the first visit\n                   -- (this indicates where the visitor left off at the end of their visit)\n                   MAX(action_type) AS last_action,\n                   -- get number of products whose details were viewed\n                   SUM(product_details_viewed) AS product_detail_views,\n                   -- get number of promotions displayed and clicked during the first visit\n                   COUNT(CASE WHEN pa_info IS NOT NULL THEN pa_info.promoIsView ELSE NULL END) AS promos_displayed,\n                   COUNT(CASE WHEN pa_info IS NOT NULL THEN pa_info.promoIsClick ELSE NULL END) AS promos_clicked,\n                   -- get number of products displayed and clicked during the first visit\n                   COUNT(CASE WHEN pu.isImpression IS NULL THEN NULL ELSE 1 END) AS product_views,\n                   COUNT(CASE WHEN pu.isClick IS NULL THEN NULL ELSE 1 END) AS product_clicks,\n                   pageviews,\n                   transact_revenue,\n                   time_on_site,\n                   browser,\n                   os,\n                   deviceCategory,\n                   SUM(added_to_cart) AS added_to_cart,\n                   made_purchase_on_future_visit,\n            FROM first_visit_attributes\n            LEFT JOIN UNNEST(promotion) as p\n            LEFT JOIN UNNEST(product) as pu\n            GROUP BY fullvisitorid,\n                     visitId,\n                     visitNumber,\n                     visitStartTime,\n                     country,\n                     quarter,\n                     month,\n                     day_of_month,\n                     day_of_week,\n                     hour,\n                     minute,\n                     second,\n                     source,\n                     medium,\n                     channelGrouping,\n                     hits,\n                     bounces,\n                     pageviews,\n                     transact_revenue,\n                     time_on_site,\n                     browser,\n                     os,\n                     deviceCategory,\n                     made_purchase_on_future_visit\n        )\n        SELECT *\n        FROM visit_attributes\n        \"\"\"\ndf = (\n    run_sql_query(query, **gcp_auth_dict, show_df=False)\n    .pipe(set_datatypes, dtypes=dtypes_dict)\n    .pipe(drop_duplicates, subset=[\"fullvisitorid\"])\n)\nwith pd.option_context(\"display.max_columns\", None):\n    display(df.head())\n    display(df.tail())\n\nQuery execution start time = 2023-04-12 22:16:47.745...done at 2023-04-12 22:17:06.333 (18.589 seconds).\nQuery returned 92,859 rows\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n0\n483329569933708956\n1477437687\n1\n2016-10-25 19:21:27\nUnited States\n4\n10\n25\n3\n19\n21\n27\ngoogle\norganic\nOrganic Search\n6\n0\n0\n0\n0\n0\n0\n0\n6\n&lt;NA&gt;\n602\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n1\n9534112552538425546\n1476671570\n1\n2016-10-16 22:32:50\nUnited States\n4\n10\n16\n1\n22\n32\n50\nyoutube.com\nreferral\nSocial\n6\n0\n0\n0\n54\n0\n0\n0\n1\n&lt;NA&gt;\n270\nOpera\nWindows\ndesktop\n0\nFalse\n\n\n2\n4648924122067625674\n1475958245\n1\n2016-10-08 16:24:05\nUnited States\n4\n10\n8\n7\n16\n24\n5\nyoutube.com\nreferral\nSocial\n5\n0\n0\n0\n36\n0\n4\n0\n2\n&lt;NA&gt;\n198\nOpera\nWindows\ndesktop\n0\nFalse\n\n\n3\n2743152869399749836\n1481229164\n1\n2016-12-08 15:32:44\nUnited States\n4\n12\n8\n5\n15\n32\n44\ngoogle\norganic\nOrganic Search\n5\n0\n0\n0\n18\n0\n0\n0\n5\n&lt;NA&gt;\n1004\nChrome\nWindows\ndesktop\n0\nFalse\n\n\n4\n1565213706199847638\n1475172212\n1\n2016-09-29 14:03:32\nUnited States\n3\n9\n29\n5\n14\n3\n32\ngoogle\norganic\nOrganic Search\n5\n0\n0\n0\n18\n0\n15\n0\n5\n&lt;NA&gt;\n107\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\nminute\nsecond\nsource\nmedium\nchannelGrouping\nhits\nbounces\nlast_action\nproduct_detail_views\npromos_displayed\npromos_clicked\nproduct_views\nproduct_clicks\npageviews\ntransact_revenue\ntime_on_site\nbrowser\nos\ndeviceCategory\nadded_to_cart\nmade_purchase_on_future_visit\n\n\n\n\n92854\n116047731488418420\n1481947293\n1\n2016-12-16 23:01:33\nUnited States\n4\n12\n16\n6\n23\n1\n33\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n40\n0\n4\n&lt;NA&gt;\n41\nInternet Explorer\nWindows\ndesktop\n0\nFalse\n\n\n92855\n4456968726181345855\n1475469647\n1\n2016-10-03 00:40:47\nUnited States\n4\n10\n3\n2\n0\n40\n47\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n48\n0\n4\n&lt;NA&gt;\n116\nSafari\nMacintosh\ndesktop\n0\nFalse\n\n\n92856\n3959327314706060020\n1482846670\n1\n2016-12-27 08:51:10\nUnited States\n4\n12\n27\n3\n8\n51\n10\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n43\n0\n4\n&lt;NA&gt;\n77\nChrome\nAndroid\nmobile\n0\nFalse\n\n\n92857\n3020400276554321201\n1478988254\n1\n2016-11-12 17:04:14\nUnited States\n4\n11\n12\n7\n17\n4\n14\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n48\n0\n4\n&lt;NA&gt;\n61\nInternet Explorer\nWindows\ndesktop\n0\nFalse\n\n\n92858\n7677161554293089105\n1481515229\n1\n2016-12-11 23:00:29\nUnited States\n4\n12\n11\n1\n23\n0\n29\ngoogle\norganic\nOrganic Search\n4\n0\n0\n0\n0\n0\n44\n0\n4\n&lt;NA&gt;\n31\nChrome\nMacintosh\ndesktop\n0\nFalse\n\n\n\n\n\n\n\nGet a list of the non-categorical columns\n\nnon_categorical_columns = [c for c in list(df) if c not in categorical_columns]\n\nShow the number of unique values in all categorical columns\n\n\nCode\ndf_nunique = pd.DataFrame.from_records(\n    [{\"column\": c, \"num_unique_values\": df[c].nunique()} for c in categorical_columns]\n)\ndf_nunique\n\n\n\n\n\n\n\n\n\ncolumn\nnum_unique_values\n\n\n\n\n0\nbounces\n2\n\n\n1\nlast_action\n7\n\n\n2\nsource\n116\n\n\n3\nmedium\n7\n\n\n4\nchannelGrouping\n8\n\n\n5\nbrowser\n26\n\n\n6\nos\n15\n\n\n7\ndeviceCategory\n3\n\n\n\n\n\n\n\nDefine a custom data transformation pipeline to handle the categorical columns. In the data preparation step, this was done using pandas.value_counts() to drop in frequently occurring values based on two thresholds for minimum wanted frequency 5% and 10%. Here, we will define a custom scikit-learn.pipeline that performs the same encoding using the feature-engine library, which provides a RareLabelEncoder that accepts a threshold as the parameter tol. Two such encoders are defined below with the required thresholds and they are then placed into a scikit-learn.pipeline to transform the data\n\nencoder_05 = RareLabelEncoder(\n    tol=0.05,\n    n_categories=2,\n    variables=[v for k, v in cols_to_group.items() if \"5\" in k][0],\n    replace_with=\"other\",\n)\nencoder_10 = RareLabelEncoder(\n    tol=0.10,\n    n_categories=2,\n    variables=[v for k, v in cols_to_group.items() if \"10\" in k][0],\n    replace_with=\"other\",\n)\ncategorical_transformer = Pipeline(\n    steps=[(\"enc_05\", encoder_05), (\"enc_10\", encoder_10)]\n)\npreprocessor = ColumnTransformer(\n    transformers=[(\"cat\", categorical_transformer, categorical_columns)],\n    remainder=\"passthrough\",\n)\npipe_trans = Pipeline(steps=[(\"preprocessor\", preprocessor)])\npipe_trans\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('cat',\n                                                  Pipeline(steps=[('enc_05',\n                                                                   RareLabelEncoder(n_categories=2,\n                                                                                    replace_with='other',\n                                                                                    variables=['source',\n                                                                                               'browser'])),\n                                                                  ('enc_10',\n                                                                   RareLabelEncoder(n_categories=2,\n                                                                                    replace_with='other',\n                                                                                    tol=0.1,\n                                                                                    variables=['os',\n                                                                                               'channelGrouping',\n                                                                                               'medium']))]),\n                                                  ['bounces', 'last_action',\n                                                   'source', 'medium',\n                                                   'channelGrouping', 'browser',\n                                                   'os',\n                                                   'deviceCategory'])]))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('preprocessor',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('cat',\n                                                  Pipeline(steps=[('enc_05',\n                                                                   RareLabelEncoder(n_categories=2,\n                                                                                    replace_with='other',\n                                                                                    variables=['source',\n                                                                                               'browser'])),\n                                                                  ('enc_10',\n                                                                   RareLabelEncoder(n_categories=2,\n                                                                                    replace_with='other',\n                                                                                    tol=0.1,\n                                                                                    variables=['os',\n                                                                                               'channelGrouping',\n                                                                                               'medium']))]),\n                                                  ['bounces', 'last_action',\n                                                   'source', 'medium',\n                                                   'channelGrouping', 'browser',\n                                                   'os',\n                                                   'deviceCategory'])]))])preprocessor: ColumnTransformerColumnTransformer(remainder='passthrough',\n                  transformers=[('cat',\n                                 Pipeline(steps=[('enc_05',\n                                                  RareLabelEncoder(n_categories=2,\n                                                                   replace_with='other',\n                                                                   variables=['source',\n                                                                              'browser'])),\n                                                 ('enc_10',\n                                                  RareLabelEncoder(n_categories=2,\n                                                                   replace_with='other',\n                                                                   tol=0.1,\n                                                                   variables=['os',\n                                                                              'channelGrouping',\n                                                                              'medium']))]),\n                                 ['bounces', 'last_action', 'source', 'medium',\n                                  'channelGrouping', 'browser', 'os',\n                                  'deviceCategory'])])cat['bounces', 'last_action', 'source', 'medium', 'channelGrouping', 'browser', 'os', 'deviceCategory']RareLabelEncoderRareLabelEncoder(n_categories=2, replace_with='other',\n                 variables=['source', 'browser'])RareLabelEncoderRareLabelEncoder(n_categories=2, replace_with='other', tol=0.1,\n                 variables=['os', 'channelGrouping', 'medium'])remainderpassthroughpassthrough\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nThe datatype of the categorical columns is set as pd.CategoricalDtype() in the datatypes dictionary dtypes_dict earlier. This was set as pd.StringDtype() during the data preparation step. Here, this change is necessary since the RareLabelEncoder() transformer expects to see these categrical columns appear as categories and not just as strings.\n\n\n\nApply the custom data transformation pipeline to prepare the training data split for EDA\n\n_ = pipe_trans.fit(df)\ndf = pd.DataFrame(\n    pipe_trans.transform(df), columns=categorical_columns + non_categorical_columns\n)[non_categorical_columns + categorical_columns].pipe(set_datatypes, dtypes=dtypes_dict)\n\nThe cardinality of the columns before and after grouping is shown below\n\n\nCode\ndf_nunique.merge(\n    pd.DataFrame.from_records(\n        [\n            {\n                \"column\": c,\n                \"column_grouped\": c,\n                \"num_unique_values_after_grouping\": df[c].nunique(),\n            }\n            for c in categorical_columns\n        ]\n    ).assign(column_grouped=lambda df: df[\"column_grouped\"] != df[\"column\"]),\n    on=[\"column\"],\n    how=\"left\",\n)\n\n\n\n\n\n\n\n\n\ncolumn\nnum_unique_values\ncolumn_grouped\nnum_unique_values_after_grouping\n\n\n\n\n0\nbounces\n2\nFalse\n2\n\n\n1\nlast_action\n7\nFalse\n7\n\n\n2\nsource\n116\nFalse\n5\n\n\n3\nmedium\n7\nFalse\n4\n\n\n4\nchannelGrouping\n8\nFalse\n4\n\n\n5\nbrowser\n26\nFalse\n3\n\n\n6\nos\n15\nFalse\n5\n\n\n7\ndeviceCategory\n3\nFalse\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThis is identical to the output seen during the data preparation step in the Handling Categorical Columns sub-section.\n\n\n\nThe category distributions (frequencies) after grouping are shown below for all categorical columns (including those that were grouped)\n\n\nCode\ndfs_cats_groups = []\nfor c in categorical_columns:\n    # get fraction of unique values\n    df_frequencies = (\n        df[c]\n        .value_counts()\n        .rename(\"number_of_visitors\")\n        .to_frame()\n        .merge(\n            (\n                df[c].value_counts(normalize=True).rename(\"fraction_of_visitors\") * 100\n            ).to_frame(),\n            left_index=True,\n            right_index=True,\n        )\n    )\n\n    # map unique values for last_action and bounces to get meaningful names\n    if c == \"last_action\":\n        df_frequencies.index = df_frequencies.index.map(mapper)\n    if c == \"bounces\":\n        df_frequencies.index = df_frequencies.index.map({0: False, 1: True})\n\n    # get running total of fraction (cumulative sum)\n    df_frequencies = (\n        df_frequencies.sort_values(by=[\"fraction_of_visitors\"])\n        .assign(\n            cumulative_fraction_of_visitors=lambda df: df[\n                \"fraction_of_visitors\"\n            ].cumsum(),\n            column_name=c,\n        )\n        .sort_values(by=[\"fraction_of_visitors\"], ascending=False)\n    )\n\n    # rename columns\n    df_frequencies = df_frequencies.reset_index().rename(columns={c: \"column_value\"})\n    dfs_cats_groups.append(df_frequencies)\ndf_frequencies_grouped = pd.concat(dfs_cats_groups, ignore_index=True)\ncol = df_frequencies_grouped.pop(\"column_name\")\ndf_frequencies_grouped.insert(0, col.name, col)\nwith pd.option_context(\"display.max_rows\", None):\n    display(df_frequencies_grouped)\n\n\n\n\n\n\n\n\n\ncolumn_name\ncolumn_value\nnumber_of_visitors\nfraction_of_visitors\ncumulative_fraction_of_visitors\n\n\n\n\n0\nbounces\nFalse\n65500\n70.771791\n100.000000\n\n\n1\nbounces\nTrue\n27051\n29.228209\n29.228209\n\n\n2\nlast_action\nUnknown\n67519\n72.953291\n100.000000\n\n\n3\nlast_action\nProduct detail views\n14720\n15.904744\n27.046709\n\n\n4\nlast_action\nAdd product(s) to cart\n4663\n5.038303\n11.141965\n\n\n5\nlast_action\nCompleted purchase\n3094\n3.343022\n6.103662\n\n\n6\nlast_action\nCheck out\n1632\n1.763352\n2.760640\n\n\n7\nlast_action\nRemove product(s) from cart\n882\n0.952988\n0.997288\n\n\n8\nlast_action\nClick through of product lists\n41\n0.044300\n0.044300\n\n\n9\nsource\ngoogle\n43478\n46.977342\n100.000000\n\n\n10\nsource\n(direct)\n21539\n23.272574\n53.022658\n\n\n11\nsource\nmall.googleplex.com\n11776\n12.723796\n29.750084\n\n\n12\nsource\nyoutube.com\n8021\n8.666573\n17.026288\n\n\n13\nsource\nother\n7737\n8.359715\n8.359715\n\n\n14\nmedium\norganic\n38580\n41.685125\n100.000000\n\n\n15\nmedium\nreferral\n25084\n27.102895\n58.314875\n\n\n16\nmedium\n(none)\n21539\n23.272574\n31.211980\n\n\n17\nmedium\nother\n7348\n7.939406\n7.939406\n\n\n18\nchannelGrouping\nOrganic Search\n38580\n41.685125\n100.000000\n\n\n19\nchannelGrouping\nDirect\n21539\n23.272574\n58.314875\n\n\n20\nchannelGrouping\nother\n16274\n17.583819\n35.042301\n\n\n21\nchannelGrouping\nReferral\n16158\n17.458482\n17.458482\n\n\n22\nbrowser\nChrome\n69001\n74.554570\n100.000000\n\n\n23\nbrowser\nSafari\n15294\n16.524943\n25.445430\n\n\n24\nbrowser\nother\n8256\n8.920487\n8.920487\n\n\n25\nos\nMacintosh\n30610\n33.073657\n100.000000\n\n\n26\nos\nWindows\n25588\n27.647459\n66.926343\n\n\n27\nos\niOS\n13500\n14.586552\n39.278884\n\n\n28\nos\nAndroid\n11486\n12.410455\n24.692332\n\n\n29\nos\nother\n11367\n12.281877\n12.281877\n\n\n30\ndeviceCategory\ndesktop\n67355\n72.776091\n100.000000\n\n\n31\ndeviceCategory\nmobile\n21790\n23.543776\n27.223909\n\n\n32\ndeviceCategory\ntablet\n3406\n3.680133\n3.680133\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThis is identical to the output seen in df_frequencies_grouped during the data preparation step in the Handling Categorical Columns sub-section.\n\n\n\nThe training data split is now prepared and ready for use in EDA."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#exploratory-data-analysis",
    "href": "notebooks/03-eda/notebooks/03_eda.html#exploratory-data-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n\n\n\n\n\nNotes\n\n\n\n\nWe will interchangeably refer to each row in the data that was prepared above as visits or visitors. Since duplicates by fullvisitorid have been dropped, each row represents a unique visitor.\nFor the rest of this step (EDA), we will only use the training data as mentioned earlier in order to avoid data leakage or lookahead bias.\nWe will interchangeably refer to each visitor who made a purchase on a return visit as a return purchaser.\n\n\n\nThe first few rows of the prepared training data are shown below\n\n\nCode\nwith pd.option_context(\"display.max_rows\", None):\n    display(df.head())\n\n\n\n\n\n\n\n\n\nfullvisitorid\nvisitId\nvisitNumber\nvisitStartTime\ncountry\nquarter\nmonth\nday_of_month\nday_of_week\nhour\n...\nadded_to_cart\nmade_purchase_on_future_visit\nbounces\nlast_action\nsource\nmedium\nchannelGrouping\nbrowser\nos\ndeviceCategory\n\n\n\n\n0\n483329569933708956\n1477437687\n1\n2016-10-25 19:21:27\nUnited States\n4\n10\n25\n3\n19\n...\n0\nFalse\n0\n0\ngoogle\norganic\nOrganic Search\nChrome\nWindows\ndesktop\n\n\n1\n9534112552538425546\n1476671570\n1\n2016-10-16 22:32:50\nUnited States\n4\n10\n16\n1\n22\n...\n0\nFalse\n0\n0\nyoutube.com\nreferral\nother\nother\nWindows\ndesktop\n\n\n2\n4648924122067625674\n1475958245\n1\n2016-10-08 16:24:05\nUnited States\n4\n10\n8\n7\n16\n...\n0\nFalse\n0\n0\nyoutube.com\nreferral\nother\nother\nWindows\ndesktop\n\n\n3\n2743152869399749836\n1481229164\n1\n2016-12-08 15:32:44\nUnited States\n4\n12\n8\n5\n15\n...\n0\nFalse\n0\n0\ngoogle\norganic\nOrganic Search\nChrome\nWindows\ndesktop\n\n\n4\n1565213706199847638\n1475172212\n1\n2016-09-29 14:03:32\nUnited States\n3\n9\n29\n5\n14\n...\n0\nFalse\n0\n0\ngoogle\norganic\nOrganic Search\nChrome\nAndroid\nmobile\n\n\n\n\n5 rows × 31 columns\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nFor the categorical columns, only the frequency-encoded versions are present in the prepared data.\n\n\n\nQuestion 1. For high-level channel, and the more fine-graned traffic source and traffic medium, get the correlation between the numerical attributes of visits and total visit revenue. Across all of these groupings of sources of web traffic arriving at the merchandise store, comment on the strongest and weakest correlations to revenue.\nAt the time of the first visit, we know whether the visitor will make a purchase during a return (or future) visit to the merchandise store. This is in the made_purchase_on_future_visit column. But, we have not extracted the visit revenue that was earned during that future visit, since we have only extracted its outcome. So, we will assume that this question is referring to visit revenue earned during the first visit since the columns (including totals.transact_revenue) are only retrieved for visitors’ first visits.\nDue to the high cardinality of channel and traffic source, this question will be answered for the grouped version of these columns. The following helper function will get this correlation and will be re-used for all three traffic-related columns\n\ndef get_revenue_corr_by_attribute(\n    df: pd.DataFrame, categorical_col: str, numerical_cols: List[str]\n) -&gt; pd.DataFrame:\n    \"\"\"Get correlation between numerical attrs and revenue for categorical attribute.\"\"\"\n    # get distribution of categorical column\n    df_frequencies = df[categorical_col].value_counts(normalize=True).reset_index()\n\n    # get correlation within groupby\n    df_corr = (\n        df.groupby(  # .query(f\"{categorical_col}.isin(@popular_categories)\")\n            [categorical_col, \"made_purchase_on_future_visit\"]\n        )[numerical_cols + [\"transact_revenue\"]]\n        .corr()\n        .reset_index()[\n            [\n                \"level_2\",\n                \"transact_revenue\",\n                categorical_col,\n                \"made_purchase_on_future_visit\",\n            ]\n        ]\n        # rename columns after reset_index\n        .rename(columns={\"level_2\": \"first_visit_attribute\"})\n        # get correlation to revenue only\n        .query(\"first_visit_attribute != 'transact_revenue'\")\n        # reshape data from tidy to untidy format\n        .pivot(\n            index=[\"first_visit_attribute\", categorical_col],\n            columns=[\"made_purchase_on_future_visit\"],\n            values=[\"transact_revenue\"],\n        )\n        .reset_index()\n    )\n\n    # flatten columns in untidy data\n    df_corr.columns = [\n        \"_\".join([str(sl) for sl in c]).rstrip(\"_\")\n        for c in df_corr.columns.to_flat_index().tolist()\n    ]\n\n    # rename columns in untidy data and merge with frequencies to show distribution\n    # side-by-side with distribution\n    df_corr = (\n        df_corr.rename(\n            columns={\n                \"transact_revenue_False\": \"corr_to_1st_visit_revenue_if_no_return_purchase\",\n                \"transact_revenue_True\": \"corr_to_1st_visit_revenue_if_return_purchase\",\n            }\n        )\n        # merge with frequencies\n        .merge(df_frequencies, on=[categorical_col], how=\"left\")\n        # sort for display purposes only\n        .sort_values(\n            by=[\"first_visit_attribute\", \"proportion\"],\n            ascending=[True, False],\n        )\n    )\n    return df_corr\n\nThe following are the numerical columns that can be used to explore correlations with revenue\n\nadded_to_cart\nhits\npageviews\nproduct_detail_views\ntime_on_site\n\n\n\nCode\nnumerical_cols = [\n    \"added_to_cart\",\n    \"hits\",\n    \"pageviews\",\n    \"product_detail_views\",\n    \"time_on_site\",\n]\n\n\nThe correlations to revenue are first shown by the channel. Channel is a high-level grouping of the source of visitor traffic reaching a website. The default channel groupings used in Google Analytics tracking data are available here. We will assume that the default-level groupings are being tracked by the Google merchandise store’s analytics tracking implementation.\nThese correlations for channels are shown below\n\nhigh_corr_categories = [\"Direct\", \"Referral\"]\ndf_corr_chn = get_revenue_corr_by_attribute(\n    df, \"channelGrouping\", numerical_cols\n).assign(is_direct_referral=lambda df: df[\"channelGrouping\"].isin(high_corr_categories))\ndf_corr_chn\n\n\n\n\n\n\n\n\nfirst_visit_attribute\nchannelGrouping\ncorr_to_1st_visit_revenue_if_no_return_purchase\ncorr_to_1st_visit_revenue_if_return_purchase\nproportion\nis_direct_referral\n\n\n\n\n1\nadded_to_cart\nOrganic Search\n0.458317\n0.176038\n0.416851\nFalse\n\n\n0\nadded_to_cart\nDirect\n0.286862\n0.354988\n0.232726\nTrue\n\n\n3\nadded_to_cart\nother\n0.234132\n0.311722\n0.175838\nFalse\n\n\n2\nadded_to_cart\nReferral\n0.195023\n0.362088\n0.174585\nTrue\n\n\n5\nhits\nOrganic Search\n0.435311\n0.117423\n0.416851\nFalse\n\n\n4\nhits\nDirect\n0.204795\n0.362308\n0.232726\nTrue\n\n\n7\nhits\nother\n0.231565\n-0.065063\n0.175838\nFalse\n\n\n6\nhits\nReferral\n0.054949\n0.440263\n0.174585\nTrue\n\n\n9\npageviews\nOrganic Search\n0.429002\n0.124916\n0.416851\nFalse\n\n\n8\npageviews\nDirect\n0.197580\n0.367974\n0.232726\nTrue\n\n\n11\npageviews\nother\n0.198325\n-0.099826\n0.175838\nFalse\n\n\n10\npageviews\nReferral\n0.043460\n0.437380\n0.174585\nTrue\n\n\n13\nproduct_detail_views\nOrganic Search\n0.406578\n0.078438\n0.416851\nFalse\n\n\n12\nproduct_detail_views\nDirect\n0.213971\n0.317490\n0.232726\nTrue\n\n\n15\nproduct_detail_views\nother\n0.304971\n0.022729\n0.175838\nFalse\n\n\n14\nproduct_detail_views\nReferral\n0.071299\n0.411491\n0.174585\nTrue\n\n\n17\ntime_on_site\nOrganic Search\n0.291891\n-0.107737\n0.416851\nFalse\n\n\n16\ntime_on_site\nDirect\n0.100362\n0.175132\n0.232726\nTrue\n\n\n19\ntime_on_site\nother\n0.101952\n-0.322572\n0.175838\nFalse\n\n\n18\ntime_on_site\nReferral\n0.030607\n0.524343\n0.174585\nTrue\n\n\n\n\n\n\n\nA plot of these correlations to revenue is shown below for return purchasers (corr_to_1st_visit_revenue_if_return_purchase)\n\nplot_faceted_grouped_bar_chart(\n    data=df_corr_chn,\n    xvar=\"channelGrouping\",\n    yvar=\"corr_to_1st_visit_revenue_if_return_purchase\",\n    zvar=\"first_visit_attribute\",\n    xvar_type=\"channel groupings\",\n    color_by_col=\"is_direct_referral\",\n    colors=[\"lightgrey\", \"red\", \"lightgrey\", \"red\"],\n    bar_order=[\"Organic Search\", \"Direct\", \"other\", \"Referral\"],\n    high_corr_categories=high_corr_categories,\n)\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nFor the high-level channel groupings of (visitor) traffic source, direct and referral-based traffic are responsible for the highest correlation to revenue earned during the first visit by return purchasers (see the corr_to_1st_visit_revenue_if_return_purchase column). Combined, these two sources account for approximately 40% of all web traffic (first-time visitors) to the merchandise store’s site.\nAmong all the selected numerical attributes of first-time visitors’ visits to the store, the time spent on the site by first-time visitors reaching the store through referrals, and who later returned to make a purchase, (see first_visit_attribute = time_on_site) is most strongly correlated to visit revenue earned.\n\n\n\nThe correlations are now similarly shown by the more fine-grained traffic source column\n\n\nCode\nhigh_corr_categories = [\"other\", \"mall.googleplex.com\"]\ndf_corr_source = get_revenue_corr_by_attribute(df, \"source\", numerical_cols).assign(\n    is_other_gmail=lambda df: df[\"source\"].isin(high_corr_categories)\n)\ndf_corr_source\n\n\n\n\n\n\n\n\n\nfirst_visit_attribute\nsource\ncorr_to_1st_visit_revenue_if_no_return_purchase\ncorr_to_1st_visit_revenue_if_return_purchase\nproportion\nis_other_gmail\n\n\n\n\n1\nadded_to_cart\ngoogle\n0.420159\n0.210653\n0.469773\nFalse\n\n\n0\nadded_to_cart\n(direct)\n0.286862\n0.354988\n0.232726\nFalse\n\n\n2\nadded_to_cart\nmall.googleplex.com\n0.328478\n0.476184\n0.127238\nTrue\n\n\n4\nadded_to_cart\nyoutube.com\nNaN\nNaN\n0.086666\nFalse\n\n\n3\nadded_to_cart\nother\n0.105265\n0.486743\n0.083597\nTrue\n\n\n6\nhits\ngoogle\n0.395540\n0.027843\n0.469773\nFalse\n\n\n5\nhits\n(direct)\n0.204795\n0.362308\n0.232726\nFalse\n\n\n7\nhits\nmall.googleplex.com\n0.182408\n0.679037\n0.127238\nTrue\n\n\n9\nhits\nyoutube.com\nNaN\nNaN\n0.086666\nFalse\n\n\n8\nhits\nother\n0.112838\n0.470637\n0.083597\nTrue\n\n\n11\npageviews\ngoogle\n0.384886\n0.018214\n0.469773\nFalse\n\n\n10\npageviews\n(direct)\n0.197580\n0.367974\n0.232726\nFalse\n\n\n12\npageviews\nmall.googleplex.com\n0.168901\n0.669607\n0.127238\nTrue\n\n\n14\npageviews\nyoutube.com\nNaN\nNaN\n0.086666\nFalse\n\n\n13\npageviews\nother\n0.112363\n0.465942\n0.083597\nTrue\n\n\n16\nproduct_detail_views\ngoogle\n0.387493\n0.043626\n0.469773\nFalse\n\n\n15\nproduct_detail_views\n(direct)\n0.213971\n0.317490\n0.232726\nFalse\n\n\n17\nproduct_detail_views\nmall.googleplex.com\n0.169731\n0.630595\n0.127238\nTrue\n\n\n19\nproduct_detail_views\nyoutube.com\nNaN\nNaN\n0.086666\nFalse\n\n\n18\nproduct_detail_views\nother\n0.200577\n0.472184\n0.083597\nTrue\n\n\n21\ntime_on_site\ngoogle\n0.248570\n-0.205277\n0.469773\nFalse\n\n\n20\ntime_on_site\n(direct)\n0.100362\n0.175132\n0.232726\nFalse\n\n\n22\ntime_on_site\nmall.googleplex.com\n0.064139\n0.636119\n0.127238\nTrue\n\n\n24\ntime_on_site\nyoutube.com\nNaN\nNaN\n0.086666\nFalse\n\n\n23\ntime_on_site\nother\n0.131011\n0.556708\n0.083597\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nTraffic source is the domain through which visitors reach the store’s website (link).\nDirect traffic source indicates a visitor entered the url of the store into the search bar on a browser and so directly accessed the store’s site (link).\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nDirect traffic sources again appear as one of the highest correlations (see the corr_to_1st_visit_revenue_if_return_purchase column) to first-visit revenue earned by return purchasers for all the numerical columns (pageviews, hits, etc.), but\n\ngmail\nother (less frequent)\n\ntraffic sources have a stronger correlation to revenue.\nA Google search (through the Google search engine, or source = google) during the first visit consistently has the weakest correlation to revenue earned during that visit for all numerical columns.\nCorrelations to revenue are stronger at this more granular level (by traffic source) than by the high-level channel groupings. For example, compare correlations in corr_to_1st_visit_revenue_if_return_purchase for first_visit_attribute = hits in df_corr_chn to the same in df_corr_source.\n\n\n\nThis is finally repeated using the same helper function for the traffic medium column\n\n\nCode\nhigh_corr_categories = [\"referral\", \"(none)\"]\ndf_corr_medium = get_revenue_corr_by_attribute(df, \"medium\", numerical_cols).assign(\n    is_none_referral=lambda df: df[\"medium\"].isin(high_corr_categories)\n)\ndf_corr_medium\n\n\n\n\n\n\n\n\n\nfirst_visit_attribute\nmedium\ncorr_to_1st_visit_revenue_if_no_return_purchase\ncorr_to_1st_visit_revenue_if_return_purchase\nproportion\nis_none_referral\n\n\n\n\n1\nadded_to_cart\norganic\n0.458317\n0.176038\n0.416851\nFalse\n\n\n3\nadded_to_cart\nreferral\n0.193514\n0.361836\n0.271029\nTrue\n\n\n0\nadded_to_cart\n(none)\n0.286862\n0.354988\n0.232726\nTrue\n\n\n2\nadded_to_cart\nother\n0.262166\n0.315144\n0.079394\nFalse\n\n\n5\nhits\norganic\n0.435311\n0.117423\n0.416851\nFalse\n\n\n7\nhits\nreferral\n0.055521\n0.439544\n0.271029\nTrue\n\n\n4\nhits\n(none)\n0.204795\n0.362308\n0.232726\nTrue\n\n\n6\nhits\nother\n0.261931\n-0.064471\n0.079394\nFalse\n\n\n9\npageviews\norganic\n0.429002\n0.124916\n0.416851\nFalse\n\n\n11\npageviews\nreferral\n0.044005\n0.436655\n0.271029\nTrue\n\n\n8\npageviews\n(none)\n0.197580\n0.367974\n0.232726\nTrue\n\n\n10\npageviews\nother\n0.228142\n-0.099564\n0.079394\nFalse\n\n\n13\nproduct_detail_views\norganic\n0.406578\n0.078438\n0.416851\nFalse\n\n\n15\nproduct_detail_views\nreferral\n0.073262\n0.411055\n0.271029\nTrue\n\n\n12\nproduct_detail_views\n(none)\n0.213971\n0.317490\n0.232726\nTrue\n\n\n14\nproduct_detail_views\nother\n0.324045\n0.024184\n0.079394\nFalse\n\n\n17\ntime_on_site\norganic\n0.291891\n-0.107737\n0.416851\nFalse\n\n\n19\ntime_on_site\nreferral\n0.035605\n0.524371\n0.271029\nTrue\n\n\n16\ntime_on_site\n(none)\n0.100362\n0.175132\n0.232726\nTrue\n\n\n18\ntime_on_site\nother\n0.063565\n-0.322501\n0.079394\nFalse\n\n\n\n\n\n\n\nA plot of these correlations to revenue is shown below for return purchasers (corr_to_1st_visit_revenue_if_return_purchase)\n\nplot_faceted_grouped_bar_chart(\n    data=df_corr_medium,\n    xvar=\"medium\",\n    yvar=\"corr_to_1st_visit_revenue_if_return_purchase\",\n    zvar=\"first_visit_attribute\",\n    xvar_type=\"medium groupings\",\n    color_by_col=\"is_none_referral\",\n    colors=[\"lightgrey\", \"red\", \"red\", \"lightgrey\"],\n    bar_order=[\"organic\", \"referral\", \"(none)\", \"other\"],\n    high_corr_categories=high_corr_categories,\n)\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nTraffic medium reflects the type of traffic source that reaches the store’s website (link).\nTraffic medium is a more higher-level grouping of visitor traffic than traffic source.\n(none) refers to traffic that originates from sources which tracking information is not available. Some reasons (1, 2) for this occurrence include a\n\nvisitor directly entering the url into a browser\nvisitor clicking a browser bookmark\nvisitor clicks a link in a PDF document\netc.\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nAgain referrals appear as one of the strongest correlations to first-visit revenue. Unknown mediums give the second strongest correlation to revenue.\nCorrelations to revenue are weaker for this aggregation of traffic than by the lower-level traffic source grouping.\n\n\n\n\n\n\n\n\n\nOverall Observations for Correlations to Revenue Based on Groupings by Traffic\n\n\n\n\nRevenue earned during a first visit to the merchandise store is most strongly correlated to numerical attributes of the first visit for referral-based or direct/unknown traffic sources.\nAttributes of visitors reaching the site through a Google search have the weakest correlation to first-visit revenue earned.\nhits and pageviews are correlated to eachother. These two attributes are also correlated to product detail views, although this is weaker than the correlation between hits and pageviews. We can see the inter-correlation between these three columns from the similar\n\nvalues in the respective DataFrames (df_corr_chn, df_corr_source and df_corr_medium)\nbar relative heights in the charts\n\n\n\n\nQuestion 2. Which channels were responsible for the most first-time visitors with a purchase on their return visit? Show this comparison on a chart by channel.\n\ndf_agg_by_channel = (\n    # groupby and count fullvisitorid\n    df.groupby([\"made_purchase_on_future_visit\", \"channelGrouping\"], as_index=False)[\n        \"fullvisitorid\"\n    ]\n    .count()\n    .rename(columns={\"fullvisitorid\": \"num_visitors\"})\n    # LEFT JOIN with frequency counts by outcome (whether purchase was made or not)\n    .merge(\n        df[\"made_purchase_on_future_visit\"]\n        .value_counts()\n        .rename(\"total_visitors\")\n        .reset_index(),\n        on=\"made_purchase_on_future_visit\",\n        how=\"left\",\n    )\n    # calculate fraction from count\n    .assign(frac_visitors=lambda df: 100 * df[\"num_visitors\"] / df[\"total_visitors\"])\n    # ORDER BY for display purposes only\n    .sort_values(by=[\"made_purchase_on_future_visit\", \"num_visitors\"], ascending=False)\n)\ndf_agg_by_channel\n\n\n\n\n\n\n\n\nmade_purchase_on_future_visit\nchannelGrouping\nnum_visitors\ntotal_visitors\nfrac_visitors\n\n\n\n\n6\nTrue\nReferral\n1841\n4250\n43.317647\n\n\n4\nTrue\nDirect\n1642\n4250\n38.635294\n\n\n5\nTrue\nOrganic Search\n579\n4250\n13.623529\n\n\n7\nTrue\nother\n188\n4250\n4.423529\n\n\n1\nFalse\nOrganic Search\n38001\n88301\n43.035753\n\n\n0\nFalse\nDirect\n19897\n88301\n22.533154\n\n\n3\nFalse\nother\n16086\n88301\n18.217234\n\n\n2\nFalse\nReferral\n14317\n88301\n16.213859\n\n\n\n\n\n\n\nA plot showing the fraction of return purchasers by channel (frac_visitors) is shown below\n\nfig = plt.figure(figsize=(11, 4))\ngrid = plt.GridSpec(1, 1)\nax1 = fig.add_subplot(grid[0, 0])\n\nfor ax, c in zip([ax1], [True]):\n    data = df_agg_by_channel.query(f\"made_purchase_on_future_visit == {c}\")\n    sns.barplot(\n        x=data[\"channelGrouping\"],\n        y=data[\"frac_visitors\"],\n        palette=[\"red\", \"lightgrey\", \"red\", \"lightgrey\"],\n        ax=ax,\n    )\n    ax.set_xlabel(None)\n    ax.set_ylabel(None)\n    ax.xaxis.set_tick_params(labelsize=12)\n    ax.yaxis.set_tick_params(labelsize=12)\n    ax.tick_params(size=0)\n    ax.axhline(0, ls=\"--\", c=\"black\")\n    ax.set_title(\n        (\n            \"Direct and Referrals dominate Google Search as most \"\n            \"popular channel used by return purchasers\"\n        ),\n        loc=\"left\",\n        fontweight=\"bold\",\n        fontsize=11,\n    )\n    ax = customize_splines(ax, None)\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\n(From the table df_agg_by_channel) Organic Search (Google search engine) and direct arrivals are the two dominant sources of first-time visitors to the site who do not make a purchase on a return visit.\n(From the chart) By comparison, when visitors who do make a purchase on their return visit reach the site, they are reaching the store through referrals (eg. NYTimes.com, etc.) or by directly entering the URL directly into their browser search bar. Organic search accounts for a relatively smaller fraction of such return purchasers.\n\n\n\nQuestion 3. Is there any one web-browser that return purchasers used on their first visit?\n\ndf_agg_by_browser = (\n    # groupby and count fullvisitorid\n    df.groupby([\"made_purchase_on_future_visit\", \"browser\"], as_index=False)[\n        \"fullvisitorid\"\n    ]\n    .count()\n    .rename(columns={\"fullvisitorid\": \"num_visitors\"})\n    # LEFT JOIN with frequency counts by outcome (whether purchase was made or not)\n    .merge(\n        df[\"made_purchase_on_future_visit\"]\n        .value_counts()\n        .rename(\"total_visitors\")\n        .reset_index(),\n        on=\"made_purchase_on_future_visit\",\n        how=\"left\",\n    )\n    # calculate fraction from count\n    .assign(frac_visitors=lambda df: 100 * df[\"num_visitors\"] / df[\"total_visitors\"])\n    # ORDER BY for display purposes only\n    .sort_values(by=[\"made_purchase_on_future_visit\", \"num_visitors\"], ascending=False)\n)\ndf_agg_by_browser\n\n\n\n\n\n\n\n\nmade_purchase_on_future_visit\nbrowser\nnum_visitors\ntotal_visitors\nfrac_visitors\n\n\n\n\n3\nTrue\nChrome\n4102\n4250\n96.517647\n\n\n4\nTrue\nSafari\n95\n4250\n2.235294\n\n\n5\nTrue\nother\n53\n4250\n1.247059\n\n\n0\nFalse\nChrome\n64899\n88301\n73.497469\n\n\n1\nFalse\nSafari\n15199\n88301\n17.212716\n\n\n2\nFalse\nother\n8203\n88301\n9.289816\n\n\n\n\n\n\n\nA plot showing the fraction of return purchasers by web browser (frac_visitors) is shown below\n\nfig = plt.figure(figsize=(8, 6))\ngrid = plt.GridSpec(2, 1, hspace=0)\nax1 = fig.add_subplot(grid[0, 0])\nax2 = fig.add_subplot(grid[1, 0])\n\nfor ax, c in zip([ax1, ax2], [True, False]):\n    data = df_agg_by_browser.query(f\"made_purchase_on_future_visit == {c}\")\n    sns.barplot(\n        x=data[\"browser\"],\n        y=data[\"frac_visitors\"],\n        palette=[\"red\", \"lightgrey\", \"lightgrey\"],\n        ax=ax,\n    )\n    ax.set_xlabel(None)\n    ax.set_ylabel(None)\n    ax.xaxis.set_tick_params(labelsize=12)\n    ax.yaxis.set_tick_params(labelsize=12)\n    ax.tick_params(size=0)\n    ax.axhline(0, ls=\"--\", c=\"black\")\n    if c:\n        ax.set_title(\n            \"Chrome was more predominant among return purchasers\",\n            loc=\"left\",\n            fontweight=\"bold\",\n        )\n        ax.set_xticklabels([])\n    ax = customize_splines(ax, None)\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nGoogle Chrome is the dominant browser used during the first visit by visitors who return to make a future purchase.\nThere are more first-time visitors that access the store using Safari using that visit who don’t make a purchase on their return visit, but even in this case Chrome is more frequently used.\n\n\n\nQuestion 4. Do visitors who make a purchase on their return visit to the store have a preference for the type of device (desktop, mobile, etc.) they are using during their first visit?\n\ndf_agg_by_device = (\n    # groupby and count fullvisitorid\n    df.groupby([\"made_purchase_on_future_visit\", \"deviceCategory\"], as_index=False)[\n        \"fullvisitorid\"\n    ]\n    .count()\n    .rename(columns={\"fullvisitorid\": \"num_visitors\"})\n    # LEFT JOIN with frequency counts by outcome (whether purchase was made or not)\n    .merge(\n        df[\"made_purchase_on_future_visit\"]\n        .value_counts()\n        .rename(\"total_visitors\")\n        .reset_index(),\n        on=\"made_purchase_on_future_visit\",\n        how=\"left\",\n    )\n    # calculate fraction from count\n    .assign(frac_visitors=lambda df: 100 * df[\"num_visitors\"] / df[\"total_visitors\"])\n    # ORDER BY for display purposes only\n    .sort_values(by=[\"made_purchase_on_future_visit\", \"num_visitors\"], ascending=False)\n)\ndf_agg_by_device\n\n\n\n\n\n\n\n\nmade_purchase_on_future_visit\ndeviceCategory\nnum_visitors\ntotal_visitors\nfrac_visitors\n\n\n\n\n3\nTrue\ndesktop\n4091\n4250\n96.258824\n\n\n4\nTrue\nmobile\n131\n4250\n3.082353\n\n\n5\nTrue\ntablet\n28\n4250\n0.658824\n\n\n0\nFalse\ndesktop\n63264\n88301\n71.645848\n\n\n1\nFalse\nmobile\n21659\n88301\n24.528601\n\n\n2\nFalse\ntablet\n3378\n88301\n3.825551\n\n\n\n\n\n\n\nA plot showing the fraction of return purchasers by type of computing device (frac_visitors) is shown below\n\nfig = plt.figure(figsize=(8, 6))\ngrid = plt.GridSpec(2, 1, hspace=0)\nax1 = fig.add_subplot(grid[0, 0])\nax2 = fig.add_subplot(grid[1, 0])\n\nfor ax, c in zip([ax1, ax2], [True, False]):\n    data = df_agg_by_device.query(f\"made_purchase_on_future_visit == {c}\")\n    sns.barplot(\n        x=data[\"deviceCategory\"],\n        y=data[\"frac_visitors\"],\n        palette=[\"red\", \"lightgrey\", \"lightgrey\"],\n        ax=ax,\n    )\n    ax.set_xlabel(None)\n    ax.set_ylabel(None)\n    ax.xaxis.set_tick_params(labelsize=12)\n    ax.yaxis.set_tick_params(labelsize=12)\n    ax.tick_params(size=0)\n    ax.axhline(0, ls=\"--\", c=\"black\")\n    if c:\n        ax.set_title(\n            \"Desktops were more predominant among return purchasers\",\n            loc=\"left\",\n            fontweight=\"bold\",\n        )\n        ax.set_xticklabels([])\n    ax = customize_splines(ax, None)\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nThis dataset was from 2016-2017. As use of mobile phones grown since then, these numbers may have changed in favor of increased use of mobile devices (even if desktop remains the dominant type of device being currently used).\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThere are relatively more visitors whow use their mobile phones for their initial visit and who don’t make a return purchase than those that do return to make a purchase. Nonetheless, regardless of whether a future purchase is made, first-time visitors are overwhelmingly accessing the store’s website from their desktops.\n\n\n\nQuestion 5. Which traffic sources were responsible for the most return purchasers on weekdays and weekends?\nThe following columns will be used for the questions involving datetime attributes\n\nfullvisitorid\nmonth (1 - 12)\nday_of_month (1 - 31)\nday_of_week (1 - 7)\nhour\nsource (traffic source after grouping)\nmade_purchase_on_future_visit (ML label column, y)\n\n\n\nCode\ndatetime_label_cols = [\n    \"fullvisitorid\",\n    \"month\",\n    \"day_of_month\",\n    \"day_of_week\",\n    \"hour\",\n    \"source\",\n    \"made_purchase_on_future_visit\",\n]\n\n\nShow the fullvisitorid, datetime and ML label (y) columns from the prepared data\n\n\nCode\ndf[datetime_label_cols].head()\n\n\n\n\n\n\n\n\n\nfullvisitorid\nmonth\nday_of_month\nday_of_week\nhour\nsource\nmade_purchase_on_future_visit\n\n\n\n\n0\n483329569933708956\n10\n25\n3\n19\ngoogle\nFalse\n\n\n1\n9534112552538425546\n10\n16\n1\n22\nyoutube.com\nFalse\n\n\n2\n4648924122067625674\n10\n8\n7\n16\nyoutube.com\nFalse\n\n\n3\n2743152869399749836\n12\n8\n5\n15\ngoogle\nFalse\n\n\n4\n1565213706199847638\n9\n29\n5\n14\ngoogle\nFalse\n\n\n\n\n\n\n\nDefinie mapping dictionaries to change month and day of week from integers to strings (month name and day name)\n\nmonth_mapper = dict(zip(range(1, 12 + 1), month_name[1:]))\nday_mapper = dict(zip(range(1, 7 + 1), [day_name[-1]] + day_name[:-1]))\n\nApply these mapping dictionaries to the prepared data to get new columns with the _name suffix and append a column to indicate if the day of the week is a weekday or weekend\n\ndf_datetime = (\n    # map month to month name\n    df.assign(month_name=lambda df: df[\"month\"].map(month_mapper))\n    # map day of week to day name\n    .assign(day_name=lambda df: df[\"day_of_week\"].map(day_mapper))\n    # map day of week to weekend check (boolean column)\n    .assign(is_weekend=lambda df: df[\"day_of_week\"].isin([1, 7]))\n)\ndf_datetime[\n    datetime_label_cols[:-1]\n    + [\"month_name\", \"is_weekend\", \"day_name\"]\n    + [datetime_label_cols[-1]]\n].head()\n\n\n\n\n\n\n\n\nfullvisitorid\nmonth\nday_of_month\nday_of_week\nhour\nsource\nmonth_name\nis_weekend\nday_name\nmade_purchase_on_future_visit\n\n\n\n\n0\n483329569933708956\n10\n25\n3\n19\ngoogle\nOctober\nFalse\nTuesday\nFalse\n\n\n1\n9534112552538425546\n10\n16\n1\n22\nyoutube.com\nOctober\nTrue\nSunday\nFalse\n\n\n2\n4648924122067625674\n10\n8\n7\n16\nyoutube.com\nOctober\nTrue\nSaturday\nFalse\n\n\n3\n2743152869399749836\n12\n8\n5\n15\ngoogle\nDecember\nFalse\nThursday\nFalse\n\n\n4\n1565213706199847638\n9\n29\n5\n14\ngoogle\nSeptember\nFalse\nThursday\nFalse\n\n\n\n\n\n\n\nPerform the GROUP BY over\n\ntraffic source\nis_weekend\nwhether return purchase was made\n\nand get fraction of visitors\n\ndf_datetime_agg_source = (\n    # groupby and count fullvisitorid\n    df_datetime.groupby(\n        [\"source\", \"is_weekend\", \"made_purchase_on_future_visit\"],\n        as_index=False,\n    )\n    .agg({\"fullvisitorid\": \"count\"})\n    .rename(columns={\"fullvisitorid\": \"num_visitors\"})\n    .sort_values(by=[\"made_purchase_on_future_visit\", \"source\"])\n    # LEFT JOIN with frequency counts by outcome (whether purchase was made or not)\n    .merge(\n        df[\"made_purchase_on_future_visit\"]\n        .value_counts()\n        .rename(\"total_visitors\")\n        .reset_index(),\n        on=\"made_purchase_on_future_visit\",\n        how=\"left\",\n    )\n    # calculate fraction from count\n    .assign(frac_visitors=lambda df: 100 * df[\"num_visitors\"] / df[\"total_visitors\"])\n)\ndf_datetime_agg_source\n\n\n\n\n\n\n\n\nsource\nis_weekend\nmade_purchase_on_future_visit\nnum_visitors\ntotal_visitors\nfrac_visitors\n\n\n\n\n0\n(direct)\nFalse\nFalse\n16220\n88301\n18.368988\n\n\n1\n(direct)\nTrue\nFalse\n3677\n88301\n4.164166\n\n\n2\ngoogle\nFalse\nFalse\n32439\n88301\n36.736843\n\n\n3\ngoogle\nTrue\nFalse\n10344\n88301\n11.714477\n\n\n4\nmall.googleplex.com\nFalse\nFalse\n9349\n88301\n10.587649\n\n\n5\nmall.googleplex.com\nTrue\nFalse\n1149\n88301\n1.301231\n\n\n6\nother\nFalse\nFalse\n5947\n88301\n6.734918\n\n\n7\nother\nTrue\nFalse\n1158\n88301\n1.311423\n\n\n8\nyoutube.com\nFalse\nFalse\n5883\n88301\n6.662439\n\n\n9\nyoutube.com\nTrue\nFalse\n2135\n88301\n2.417866\n\n\n10\n(direct)\nFalse\nTrue\n1343\n4250\n31.600000\n\n\n11\n(direct)\nTrue\nTrue\n299\n4250\n7.035294\n\n\n12\ngoogle\nFalse\nTrue\n561\n4250\n13.200000\n\n\n13\ngoogle\nTrue\nTrue\n134\n4250\n3.152941\n\n\n14\nmall.googleplex.com\nFalse\nTrue\n1123\n4250\n26.423529\n\n\n15\nmall.googleplex.com\nTrue\nTrue\n155\n4250\n3.647059\n\n\n16\nother\nFalse\nTrue\n513\n4250\n12.070588\n\n\n17\nother\nTrue\nTrue\n119\n4250\n2.800000\n\n\n18\nyoutube.com\nFalse\nTrue\n2\n4250\n0.047059\n\n\n19\nyoutube.com\nTrue\nTrue\n1\n4250\n0.023529\n\n\n\n\n\n\n\nA heatmap is shown below for return purchasers (frac_visitors) and similarly for visitors who did not make a purchase on a return visit\n\nfig = plt.figure(figsize=(12, 4))\ngrid = plt.GridSpec(2, 1, hspace=0.3)\nax1 = fig.add_subplot(grid[0, 0])\nax2 = fig.add_subplot(grid[1, 0])\n\nfor ax, c, ptitle_substr, source in zip(\n    [ax1, ax2],\n    [True, False],\n    [\"returning purchasers\", \"returning non-purchasers\"],\n    [\"direct access\", \"Google Search\"],\n):\n    data = (\n        # filter\n        (\n            df_datetime_agg_source.query(\n                f\"made_purchase_on_future_visit == {c}\"\n            ).assign(\n                is_weekend=lambda df: df[\"is_weekend\"].map(\n                    {False: \"weekday\", True: \"weekend\"}\n                )\n            )\n        )\n        # reshape for heatmap\n        .pivot(\n            index=\"source\",\n            columns=\"is_weekend\",\n            values=\"frac_visitors\",\n        )\n        .astype(float)\n        .transpose()\n    )\n\n    # plot heatmap\n    ax = sns.heatmap(data, cmap=\"YlOrRd\", cbar_kws={\"pad\": 0.01}, linewidth=0.5, ax=ax)\n\n    # customize heatmap\n    ax.set_xlabel(None)\n    ax.set_ylabel(None)\n    ax.xaxis.set_tick_params(labelsize=12)\n    ax.yaxis.set_tick_params(labelsize=12, rotation=0)\n    ax.set_title(\n        f\"Most {ptitle_substr} access the site through {source}\",\n        loc=\"left\",\n        fontweight=\"bold\",\n    )\n    cbar = ax.collections[0].colorbar\n    cbar.ax.tick_params(size=0, labelsize=12)\n    if c:\n        ax.set_xticklabels([])\n    ax.tick_params(size=0)\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nDirect channels and referrals were the found earlier to be the dominant channels used by return purchasers (made_purchase_on_future_visit = True). So it is not surprising that the same two sources are the dominant ones bringing return purchasers to the site on weekedays and weekends in the top subplot. Among referrals, Gmail is the dominant referral source bringing return purchasers to the store.\n\n\n\nQuestion 6. Show the fraction of visitors who did make a purchase on their return visit to the merchandise store by month and day of the month.\n\ndf_agg = df.groupby([\"month\", \"day_of_month\"], as_index=False).agg(\n    {\"made_purchase_on_future_visit\": [\"sum\"], \"fullvisitorid\": \"count\"}\n)\ndf_agg.columns = [\"_\".join(c).rstrip(\"_\") for c in df_agg.columns.to_flat_index()]\ndf_agg = df_agg.rename(\n    columns={\n        \"made_purchase_on_future_visit_sum\": \"return_purchasers\",\n        \"fullvisitorid_count\": \"return_visitors\",\n    }\n).assign(\n    frac_return_purchasers=lambda df: 100\n    * df[\"return_purchasers\"]\n    / df[\"return_visitors\"]\n)\ndisplay(df_agg.head())\ndisplay(df_agg.tail())\n\n\n\n\n\n\n\n\nmonth\nday_of_month\nreturn_purchasers\nreturn_visitors\nfrac_return_purchasers\n\n\n\n\n0\n1\n1\n1\n39\n2.564103\n\n\n1\n9\n1\n18\n643\n2.799378\n\n\n2\n9\n2\n17\n647\n2.627512\n\n\n3\n9\n3\n5\n408\n1.22549\n\n\n4\n9\n4\n6\n350\n1.714286\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonth\nday_of_month\nreturn_purchasers\nreturn_visitors\nfrac_return_purchasers\n\n\n\n\n118\n12\n27\n34\n665\n5.112782\n\n\n119\n12\n28\n30\n577\n5.199307\n\n\n120\n12\n29\n22\n588\n3.741497\n\n\n121\n12\n30\n13\n436\n2.981651\n\n\n122\n12\n31\n15\n439\n3.416856\n\n\n\n\n\n\n\nReshape into untidy data for heatmap\n\ndata = (\n    df_agg.query(\"month &gt;= 9\")\n    .assign(month_name=lambda df: df[\"month\"].map(month_mapper))\n    .pivot(index=\"day_of_month\", columns=\"month_name\", values=\"frac_return_purchasers\")\n    .astype(float)[month_name[1:][-4:]]\n)\ndata.reset_index()\n\n\n\n\n\n\n\nmonth_name\nday_of_month\nSeptember\nOctober\nNovember\nDecember\n\n\n\n\n0\n1\n2.799378\n2.094241\n6.130790\n5.904059\n\n\n1\n2\n2.627512\n1.670644\n5.576679\n5.989305\n\n\n2\n3\n1.225490\n4.066265\n6.161137\n3.909774\n\n\n3\n4\n1.714286\n2.702703\n5.153203\n5.652174\n\n\n4\n5\n2.444444\n3.389831\n5.772812\n7.899306\n\n\n5\n6\n1.834862\n2.423469\n6.654676\n6.147541\n\n\n6\n7\n2.624672\n2.497027\n8.690013\n6.353861\n\n\n7\n8\n2.627737\n1.720841\n4.913295\n5.579399\n\n\n8\n9\n3.285714\n1.691729\n6.239737\n5.838041\n\n\n9\n10\n2.127660\n4.490291\n6.200528\n4.596273\n\n\n10\n11\n1.162791\n2.731591\n8.401084\n5.465839\n\n\n11\n12\n3.047896\n4.694836\n3.433476\n6.115108\n\n\n12\n13\n3.511450\n3.967328\n5.835010\n6.141079\n\n\n13\n14\n3.096774\n4.551724\n5.581948\n4.728546\n\n\n14\n15\n2.980473\n0.751880\n6.207675\n4.850746\n\n\n15\n16\n2.785146\n2.003643\n5.672970\n4.486626\n\n\n16\n17\n0.982801\n4.216074\n7.978723\n4.000000\n\n\n17\n18\n3.359173\n3.726708\n6.483791\n2.739726\n\n\n18\n19\n4.676754\n2.557201\n6.428571\n4.984177\n\n\n19\n20\n3.983516\n2.230483\n6.158358\n3.688181\n\n\n20\n21\n3.648649\n2.580645\n6.652587\n3.598691\n\n\n21\n22\n2.435065\n1.841621\n6.773399\n4.477612\n\n\n22\n23\n2.184874\n1.949318\n8.421053\n2.935780\n\n\n23\n24\n1.269036\n2.709069\n6.306306\n3.448276\n\n\n24\n25\n1.363636\n3.057758\n6.560847\n2.004454\n\n\n25\n26\n4.781997\n5.309735\n8.108108\n3.983229\n\n\n26\n27\n3.030303\n4.171633\n6.736353\n5.112782\n\n\n27\n28\n3.030303\n4.801097\n9.046154\n5.199307\n\n\n28\n29\n1.894452\n3.861004\n8.056171\n3.741497\n\n\n29\n30\n2.297090\n2.977233\n6.707855\n2.981651\n\n\n30\n31\nNaN\n5.781866\nNaN\n3.416856\n\n\n\n\n\n\n\nShow heatmap\n\nshow_heatmap(\n    data,\n    \"Day of Month\",\n    \"% of return purchasers was higher in November 2016 than neighbouring months\",\n    {\"pad\": 0.01},\n    fig_size=(10, 12),\n)\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe fraction of daily visitors who made a purchase on their return visit to the store (or, return purchasers) peaked during November 2016 before dropping in December. This trend not only implies seasonality in bulk buying trends at the store but also, the higher fraction before Christmas and the New Year festivities is critical to the store’s strategic planning.\n\n\n\nQuestion 7. Show the fraction of visitors who made a purchase on their return visit to the merchandise store by month and day of the week.\nAggregate to get number of\n\nvisitors\nchannels\n\nused by visitors who did and did not make purchase on a return visit\n\ndf_agg = df.groupby(\n    [\"month\", \"day_of_week\", \"made_purchase_on_future_visit\"], as_index=False\n).agg({\"fullvisitorid\": \"count\", \"channelGrouping\": \"nunique\"})\ndf_agg = df_agg.rename(\n    columns={\"channelGrouping\": \"num_channels\", \"fullvisitorid\": \"return_visitors\"}\n)\ndf_agg.head()\n\n\n\n\n\n\n\n\nmonth\nday_of_week\nmade_purchase_on_future_visit\nreturn_visitors\nnum_channels\n\n\n\n\n0\n1\n1\nFalse\n38\n4\n\n\n1\n1\n1\nTrue\n1\n1\n\n\n2\n9\n1\nFalse\n1577\n4\n\n\n3\n9\n1\nTrue\n30\n4\n\n\n4\n9\n2\nFalse\n2477\n4\n\n\n\n\n\n\n\nPivot the data so that the number of visitors who did and did not make a return purchase are shown as separate columns (repeat for number of channels used by visitors who did and did not make a return purchase)\n\ndf_agg_untidy = df_agg.pivot(\n    index=[\"month\", \"day_of_week\"],\n    columns=[\"made_purchase_on_future_visit\"],\n    values=[\"return_visitors\", \"num_channels\"],\n).reset_index()\ndf_agg_untidy.columns = [\n    \"_\".join([str(c) for c in c_list]).rstrip(\"_\")\n    for c_list in df_agg_untidy.columns.to_flat_index()\n]\ndf_agg_untidy.head()\n\n\n\n\n\n\n\n\nmonth\nday_of_week\nreturn_visitors_False\nreturn_visitors_True\nnum_channels_False\nnum_channels_True\n\n\n\n\n0\n1\n1\n38\n1\n4\n1\n\n\n1\n9\n1\n1577\n30\n4\n4\n\n\n2\n9\n2\n2477\n100\n4\n4\n\n\n3\n9\n3\n2645\n85\n4\n4\n\n\n4\n9\n4\n2910\n93\n4\n4\n\n\n\n\n\n\n\nGet total number of visitors and channels\n\ndf_agg_untidy[\"num_channels\"] = (\n    df_agg_untidy[\"num_channels_False\"] + df_agg_untidy[\"num_channels_True\"]\n)\ndf_agg_untidy[\"return_visitors\"] = (\n    df_agg_untidy[\"return_visitors_False\"] + df_agg_untidy[\"return_visitors_True\"]\n)\ndf_agg_untidy.head()\n\n\n\n\n\n\n\n\nmonth\nday_of_week\nreturn_visitors_False\nreturn_visitors_True\nnum_channels_False\nnum_channels_True\nnum_channels\nreturn_visitors\n\n\n\n\n0\n1\n1\n38\n1\n4\n1\n5\n39\n\n\n1\n9\n1\n1577\n30\n4\n4\n8\n1607\n\n\n2\n9\n2\n2477\n100\n4\n4\n8\n2577\n\n\n3\n9\n3\n2645\n85\n4\n4\n8\n2730\n\n\n4\n9\n4\n2910\n93\n4\n4\n8\n3003\n\n\n\n\n\n\n\nConvert number of visitors and channels into fractions of visitors and channels\n\ndf_agg_untidy[\"frac_channels_used_by_return_purchasers\"] = 100 * (\n    df_agg_untidy[\"num_channels_True\"] / df_agg_untidy[\"num_channels\"]\n)\ndf_agg_untidy[\"frac_return_purchasers\"] = 100 * (\n    df_agg_untidy[\"return_visitors_True\"] / df_agg_untidy[\"return_visitors\"]\n)\ndf_agg_untidy.sample(5)\n\n\n\n\n\n\n\n\nmonth\nday_of_week\nreturn_visitors_False\nreturn_visitors_True\nnum_channels_False\nnum_channels_True\nnum_channels\nreturn_visitors\nfrac_channels_used_by_return_purchasers\nfrac_return_purchasers\n\n\n\n\n7\n9\n7\n1609\n23\n4\n4\n8\n1632\n50.0\n1.409314\n\n\n22\n12\n1\n2633\n114\n4\n4\n8\n2747\n50.0\n4.149982\n\n\n15\n11\n1\n2430\n166\n4\n4\n8\n2596\n50.0\n6.394453\n\n\n18\n11\n4\n4004\n281\n4\n4\n8\n4285\n50.0\n6.557760\n\n\n4\n9\n4\n2910\n93\n4\n4\n8\n3003\n50.0\n3.096903\n\n\n\n\n\n\n\nMelt data to get back to GROUP BY format, and only keep columns with fractions (drop columns with numbers)\n\ndf_agg_tidy = df_agg_untidy.melt(\n    id_vars=[\"month\", \"day_of_week\"],\n    value_vars=[\"frac_channels_used_by_return_purchasers\", \"frac_return_purchasers\"],\n)\ndf_agg_tidy.head()\n\n\n\n\n\n\n\n\nmonth\nday_of_week\nvariable\nvalue\n\n\n\n\n0\n1\n1\nfrac_channels_used_by_return_purchasers\n20.0\n\n\n1\n9\n1\nfrac_channels_used_by_return_purchasers\n50.0\n\n\n2\n9\n2\nfrac_channels_used_by_return_purchasers\n50.0\n\n\n3\n9\n3\nfrac_channels_used_by_return_purchasers\n50.0\n\n\n4\n9\n4\nfrac_channels_used_by_return_purchasers\n50.0\n\n\n\n\n\n\n\nReshape into untidy data for heatmap\n\ndata = (\n    df_agg_tidy.query(\"month &gt;= 9\")\n    .query(\"variable == 'frac_return_purchasers'\")\n    .assign(day_name=lambda df: df[\"day_of_week\"].map(day_mapper))\n    .assign(month_name=lambda df: df[\"month\"].map(month_mapper))\n    .pivot(index=\"day_name\", columns=\"month_name\", values=\"value\")\n    .loc[list(day_name)][month_name[1:][-4:]]\n)\ndata\n\n\n\n\n\n\n\nmonth_name\nSeptember\nOctober\nNovember\nDecember\n\n\nday_name\n\n\n\n\n\n\n\n\nMonday\n3.880481\n4.226082\n7.741935\n6.023815\n\n\nTuesday\n3.113553\n3.009504\n6.656243\n5.300023\n\n\nWednesday\n3.096903\n4.055525\n6.557760\n4.974037\n\n\nThursday\n2.571116\n3.224825\n6.718891\n5.071080\n\n\nFriday\n2.657510\n3.602058\n6.650016\n4.810249\n\n\nSaturday\n1.409314\n2.041633\n6.209292\n3.981043\n\n\nSunday\n1.866833\n2.089783\n6.394453\n4.149982\n\n\n\n\n\n\n\nShow heatmap\n\nshow_heatmap(\n    data,\n    None,\n    \"% of return purchasers was consistently lower on weekends than weekdays\",\n    False,\n    annot_kws={\"size\": 14},\n    fig_size=(9, 4),\n)\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nThe pool of visitors who are return purchasers shows weak evidence of following the structure of the work week since the fraction of return purchasers dropped on weekends (Saturday and Sunday) compared to weekedays.\n\n\n\nQuestion 8. Show the breakdown of total revenue earned by visitors who are return purchasers and those that are not return purchasers.\n\n\nCode\ndf.groupby([\"made_purchase_on_future_visit\"])[\n    \"transact_revenue\"\n].sum().reset_index().assign(\n    total_first_visit_revenue=lambda df: df[\"transact_revenue\"].sum()\n).assign(\n    frac_transact_revenue=lambda df: 100\n    * df[\"transact_revenue\"]\n    / df[\"total_first_visit_revenue\"]\n).query(\n    \"made_purchase_on_future_visit == True\"\n)\n\n\n\n\n\n\n\n\n\nmade_purchase_on_future_visit\ntransact_revenue\ntotal_first_visit_revenue\nfrac_transact_revenue\n\n\n\n\n1\nTrue\n89350.15625\n484412.15625\n18.44507\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n\n\nReturn purchasers account for nearly 20% of total revenue earned during the first visit."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#key-findings",
    "href": "notebooks/03-eda/notebooks/03_eda.html#key-findings",
    "title": "Exploratory Data Analysis",
    "section": "Key Findings",
    "text": "Key Findings\n\nProducts and promotions on the store’s website are not being viewed or clicked often by first-time visitors to the site.\nDuring the months covered by the training data, only\n\n10% of all visitors to the store added a product to their shopping cart during their first visit\n4% of all first-time visitors to the store made a purchase on a return visit\n\nCorrelations between numerical attributes of visitors’ first visits and revenue earned during the first visit\n\ngrouping traffic by channel\n\ndirect traffic and referrals account for approximately 40% of all return purchasers and are responsible for the highest correlation to revenue earned during the first visit by visitors who returned to make a purchase during a return (future) visit.\n\ngrouping visitor traffic by source\n\ngmail and the combined other (less frequently used) traffic sources show the highest correlation to revenue. Direct sources ranks third.\ncorrelations are stronger at the source level (more granular) than at the channel or traffic medium level (both of which are higher-level groupings of traffic sources)\nsome of the columns namely hits, pageviews and products with detail views are correlated to eachother, so one or more of these features should be excluded during ML development\n\n\nGoogle Chrome is the dominant browser used during the first visit of visitors who return to make a future purchase.\nFor those visitors that do return and make a future purchase, they are predominantly doing so by accessing the store’s site from a desktop computer.\nBy traffic source, direct channels and referrals are the dominant sources bringing return purchasers to the site on both weekedays and weekends.\nReturn purchasers peaked during November 2016 before dropping in December.\nReturn purchasers were higher in number on weekdays than on weekends."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#summary-of-assumptions",
    "href": "notebooks/03-eda/notebooks/03_eda.html#summary-of-assumptions",
    "title": "Exploratory Data Analysis",
    "section": "Summary of Assumptions",
    "text": "Summary of Assumptions\nNone."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#summary-of-tasks-performed",
    "href": "notebooks/03-eda/notebooks/03_eda.html#summary-of-tasks-performed",
    "title": "Exploratory Data Analysis",
    "section": "Summary of Tasks Performed",
    "text": "Summary of Tasks Performed\nThis step has performed non-exhaustive EDA for insights into the prepared data."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#limitations",
    "href": "notebooks/03-eda/notebooks/03_eda.html#limitations",
    "title": "Exploratory Data Analysis",
    "section": "Limitations",
    "text": "Limitations\n\nLimited EDA has been performed. For columns for which we have not performed EDA, we will be relying on our intuition to determine whether they will be useful as ML features."
  },
  {
    "objectID": "notebooks/03-eda/notebooks/03_eda.html#next-step",
    "href": "notebooks/03-eda/notebooks/03_eda.html#next-step",
    "title": "Exploratory Data Analysis",
    "section": "Next Step",
    "text": "Next Step\nThe next step will transform the raw data in this dataset, in order to prepare it for machine learning, as follows\n\nextract the attributes of each visit that were recommended in this step\ndrop duplicates by fullvisitorid\nhandle high-cardinality categorical columns\n\nThis will be done separately for training, validation and test data splits. As with the (current) EDA step, we will again use the learnings from data preparation in order to avoid preparing data for ML development that suffers from data leakage/lookahead bias.\nThe data will first be split into training, validation and test splits before 1. dropping duplicates 2. creating a lookup table using the training data to create category groupings for the categorical features - as shown in this step, these groupings are used to address the issue of high-cardinality categorical features during ML model development"
  }
]